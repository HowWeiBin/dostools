{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84565b74",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfdaeca7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:01.560384Z",
     "start_time": "2023-04-01T13:10:58.548237Z"
    }
   },
   "outputs": [],
   "source": [
    "import dostools\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import time\n",
    "torch.set_default_dtype(torch.float64) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ccbf26d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:04.555132Z",
     "start_time": "2023-04-01T13:11:01.563421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ldos shape is torch.Size([1039, 778])\n",
      "mean dos shape is torch.Size([778])\n",
      "Variance covered with 10 PCs is = 0.9871211778950163\n"
     ]
    }
   ],
   "source": [
    "import dostools.datasets.data as data\n",
    "import dostools.utils.utils as utils\n",
    "\n",
    "n_structures = 1039\n",
    "np.random.seed(0)\n",
    "n_train = int(0.8 * n_structures)\n",
    "train_index = np.arange(n_structures)\n",
    "np.random.shuffle(train_index)\n",
    "test_index = train_index[n_train:]\n",
    "train_index = train_index[:n_train]\n",
    "\n",
    "with torch.no_grad():\n",
    "    structures = data.load_structures(\":\")\n",
    "    n_structures = len(structures) #total number of structures\n",
    "    for structure in structures:#implement periodicity\n",
    "        structure.wrap(eps = 1e-12) \n",
    "    n_atoms = np.zeros(n_structures, dtype = int) #stores number of atoms in each structures\n",
    "    for i in range(n_structures):\n",
    "        n_atoms[i] = len(structures[i])\n",
    "\n",
    "    #eigenergies, emin, emax = dostools.src.datasets.data.load_eigenenergies(unpack = True, n_structures = len(structures))\n",
    "    xdos = torch.tensor(data.load_xdos())\n",
    "    ldos = torch.tensor(data.load_ldos())\n",
    "    ldos *= 2\n",
    "\n",
    "    print (\"ldos shape is {}\".format(ldos.shape))\n",
    "    mean_dos_per_atom = ldos[train_index].mean(axis = 0) #only calculated for train set to prevent data leakage\n",
    "    print (\"mean dos shape is {}\".format(mean_dos_per_atom.shape))\n",
    "    \n",
    "    \n",
    "    y_pw = ldos - mean_dos_per_atom\n",
    "    y_lcdf = torch.cumsum(y_pw, dim = 1)\n",
    "    _, pc_vectors = utils.build_pc(ldos[train_index], mean_dos_per_atom[None,:], n_pc = 10)\n",
    "    y_pc = utils.build_coeffs(ldos - mean_dos_per_atom[None,:], pc_vectors)\n",
    "    Silicon = data.load_features()\n",
    "    kMM = data.load_kMM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "381681ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:09.395746Z",
     "start_time": "2023-04-01T13:11:04.557590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file contains the eigenenergies and their corresponding kpoints of the training Silicon structures generated using DFT PBE as implemented in FHI-AIMS version 171221_1 with the ``tight'' settings\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(data)\n",
    "eigen_energies, emin, emax = data.load_eigenenergies(unpack = True, n_structures = n_structures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cccb6b75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:21.416092Z",
     "start_time": "2023-04-01T13:11:21.306969Z"
    }
   },
   "outputs": [],
   "source": [
    "sigma = 0.3\n",
    "dx = 0.05\n",
    "\n",
    "full_eigen_energies = [torch.tensor(i.flatten()) for i in eigen_energies]\n",
    "eigenenergy_length = [len(i) for i in full_eigen_energies]\n",
    "eigenenergy_length_t = torch.tensor(eigenenergy_length)\n",
    "normalization_eiglength = [len(i) for i in eigen_energies]\n",
    "normalization_eiglength_t = torch.tensor(normalization_eiglength)\n",
    "normalization = 1/torch.sqrt(2*torch.tensor(np.pi)*sigma**2)/n_atoms/normalization_eiglength_t\n",
    "normalization_quartic = 1/n_atoms/normalization_eiglength_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff48068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:23.681962Z",
     "start_time": "2023-04-01T13:11:23.631859Z"
    }
   },
   "outputs": [],
   "source": [
    "#Determine right_bound as highest eigenenergy\n",
    "def determine_rightbounds(eigen_energies):\n",
    "    right_bounds = []\n",
    "    for energies in (eigen_energies):\n",
    "        right_bound = torch.max(energies)\n",
    "        right_bounds.append(right_bound)\n",
    "    right_bounds = torch.vstack(right_bounds)\n",
    "    return right_bounds\n",
    "\n",
    "\n",
    "rbounds = determine_rightbounds(full_eigen_energies)\n",
    "\n",
    "def determine_leftbounds(eigen_energies):\n",
    "    left_bounds = []\n",
    "    for energies in (eigen_energies):\n",
    "        left_bound = torch.min(energies)\n",
    "        left_bounds.append(left_bound)\n",
    "    left_bounds = torch.vstack(left_bounds)\n",
    "    return left_bounds\n",
    "lbounds = determine_leftbounds(full_eigen_energies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6c5f365",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:24.401985Z",
     "start_time": "2023-04-01T13:11:24.396562Z"
    }
   },
   "outputs": [],
   "source": [
    "# Determine Fermi level with respect to upper bound\n",
    "# Get core level references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d6187a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:27.373768Z",
     "start_time": "2023-04-01T13:11:24.587286Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fermi level\n",
    "import ase\n",
    "\n",
    "T_0 = 200\n",
    "beta_0 = 1 / (ase.units.kB * T_0) # inverse temperature\n",
    "efermi = np.zeros(n_structures)\n",
    "for i in range(n_structures):\n",
    "    efermi[i] = utils.getmu(ldos[i], beta_0, xdos, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39bbc8ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:27.382557Z",
     "start_time": "2023-04-01T13:11:27.375943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.375835372334838e+00"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(efermi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b3d70a",
   "metadata": {},
   "source": [
    "## Inspecting default train-test split and generating biased dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935d71c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:27.401012Z",
     "start_time": "2023-04-01T13:11:27.384216Z"
    }
   },
   "outputs": [],
   "source": [
    "diamond_range = np.arange(0,324,1)\n",
    "beta_tin_range = np.arange(324,604,1)\n",
    "liquid_range = np.arange(604, 673, 1)\n",
    "clusters_range = np.arange(673, 939, 1)\n",
    "amorphous_range = np.arange(939, 1039, 1)\n",
    "def find_structures_in_index(index):\n",
    "    structures = {}\n",
    "    structures['diamond'] =  np.sum(np.isin(index, diamond_range))\n",
    "    structures['beta_tin'] = np.sum(np.isin(index, beta_tin_range))\n",
    "    structures['liquid'] = np.sum(np.isin(index, liquid_range))\n",
    "    structures['clusters'] = np.sum(np.isin(index, clusters_range))\n",
    "    structures['amorphous'] = np.sum(np.isin(index, amorphous_range))\n",
    "    \n",
    "    return structures\n",
    "\n",
    "train_structures = find_structures_in_index(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36af1a3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:27.415017Z",
     "start_time": "2023-04-01T13:11:27.403674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diamond': 249,\n",
       " 'beta_tin': 231,\n",
       " 'liquid': 58,\n",
       " 'clusters': 209,\n",
       " 'amorphous': 84}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8587576f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:27.431351Z",
     "start_time": "2023-04-01T13:11:27.417002Z"
    }
   },
   "outputs": [],
   "source": [
    "#Selected Amorphous structures\n",
    "\n",
    "amorph_train = np.arange(939,1039,1)\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(amorph_train)\n",
    "\n",
    "amorph_test = amorph_train[:80]\n",
    "amorph_train = amorph_train[80:]\n",
    "\n",
    "n_structures2 = 939\n",
    "np.random.seed(0)\n",
    "n_train = int(0.8 * 1039)-20\n",
    "remaining_train_index = np.arange(n_structures2)\n",
    "np.random.shuffle(remaining_train_index)\n",
    "\n",
    "remaining_test_index = remaining_train_index[n_train:]\n",
    "remaining_train_index = remaining_train_index[:n_train]\n",
    "\n",
    "biased_train_index = np.concatenate([remaining_train_index, amorph_train])\n",
    "biased_test_index = np.concatenate([remaining_test_index, amorph_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb15359d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:28.494971Z",
     "start_time": "2023-04-01T13:11:28.488589Z"
    }
   },
   "outputs": [],
   "source": [
    "biased_train_structures = find_structures_in_index(biased_train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71d34496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:28.821587Z",
     "start_time": "2023-04-01T13:11:28.815010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diamond': 278,\n",
       " 'beta_tin': 244,\n",
       " 'liquid': 60,\n",
       " 'clusters': 229,\n",
       " 'amorphous': 20}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biased_train_structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dbdbbf",
   "metadata": {},
   "source": [
    "## Quartic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec184a5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:30.742335Z",
     "start_time": "2023-04-01T13:11:30.712936Z"
    }
   },
   "outputs": [],
   "source": [
    "#Determine bounds\n",
    "#Determine right_bound as highest eigenenergy\n",
    "rbounds = determine_rightbounds(full_eigen_energies)\n",
    "efermi = torch.tensor(efermi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88b8889f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:31.395805Z",
     "start_time": "2023-04-01T13:11:31.386856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor(-4.3758),\n",
       "indices=tensor(723))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(efermi, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccafc0a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:31.608923Z",
     "start_time": "2023-04-01T13:11:31.602767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor(-7.8526),\n",
       "indices=tensor(346))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(efermi, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc5a7368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:31.775804Z",
     "start_time": "2023-04-01T13:11:31.763806Z"
    }
   },
   "outputs": [],
   "source": [
    "def quartic_dos(energies,xdos, sigma):\n",
    "   \n",
    "    left_b = energies - (np.sqrt(7) * sigma)\n",
    "\n",
    "    output = torch.zeros_like(xdos)\n",
    "\n",
    "    left_bound = torch.searchsorted(xdos, left_b)\n",
    "    \n",
    "    xdos_interval = xdos[1]-xdos[0]\n",
    "    interval = int((2 * (np.sqrt(7) * sigma))/xdos_interval) + 1\n",
    "    indexes = torch.clamp(left_bound.repeat(interval,1) + torch.arange(0,interval,1).view(-1,1), 0, len(xdos)-1)\n",
    "                     \n",
    "    E = torch.clamp((energies.view(1,-1) - xdos[indexes]), min = -1* (np.sqrt(7) * sigma), max = (np.sqrt(7) * sigma))\n",
    "    values = (E**2 - (7 * (sigma**2))) **2 / ((16/15) * (np.sqrt(7) * sigma)**5)\n",
    "    output.index_add_(0, indexes.flatten(), values.flatten())\n",
    "\n",
    "#     output = -1 * output\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce53b9e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:11:34.284191Z",
     "start_time": "2023-04-01T13:11:32.867822Z"
    }
   },
   "outputs": [],
   "source": [
    "#1\n",
    "full_eigen_energies = [torch.tensor(i.flatten()) for i in eigen_energies]\n",
    "sorted_full_eigen_energies = [torch.sort(i)[0] for i in full_eigen_energies]\n",
    "# #2\n",
    "# #Sticking to sigma=0.3, 2eV above the max fermi level will correspond to max energy of 2.8ev above the max fermi level\n",
    "# sorted_full_eigen_energies_2 = []\n",
    "# for e in sorted_full_eigen_energies:\n",
    "    \n",
    "#     sorted_full_eigen_energies_2.append(e[:torch.searchsorted(e, torch.max(efermi) + 2.8)])\n",
    "# #3\n",
    "# sorted_full_eigen_energies_3 = []\n",
    "# for i,e in enumerate(sorted_full_eigen_energies):    \n",
    "#     sorted_full_eigen_energies_3.append(e[:torch.searchsorted(e, efermi[i] + 2.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1c5102e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T14:53:52.371029Z",
     "start_time": "2023-04-03T14:53:46.858681Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1039/1039 [00:05<00:00, 189.06it/s]\n"
     ]
    }
   ],
   "source": [
    "##Generate individual xdos, ldos\n",
    "with torch.no_grad():\n",
    "\n",
    "    n_xdos2 = []\n",
    "    n_ldos2 = []\n",
    "\n",
    "    sigma = torch.tensor(0.3)\n",
    "    ndos = 778 #+ int(30/0.05)\n",
    "\n",
    "\n",
    "    emin = -24.5537\n",
    "    emax = 11.3464\n",
    "\n",
    "    n_xdos2 = torch.linspace(emin - 1.5, emax + 1.5,ndos)\n",
    "\n",
    "    for i in tqdm(range(1039)):\n",
    "        #steps = int((rbounds[i].item()- (10 * sigma) - lbounds[i].item() - 1.5)/0.05)    \n",
    "        l_dos2 = quartic_dos(sorted_full_eigen_energies[i], n_xdos2, sigma)#torch.sum(torch.exp(-0.5*((x_dos - full_eigen_energies[i].view(-1,1))/sigma)**2), dim = 0)\n",
    "    #     n_xdos2.append(x_dos2)\n",
    "        n_ldos2.append(l_dos2)\n",
    "\n",
    "    # n_xdos2 = torch.vstack(n_xdos2)\n",
    "    n_ldos2 = torch.vstack(n_ldos2)\n",
    "    n_ldos2 = ((n_ldos2.T * normalization_quartic ).T)* 2\n",
    "\n",
    "#Do cutting here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d02dccee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T14:53:28.074372Z",
     "start_time": "2023-04-03T14:53:28.069740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1039, 778])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cf2b8575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T14:56:08.606602Z",
     "start_time": "2023-04-03T14:56:08.440893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efd58efc430>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xdos = torch.tensor(data.load_xdos())\n",
    "ldos = torch.tensor(data.load_ldos())\n",
    "ldos *= 2\n",
    "\n",
    "# plt.plot(xdos, n_ldos2[train_index[0]], c= 'r')\n",
    "plt.plot(xdos, ldos[train_index[1]], c= 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ceecce16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T14:57:52.505875Z",
     "start_time": "2023-04-03T14:57:52.499844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0006)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalization_quartic[train_index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af446d11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:16:40.730746Z",
     "start_time": "2023-04-01T13:16:40.721395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([839])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_xdos2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a2d78aa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:57:54.491271Z",
     "start_time": "2023-03-29T11:57:51.528762Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1039/1039 [00:02<00:00, 353.08it/s]\n"
     ]
    }
   ],
   "source": [
    "##Generate shifted quartic dataset\n",
    "\n",
    "\n",
    "full_xdos = []\n",
    "shifted_full_ldos = []\n",
    "\n",
    "sigma = torch.tensor(0.3)\n",
    "# ndos = 778 #+ int(30/0.05)\n",
    "\n",
    "\n",
    "emin = -24.5537\n",
    "emax = 11.3464\n",
    "\n",
    "true_alignments = (torch.rand(1039)-0.5) * 4\n",
    "\n",
    "full_xdos = torch.arange(emin - 3, emax + 3,0.05)\n",
    "for i in tqdm(range(n_structures)):\n",
    "    #steps = int((rbounds[i].item()- (10 * sigma) - lbounds[i].item() - 1.5)/0.05)\n",
    "    #x_dos2 = torch.linspace(emin - 1.5, emax + 1.5,ndos)\n",
    "    shifted_full_ldos_i = quartic_dos(sorted_full_eigen_energies[i] + true_alignments[i], full_xdos, sigma)#torch.sum(torch.exp(-0.5*((x_dos - full_eigen_energies[i].view(-1,1))/sigma)**2), dim = 0)\n",
    "#     n_xdos2.append(x_dos2)\n",
    "    shifted_full_ldos.append(shifted_full_ldos_i)\n",
    "    \n",
    "#n_xdos2 = torch.vstack(n_xdos2)\n",
    "shifted_full_ldos = torch.vstack(shifted_full_ldos)\n",
    "shifted_full_ldos = ((shifted_full_ldos.T * normalization_quartic ).T)* 2\n",
    "\n",
    "#Do cutting here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f549e7fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:11.308422Z",
     "start_time": "2023-03-28T18:29:11.306098Z"
    }
   },
   "outputs": [],
   "source": [
    "# i = 700\n",
    "# #plt.plot(n_xdos[i], n_ldos[i], c= 'r')\n",
    "# plt.plot(xdos, ldos[i], c= 'b')\n",
    "# plt.plot(xdos, n_ldos2[i], c= 'g')\n",
    "# plt.vlines(x = efermi[i], ymin = -0.05, ymax = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfd31fc",
   "metadata": {},
   "source": [
    "## Gradient descent in loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "45cfdd8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:51.157247Z",
     "start_time": "2023-03-28T18:29:51.152205Z"
    }
   },
   "outputs": [],
   "source": [
    "from dostools.loss.loss import t_get_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f184caef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:54:39.546974Z",
     "start_time": "2023-03-27T19:54:39.544674Z"
    }
   },
   "outputs": [],
   "source": [
    "#Goal is to only evaluate loss on the relevant energies\n",
    "# 1) Need to know the range of relevant energies \n",
    "# 2) Should train the energy levels individually,\n",
    "# 3) Need a dataset class\n",
    "# 4) Model receives data and determines which one to feed to\n",
    "# 5) Optimizer updates all relevant weights at once\n",
    "\n",
    "# To define Loss\n",
    "# 1) String together all the xdos, ldos values\n",
    "# 2) Calculate loss on that interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5769926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:54:39.558044Z",
     "start_time": "2023-03-27T19:54:39.549097Z"
    }
   },
   "outputs": [],
   "source": [
    "# Quartic polynomials\n",
    "# 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "582165de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:54:39.569056Z",
     "start_time": "2023-03-27T19:54:39.560289Z"
    }
   },
   "outputs": [],
   "source": [
    "#Need to see if i should align all at once or just one at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3df1b4bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T14:05:19.971501Z",
     "start_time": "2023-04-01T14:05:19.950005Z"
    }
   },
   "outputs": [],
   "source": [
    "def MSE_shift_discrete(pred: torch.tensor, target_eigvals: list, normalization:torch.tensor, xdos: torch.tensor, rbound:int, n_epochs:int, draw = False):\n",
    "    #cannot rely solely on error values because pred might look different from target\n",
    "    alignments = []\n",
    "    all_mse = []\n",
    "    sigma = 0.3\n",
    "    patience = 20\n",
    "    counter = 0\n",
    "###DRAW\n",
    "    if draw:\n",
    "        fig, ax_list = plt.subplots(1,1)\n",
    "    #     ax_list = ax_list.flatten()\n",
    "        line, = ax_list.plot(xdos, pred[0], label = \"Aligned True\")\n",
    "        z, = ax_list.plot(xdos, pred[0], label = \"Prediction\")\n",
    "        ax_list.vlines(x = -2.3231, ymin = -0.05, ymax = 1, color = 'black')\n",
    "        fig.legend([line,z], labels = [\"Aligned True\", \"Prediction\"], loc = \"lower center\")\n",
    "\n",
    "    for i in tqdm(range(len(target_eigvals))):        \n",
    "        xdos_i = xdos\n",
    "        shift = torch.nn.parameter.Parameter(torch.tensor(0.))\n",
    "        best_mse = torch.tensor(1)\n",
    "        best_state = shift.clone()\n",
    "        opt_LBFGS = torch.optim.LBFGS([shift], lr = 100, line_search_fn = 'strong_wolfe')#, weight_decay = 0)\n",
    "        opt_adam = torch.optim.Adam([shift], lr = 1, weight_decay = 0)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_adam, factor = 0.1, patience = 20, threshold = 1e-7, min_lr = 0.01)\n",
    "        if draw:\n",
    "            z.set_ydata(pred[i].detach().numpy())\n",
    "        prev_mse = torch.tensor(1)\n",
    "        for epoch in range(n_epochs):            \n",
    "            opt_LBFGS.zero_grad()\n",
    "            def closure():\n",
    "                opt_LBFGS.zero_grad()\n",
    "                ldos_i = quartic_dos(target_eigvals[i] + shift, xdos_i, sigma)\n",
    "                ldos_i = ((ldos_i * normalization[i] ))* 2\n",
    "                mse = loss.t_get_mse(pred[i,:rbound], ldos_i[:rbound])\n",
    "                mse.backward()\n",
    "                return mse\n",
    "                            \n",
    "            \n",
    "            if epoch == 0:\n",
    "                opt_LBFGS.step(closure)\n",
    "            else:\n",
    "                opt_adam.step(closure)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                ldos_i = quartic_dos(target_eigvals[i] + shift, xdos_i, sigma)\n",
    "                ldos_i = ((ldos_i * normalization[i] ))* 2\n",
    "                mse = loss.t_get_mse(pred[i,:rbound], ldos_i[:rbound])\n",
    "                scheduler.step(mse)\n",
    "            if mse < best_mse:\n",
    "                \n",
    "                best_mse = mse.detach().clone()\n",
    "                best_state = shift.detach().clone()\n",
    "            \n",
    "            if mse < prev_mse * (1 - 1e-3):\n",
    "                counter = 0 \n",
    "            else:\n",
    "                counter +=1\n",
    "            prev_mse = mse\n",
    "#                 counter += 1\n",
    "#                 if counter >= patience:\n",
    "#                     shift = torch.nn.parameter.Parameter(torch.tensor(best_state))\n",
    "#                     counter = 0\n",
    "#             else:\n",
    "                \n",
    "##DRAW      \n",
    "            if draw:\n",
    "                ldos_i = quartic_dos(target_eigvals[i] + shift, xdos_i, sigma)\n",
    "                ldos_i = ((ldos_i * normalization[i] ))* 2\n",
    "                line.set_ydata(ldos_i.detach().numpy())\n",
    "                fig.suptitle(\"Epochs: {}, Shift: {:.3}, Best Shift: {:.3}, Current loss:{:.3}, Best Loss: {:.3}, LR: {}\".format(epoch, shift.item(), best_state.item(), mse.item(), best_mse.item(), opt_adam.param_groups[0]['lr']))\n",
    "                fig.canvas.draw()\n",
    "                fig.canvas.flush_events()\n",
    "            \n",
    "            \n",
    "            if mse < 1e-10:\n",
    "#                 print (\"break at lr: {}, mse : {}, epoch : {}, shift: {}\". format(opt.param_groups[0]['lr'], mse, epoch, shift.item()))\n",
    "                break\n",
    "            if best_mse.item() > 1e-5 and counter >= patience: #does not really work because i dont know when the error is unacceptable, maybe only applies to trained models?\n",
    "                shift = torch.nn.parameter.Parameter(best_state)\n",
    "                opt_adam = torch.optim.Adam([shift], lr = opt_adam.param_groups[0]['lr'], weight_decay = 0)\n",
    "                counter = 0\n",
    "                    \n",
    "            if opt_adam.param_groups[0]['lr'] < 0.1 and (counter >= patience or mse.item() < 1e-10):\n",
    "#                 print (\"break at lr: {}, mse : {}, epoch : {}, shift: {}\". format(opt.param_groups[0]['lr'], mse, epoch, shift.item()))\n",
    "                break\n",
    "\n",
    "\n",
    "        alignments.append(torch.tensor(best_state.item()))\n",
    "        ldos_i = quartic_dos(target_eigvals[i] + shift, xdos_i, sigma)\n",
    "        ldos_i = ((ldos_i * normalization_quartic[i] ))* 2\n",
    "        mse = loss.t_get_mse(pred[i,:rbound], ldos_i[:rbound])\n",
    "        all_mse.append(mse)\n",
    "                \n",
    "        \n",
    "    all_mse = torch.vstack(all_mse)\n",
    "    alignments = torch.vstack(alignments)\n",
    "    \n",
    "    return all_mse, alignments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4814218a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:47:57.369903Z",
     "start_time": "2023-03-27T19:47:57.369891Z"
    }
   },
   "outputs": [],
   "source": [
    "def MSE_shift_continuous(x_pred, target): #Should make the model repredict the DOS at a shifted energy value\n",
    "    alignments = torch.nn.parameter.Parameter(torch.zeros(len(target)))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a4d5be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:47:57.370759Z",
     "start_time": "2023-03-27T19:47:57.370749Z"
    }
   },
   "outputs": [],
   "source": [
    "def MSE_shift_fourier(x_pred, target):\n",
    "    alignments = torch.nn.parameter.Parameter(torch.zeros(len(target)))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f361688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_shift_continuous(pred, target): #shifts the prediction values, 1) want to extract the inner representation with a method. 2) modify the energy input values at the inner representation layer, 3) optimize the optimal alignment values \n",
    "    alignments = torch.nn.parameter.Parameter(torch.tensor(0.))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "854eb832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T10:19:22.666424Z",
     "start_time": "2023-03-27T10:19:19.942612Z"
    },
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1039/1039 [00:02<00:00, 385.95it/s]\n"
     ]
    }
   ],
   "source": [
    "##Generate shifted quartic dataset\n",
    "\n",
    "\n",
    "full_xdos = []\n",
    "shifted_full_ldos = []\n",
    "\n",
    "sigma = torch.tensor(0.3)\n",
    "# ndos = 778 #+ int(30/0.05)\n",
    "\n",
    "\n",
    "emin = -24.5537\n",
    "emax = 11.3464\n",
    "\n",
    "true_alignments = (torch.rand(1039)-0.5) * 4\n",
    "\n",
    "full_xdos = torch.arange(emin - 1.5, emax + 3,0.05)\n",
    "for i in tqdm(range(n_structures)):\n",
    "    #steps = int((rbounds[i].item()- (10 * sigma) - lbounds[i].item() - 1.5)/0.05)\n",
    "    #x_dos2 = torch.linspace(emin - 1.5, emax + 1.5,ndos)\n",
    "    shifted_full_ldos_i = quartic_dos(sorted_full_eigen_energies[i] + true_alignments[i], full_xdos, sigma)#torch.sum(torch.exp(-0.5*((x_dos - full_eigen_energies[i].view(-1,1))/sigma)**2), dim = 0)\n",
    "#     n_xdos2.append(x_dos2)\n",
    "    shifted_full_ldos.append(shifted_full_ldos_i)\n",
    "    \n",
    "#n_xdos2 = torch.vstack(n_xdos2)\n",
    "shifted_full_ldos = torch.vstack(shifted_full_ldos)\n",
    "shifted_full_ldos = ((shifted_full_ldos.T * normalization_quartic ).T)* 2\n",
    "\n",
    "#Do cutting here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14394287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T10:19:12.458430Z",
     "start_time": "2023-03-27T10:19:12.402681Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6445e81a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T11:55:07.887185Z",
     "start_time": "2023-03-27T11:42:17.206424Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1039/1039 [12:50<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "j = 1039\n",
    "\n",
    "mse3, shift3 = MSE_shift_discrete(shifted_full_ldos[i:i+j], sorted_full_eigen_energies[i:i+j], normalization_quartic[i:i+j], full_xdos, 479, 300, draw = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601047c9",
   "metadata": {},
   "source": [
    "## New Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8adcae37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:18:32.259427Z",
     "start_time": "2023-04-01T13:17:53.168262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e79f0a84a604189ae5e7f9b59143195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import rascaline\n",
    "from skcosmo.feature_selection import FPS\n",
    "import scipy\n",
    "\n",
    "HYPER_PARAMETERS = {\n",
    "    \"cutoff\": 4.0,#6.0,#4.0,\n",
    "    \"max_radial\": 8,#12,#8,\n",
    "    \"max_angular\": 6,#9,#6,\n",
    "    \"atomic_gaussian_width\": 0.45,\n",
    "    \"center_atom_weight\": 1.0,\n",
    "    \"radial_basis\":{\n",
    "        \"Gto\":{}\n",
    "    },\n",
    "    \"cutoff_function\":{\n",
    "        \"Step\":{}, #maybe \n",
    "    },\n",
    "    \"radial_scaling\":{\n",
    "        \"Willatt2018\":{\n",
    "        'exponent': 5,\n",
    "        'rate' : 1,\n",
    "        'scale' : 3.,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "calculator = rascaline.SoapPowerSpectrum(**HYPER_PARAMETERS)\n",
    "descriptors = calculator.compute(structures)\n",
    "descriptors.keys_to_samples(\"species_center\")\n",
    "descriptors.keys_to_properties([\"species_neighbor_1\", \"species_neighbor_2\"])\n",
    "\n",
    "\n",
    "\n",
    "n_refs = 200\n",
    "n_atoms = descriptors.block(0).values.shape[0]\n",
    "n_structures = np.unique(descriptors.block(0).samples[\"structure\"])\n",
    "feature = torch.zeros(len(n_structures), n_refs)\n",
    "atom_descriptors = torch.tensor(descriptors.block(0).values)\n",
    "atom_descriptors = torch.nn.functional.normalize(atom_descriptors, dim = 1)\n",
    "selector = FPS(n_to_select = n_refs,\n",
    "           progress_bar = True,\n",
    "           score_threshold = 1e-12,\n",
    "           full = False,\n",
    "           initialize = 0\n",
    "          )\n",
    "selector.fit(atom_descriptors.T)\n",
    "references = selector.transform(atom_descriptors.T).T\n",
    "atomkernel_descriptors = torch.pow(atom_descriptors @ references.T, 2)\n",
    "for structure_i in n_structures:\n",
    "    a_i = descriptors.block(0).samples[\"structure\"] == structure_i\n",
    "    feature[structure_i, :] = torch.sum(atomkernel_descriptors[a_i, :], axis = 0)/np.sum(a_i)\n",
    "\n",
    "kMM = references @ references.T\n",
    "rtkMM = scipy.linalg.sqrtm(kMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bf0843",
   "metadata": {},
   "source": [
    "## Linalg-Shift, Full dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94910032",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T13:17:02.766569Z",
     "start_time": "2023-04-01T13:17:02.753354Z"
    }
   },
   "outputs": [],
   "source": [
    "import dostools.loss.loss as loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "303456b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T14:02:14.664965Z",
     "start_time": "2023-04-01T14:02:14.659803Z"
    }
   },
   "outputs": [],
   "source": [
    "test_eigenenergies = [sorted_full_eigen_energies[i] for i in test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d6c9e22d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T12:09:00.681749Z",
     "start_time": "2023-04-03T12:08:30.131125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference training loss: 10.03\n",
      "Reference test loss : 11.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1:   2%|█▉                                                                                                | 1/50 [00:13<11:01, 13.51s/it, current_rmse=10, lowest_mse=7.36e-5, pred_loss=7.36e-5, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2:   4%|███▉                                                                                             | 2/50 [00:30<12:07, 15.15s/it, current_rmse=10.1, lowest_mse=7.36e-5, pred_loss=7.4e-5, trigger=1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m         train_ldos \u001b[38;5;241m=\u001b[39m train_ldos\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m loss_i\n\u001b[0;32m---> 79\u001b[0m     \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     train_ldos \u001b[38;5;241m=\u001b[39m train_ldos\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:183\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 183\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    186\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "Input \u001b[0;32mIn [75]\u001b[0m, in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m i_batch:\n\u001b[0;32m---> 70\u001b[0m     ldos_i \u001b[38;5;241m=\u001b[39m \u001b[43mquartic_dos\u001b[49m\u001b[43m(\u001b[49m\u001b[43msorted_full_eigen_energies\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malignment\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxdos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m normalization_quartic[i] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     71\u001b[0m     train_ldos[i] \u001b[38;5;241m=\u001b[39m ldos_i[:cutoff_index]            \n\u001b[1;32m     72\u001b[0m reg_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvstack([train_ldos, torch\u001b[38;5;241m.\u001b[39mzeros(n_col,train_ldos\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])])\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mquartic_dos\u001b[0;34m(energies, xdos, sigma)\u001b[0m\n\u001b[1;32m     13\u001b[0m     E \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp((energies\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m xdos[indexes]), \u001b[38;5;28mmin\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39m (np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m7\u001b[39m) \u001b[38;5;241m*\u001b[39m sigma), \u001b[38;5;28mmax\u001b[39m \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m7\u001b[39m) \u001b[38;5;241m*\u001b[39m sigma))\n\u001b[1;32m     14\u001b[0m     values \u001b[38;5;241m=\u001b[39m (E\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m7\u001b[39m \u001b[38;5;241m*\u001b[39m (sigma\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m ((\u001b[38;5;241m16\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m15\u001b[39m) \u001b[38;5;241m*\u001b[39m (np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m7\u001b[39m) \u001b[38;5;241m*\u001b[39m sigma)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#     output = -1 * output\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dostools.loss import loss\n",
    "#normal dataset\n",
    "\n",
    "batch_size = 64\n",
    "sigma = 0.3\n",
    "n_epochs = 50\n",
    "patience = 20\n",
    "\n",
    "index = train_index\n",
    "t_index = test_index\n",
    "\n",
    "Sampler = torch.utils.data.RandomSampler(index, replacement = False)\n",
    "Batcher = torch.utils.data.BatchSampler(Sampler, batch_size, False)\n",
    "\n",
    "Features = torch.hstack([feature[index].double(), torch.ones(len(index)).view(-1,1)])\n",
    "t_Features = torch.hstack([feature[t_index].double(), torch.ones(len(t_index)).view(-1,1)])\n",
    "# Features = torch.hstack([Silicon.Features['structure_avedescriptors'][index].double(), torch.ones(len(index)).view(-1,1)])\n",
    "# t_Features = torch.hstack([Silicon.Features['structure_avedescriptors'][t_index].double(), torch.ones(len(t_index)).view(-1,1)])\n",
    "alignment = torch.nn.parameter.Parameter(torch.zeros(len(index)))\n",
    "\n",
    "opt = torch.optim.Adam([alignment], lr = 1e-3, weight_decay = 0)\n",
    "# opt_LBFGS = torch.optim.LBFGS([alignment], lr = 1e-11, line_search_fn = 'strong_wolfe')\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor = 0.1, patience = 5, threshold = 1e-7, min_lr = 1e-5)\n",
    "\n",
    "xdos = n_xdos2\n",
    "cutoff = torch.max(efermi) + 3\n",
    "cutoff_index = torch.searchsorted(xdos, cutoff)\n",
    "\n",
    "# ldos = shifted_full_ldos[index,:cutoff_index].clone()#\n",
    "ldos = n_ldos2[index,:cutoff_index].clone()\n",
    "\n",
    "train_ldos = ldos.clone()\n",
    "\n",
    "best_mse = torch.tensor(100)\n",
    "best_state = alignment.clone()\n",
    "\n",
    "n_col = Features.shape[1]\n",
    "regularization = 1\n",
    "\n",
    "reg = torch.hstack([torch.real(torch.tensor(regularization * rtkMM)), torch.zeros(rtkMM.shape[0]).view(-1,1)])\n",
    "reg = torch.vstack([reg, torch.zeros(n_col)])\n",
    "\n",
    "\n",
    "reg_features = torch.vstack([Features, reg])\n",
    "reg_target = torch.vstack([train_ldos, torch.zeros(n_col,train_ldos.shape[1])])\n",
    "reference_weights = torch.linalg.lstsq(reg_features, reg_target, driver = \"gelsd\", rcond = 1e-10).solution\n",
    "reference_pred = Features @ reference_weights\n",
    "reference_t_pred = t_Features @ reference_weights\n",
    "\n",
    "train_loss = loss.t_get_rmse(reference_pred, ldos, xdos[:cutoff_index], perc = True)\n",
    "test_loss = loss.t_get_rmse(reference_t_pred, n_ldos2[t_index,:cutoff_index], xdos[:cutoff_index], perc = True)\n",
    "current_rmse = torch.tensor(100)\n",
    "pred_loss = torch.tensor(100)\n",
    "prev_loss = torch.tensor(100)\n",
    "trigger = 0\n",
    "print (\"Reference training loss: {:.4}\".format(train_loss))\n",
    "print (\"Reference test loss : {:.4}\".format(test_loss))\n",
    "\n",
    "\n",
    "pbar = tqdm(range(n_epochs))\n",
    "for epoch in pbar:\n",
    "    pbar.set_description(f\"Epoch: {epoch}\")\n",
    "    pbar.set_postfix(pred_loss = pred_loss.item(), lowest_mse = best_mse.item(), current_rmse = current_rmse.item(), trigger = trigger)\n",
    "    \n",
    "    for i_batch in Batcher:\n",
    "        def closure():\n",
    "            global train_ldos\n",
    "            opt.zero_grad()\n",
    "            for i in i_batch:\n",
    "                ldos_i = quartic_dos(sorted_full_eigen_energies[index[i]] + alignment[i], xdos, sigma) * normalization_quartic[i] * 2\n",
    "                train_ldos[i] = ldos_i[:cutoff_index]            \n",
    "            reg_target = torch.vstack([train_ldos, torch.zeros(n_col,train_ldos.shape[1])])\n",
    "            train_weights = torch.linalg.lstsq(reg_features, reg_target, driver = \"gelsd\").solution\n",
    "            train_pred = Features @ train_weights\n",
    "            loss_i = loss.t_get_mse(train_pred, train_ldos)\n",
    "            loss_i.backward(inputs = alignment)\n",
    "            train_ldos = train_ldos.detach()\n",
    "            return loss_i\n",
    "        opt.step(closure)\n",
    "        train_ldos = train_ldos.detach()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        train_ldos = []\n",
    "        for i in range(len(index)):  \n",
    "            l_dosi = quartic_dos(sorted_full_eigen_energies[index[i]] + alignment[i], xdos, sigma)\n",
    "            \n",
    "    #     n_xdos2.append(x_dos2)\n",
    "            train_ldos.append(l_dosi[:cutoff_index])\n",
    "    \n",
    "    # n_xdos2 = torch.vstack(n_xdos2)\n",
    "        train_ldos = torch.vstack(train_ldos)\n",
    "        train_ldos = ((train_ldos.T * normalization_quartic[index] ).T)* 2\n",
    "        reg_target = torch.vstack([train_ldos, torch.zeros(n_col,train_ldos.shape[1])])\n",
    "        weights_i = torch.linalg.lstsq(reg_features, reg_target, driver = \"gelsd\").solution\n",
    "        pred_i = Features @ weights_i\n",
    "\n",
    "        i_loss = loss.t_get_mse(pred_i, train_ldos)\n",
    "        i_rmse = loss.t_get_rmse(pred_i, train_ldos, xdos[:cutoff_index], perc = True)\n",
    "    \n",
    "    \n",
    "        pred_loss = i_loss\n",
    "        if i_loss < prev_loss * (1 + 1e-3): \n",
    "            trigger = 0\n",
    "        else:\n",
    "            trigger +=1 \n",
    "            if trigger >= patience:\n",
    "                alignment = torch.nn.parameter.Parameter(best_state)\n",
    "                opt = torch.optim.Adam([alignment], lr = opt.param_groups[0]['lr'], weight_decay = 0)\n",
    "                opt_LBFGS = torch.optim.LBFGS([alignment], lr = opt_LBFGS.param_groups[0]['lr'], line_search_fn = 'strong_wolfe')\n",
    "                counter = 0\n",
    "\n",
    "        if i_loss < best_mse:\n",
    "            best_mse = i_loss\n",
    "            best_state = alignment.clone()\n",
    "            print (\"This is the best state\")\n",
    "\n",
    "        prev_loss = i_loss\n",
    "        current_rmse = i_rmse\n",
    "\n",
    "#         scheduler.step(i_loss)\n",
    "\n",
    "#         if opt.param_groups[0]['lr'] < 1e-4:\n",
    "#             break\n",
    "\n",
    "best_state = torch.zeros(len(index))\n",
    "shifted_ldos = []\n",
    "for i in range(len(index)):\n",
    "    shifted_ldos_i = quartic_dos(sorted_full_eigen_energies[index[i]] + torch.clamp(best_state[i], -3,3), xdos, sigma)[:cutoff_index]\n",
    "    shifted_ldos.append(shifted_ldos_i)\n",
    "    \n",
    "shifted_ldos = torch.vstack(shifted_ldos)\n",
    "shifted_ldos = ((shifted_ldos.T * normalization_quartic[index]).T) * 2\n",
    "shifted_reg_target = torch.vstack([shifted_ldos, torch.zeros(n_col,shifted_ldos.shape[1])])\n",
    "shifted_weights = torch.linalg.lstsq(reg_features, shifted_reg_target, driver = \"gelsd\", rcond = 1e-10).solution\n",
    "shifted_preds = Features @ shifted_weights\n",
    "shifted_t_preds = t_Features @ shifted_weights\n",
    "\n",
    "\n",
    "shifted_train_loss = loss.t_get_rmse(shifted_preds, shifted_ldos, xdos[:cutoff_index], perc = True)\n",
    "# shifted_test_loss = MSE_shift_discrete(shifted_t_preds, test_eigenenergies, normalization[test_index], xdos, cutoff_index, 300) #Need the one with the new loss function\n",
    "\n",
    "\n",
    "print (\"Final training loss: {:.4}\".format(shifted_train_loss))\n",
    "# print (\"Final test loss: {:.4}\".format(shifted_test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "90b23a8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-01T14:23:23.162947Z",
     "start_time": "2023-04-01T14:23:23.158605Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fix target regeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "b30fe43a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T11:01:18.215544Z",
     "start_time": "2023-03-31T11:01:15.504414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training loss: 2.507\n"
     ]
    }
   ],
   "source": [
    "shifted_ldos = []\n",
    "for i in range(len(index)):\n",
    "    shifted_ldos_i = quartic_dos(sorted_full_eigen_energies[index[i]] + torch.clamp(best_state[i], -3,3), xdos, sigma)\n",
    "    shifted_ldos.append(shifted_ldos_i)\n",
    "    \n",
    "shifted_ldos = torch.vstack(shifted_ldos)\n",
    "shifted_ldos = ((shifted_ldos.T * normalization_quartic[index]).T) * 2\n",
    "\n",
    "shifted_weights = torch.linalg.lstsq(Features, shifted_ldos[:,:cutoff_index], driver = \"gelsd\").solution\n",
    "shifted_preds = Features @ shifted_weights\n",
    "shifted_t_preds = t_Features @ shifted_weights\n",
    "\n",
    "\n",
    "shifted_train_loss = loss.t_get_rmse(shifted_preds, shifted_ldos[:,:cutoff_index], xdos[:cutoff_index], perc = True)\n",
    "# shifted_test_loss = loss.t_get_rmse(shifted_t_preds, shifted_ldos, xdos, perc = True) Need the one with the new loss function\n",
    "\n",
    "print (\"Final training loss: {:.4}\".format(shifted_train_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "87fc2102",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T11:02:23.797701Z",
     "start_time": "2023-03-31T11:02:23.647018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference training loss: 8.175\n",
      "Reference test loss : 10.08\n"
     ]
    }
   ],
   "source": [
    "regularization = 0\n",
    "reg = regularization * torch.eye(n_col)\n",
    "reg[n_col-1, n_col-1] = 0\n",
    "reg_features = Features.T @ Features + reg\n",
    "reference_weights = torch.linalg.lstsq(reg_features, Features.T @ n_ldos2[index,:cutoff_index], driver = \"gelsd\").solution\n",
    "reference_pred = Features @ reference_weights\n",
    "reference_t_pred = t_Features @ reference_weights\n",
    "\n",
    "train_loss = loss.t_get_rmse(reference_pred, n_ldos2[index, :cutoff_index], xdos[:cutoff_index], perc = True)\n",
    "test_loss = loss.t_get_rmse(reference_t_pred, n_ldos2[t_index,:cutoff_index], xdos[:cutoff_index], perc = True)\n",
    "current_rmse = torch.tensor(100)\n",
    "pred_loss = torch.tensor(100)\n",
    "prev_loss = torch.tensor(100)\n",
    "trigger = 0\n",
    "print (\"Reference training loss: {:.4}\".format(train_loss))\n",
    "print (\"Reference test loss : {:.4}\".format(test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "554fa3e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T11:10:14.010027Z",
     "start_time": "2023-03-31T11:10:14.003770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1001, 524])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "6f8dc4ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T11:10:21.169842Z",
     "start_time": "2023-03-31T11:10:21.163664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([831, 1001])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "b41b01e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T11:22:47.977804Z",
     "start_time": "2023-03-31T11:22:47.970391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1001, 524])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02731133",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "4a3ec570",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T12:22:09.952516Z",
     "start_time": "2023-03-31T12:22:09.868466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.9378e+23)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.cond(Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "ccec8362",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T13:47:03.992097Z",
     "start_time": "2023-03-31T13:47:03.786711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training loss: 5.389\n"
     ]
    }
   ],
   "source": [
    "Features = torch.hstack([Silicon.Features['structure_avekerneldescriptors'][index].double(), torch.ones(len(index)).view(-1,1)])\n",
    "t_Features = torch.hstack([Silicon.Features['structure_avekerneldescriptors'][t_index].double(), torch.ones(len(t_index)).view(-1,1)])\n",
    "\n",
    "\n",
    "matinv = torch.linalg.inv(Features.T @ Features)\n",
    "weight = matinv @ Features.T @ n_ldos2[index,:cutoff_index]\n",
    "\n",
    "shifted_weights = torch.linalg.lstsq(Features.T @ Features, Features.T @ n_ldos2[index,:cutoff_index], driver = \"gelsd\", rcond = 1e-15).solution\n",
    "shifted_preds = Features @ shifted_weights\n",
    "# shifted_preds2 = Features @ weight\n",
    "\n",
    "\n",
    "shifted_train_loss = loss.t_get_rmse(shifted_preds, n_ldos2[index,:cutoff_index], xdos[:cutoff_index], perc = True)\n",
    "shifted_train_loss2 = loss.t_get_rmse(shifted_preds2, n_ldos2[index,:cutoff_index], xdos[:cutoff_index], perc = True)\n",
    "\n",
    "# shifted_test_loss = loss.t_get_rmse(shifted_t_preds, shifted_ldos, xdos, perc = True) Need the one with the new loss function\n",
    "\n",
    "print (\"Final training loss: {:.4}\".format(shifted_train_loss))\n",
    "# print (\"Final training loss2: {:.4}\".format(shifted_train_loss2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "4694f0ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T11:01:32.275844Z",
     "start_time": "2023-03-31T11:01:32.115502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference training loss: 11.7\n",
      "Reference test loss : 10.08\n"
     ]
    }
   ],
   "source": [
    "regularization = 0\n",
    "reg = regularization * torch.eye(n_col)\n",
    "reg[n_col-1, n_col-1] = 0\n",
    "reg_features = Features.T @ Features + reg\n",
    "reference_weights = torch.linalg.lstsq(reg_features, Features.T @ shifted_ldos[:, :cutoff_index], driver = \"gelsd\").solution\n",
    "reference_pred = Features @ reference_weights\n",
    "reference_t_pred = t_Features @ reference_weights\n",
    "\n",
    "train_loss = loss.t_get_rmse(reference_pred, shifted_ldos[:, :cutoff_index], xdos[:cutoff_index], perc = True)\n",
    "current_rmse = torch.tensor(100)\n",
    "pred_loss = torch.tensor(100)\n",
    "prev_loss = torch.tensor(100)\n",
    "trigger = 0\n",
    "print (\"Reference training loss: {:.4}\".format(train_loss))\n",
    "print (\"Reference test loss : {:.4}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "33838e1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T10:14:17.836274Z",
     "start_time": "2023-03-31T10:14:17.831220Z"
    }
   },
   "outputs": [],
   "source": [
    "alignment_1 = best_state.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "143cec57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T12:11:23.906748Z",
     "start_time": "2023-03-29T12:11:23.872441Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "trapezoid: There must be one `x` value for each sample point",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [242]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m i_rmse \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt_get_rmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ldos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxdos\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcutoff_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dostools/src/dostools/loss/loss.py:38\u001b[0m, in \u001b[0;36mt_get_rmse\u001b[0;34m(a, b, xdos, perc)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xdos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a\u001b[38;5;241m.\u001b[39msize()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 38\u001b[0m         rmse \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt((\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrapezoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxdos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m         rmse \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt((torch\u001b[38;5;241m.\u001b[39mtrapezoid((a \u001b[38;5;241m-\u001b[39m b)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, xdos, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mmean())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: trapezoid: There must be one `x` value for each sample point"
     ]
    }
   ],
   "source": [
    "i_rmse = loss.t_get_rmse(pred_i, train_ldos, xdos[:cutoff_index], perc = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "93198ded",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T12:11:52.271104Z",
     "start_time": "2023-03-29T12:11:52.264701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(524)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c6df9c89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T12:11:36.660547Z",
     "start_time": "2023-03-29T12:11:36.654357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([831, 839])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ad443af0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T12:11:42.276878Z",
     "start_time": "2023-03-29T12:11:42.270808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([831, 839])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ldos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f310d09d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:21:16.375671Z",
     "start_time": "2023-03-28T18:14:55.033259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference training loss: 3.98\n",
      "Reference test loss : 39.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:   0%|                                                                                                              | 0/10000 [06:19<?, ?it/s, current_rmse=100, lowest_mse=100, pred_loss=100, trigger=0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [144]\u001b[0m, in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         train_ldos \u001b[38;5;241m=\u001b[39m train_ldos\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m loss_i\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     train_ldos \u001b[38;5;241m=\u001b[39m train_ldos\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:426\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directional_evaluate(closure, x, t, d)\n\u001b[0;32m--> 426\u001b[0m     loss, flat_grad, t, ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[43m_strong_wolfe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[1;32m    429\u001b[0m opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:148\u001b[0m, in \u001b[0;36m_strong_wolfe\u001b[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[1;32m    145\u001b[0m     insuf_progress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Evaluate new point\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m f_new, g_new \u001b[38;5;241m=\u001b[39m \u001b[43mobj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m ls_func_evals \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    150\u001b[0m gtd_new \u001b[38;5;241m=\u001b[39m g_new\u001b[38;5;241m.\u001b[39mdot(d)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:424\u001b[0m, in \u001b[0;36mLBFGS.step.<locals>.obj_func\u001b[0;34m(x, t, d)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[0;32m--> 424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_directional_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:277\u001b[0m, in \u001b[0;36mLBFGS._directional_evaluate\u001b[0;34m(self, closure, x, t, d)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_directional_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure, x, t, d):\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(closure())\n\u001b[1;32m    279\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:265\u001b[0m, in \u001b[0;36mLBFGS._add_grad\u001b[0;34m(self, step_size, update)\u001b[0m\n\u001b[1;32m    263\u001b[0m     numel \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;66;03m# view as to avoid deprecated pointwise semantics\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m[\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m:\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m     offset \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numel\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m offset \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numel()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#normal dataset\n",
    "\n",
    "batch_size = 831\n",
    "sigma = 0.3\n",
    "n_epochs = 10000\n",
    "patience = 20\n",
    "\n",
    "index = train_index\n",
    "t_index = test_index\n",
    "\n",
    "Sampler = torch.utils.data.RandomSampler(index, replacement = False)\n",
    "Batcher = torch.utils.data.BatchSampler(Sampler, batch_size, False)\n",
    "\n",
    "Features = torch.hstack([Silicon.Features['structure_avedescriptors'][index].double(), torch.ones(len(index)).view(-1,1)])\n",
    "t_Features = torch.hstack([Silicon.Features['structure_avedescriptors'][t_index].double(), torch.ones(len(t_index)).view(-1,1)])\n",
    "alignment = torch.nn.parameter.Parameter(torch.zeros(len(index)))\n",
    "\n",
    "#opt = torch.optim.Adam([alignment], lr = 0.01, weight_decay = 0)\n",
    "opt = torch.optim.LBFGS([alignment], lr = 100, line_search_fn = 'strong_wolfe')\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor = 0.1, patience = 50, threshold = 1e-7, min_lr = 0.00001)\n",
    "\n",
    "xdos = n_xdos2\n",
    "ldos = n_ldos2[index].clone()\n",
    "\n",
    "train_ldos = ldos.clone()\n",
    "\n",
    "best_mse = torch.tensor(100)\n",
    "best_state = alignment.clone()\n",
    "\n",
    "reference_weights = torch.linalg.lstsq(Features, ldos, driver = \"gelsd\").solution\n",
    "reference_pred = Features @ reference_weights\n",
    "reference_t_pred = t_Features @ reference_weights\n",
    "\n",
    "train_loss = loss.t_get_rmse(reference_pred, ldos, xdos, perc = True)\n",
    "test_loss = loss.t_get_rmse(reference_t_pred, n_ldos2[t_index], xdos, perc = True)\n",
    "current_rmse = torch.tensor(100)\n",
    "pred_loss = torch.tensor(100)\n",
    "prev_loss = torch.tensor(100)\n",
    "trigger = 0\n",
    "print (\"Reference training loss: {:.4}\".format(train_loss))\n",
    "print (\"Reference test loss : {:.4}\".format(test_loss))\n",
    "pbar = tqdm(range(n_epochs))\n",
    "\n",
    "for epoch in pbar:\n",
    "    pbar.set_description(f\"Epoch: {epoch}\")\n",
    "    pbar.set_postfix(pred_loss = pred_loss.item(), lowest_mse = best_mse.item(), current_rmse = current_rmse.item(), trigger = trigger)\n",
    "    \n",
    "    for i_batch in Batcher:\n",
    "        def closure():\n",
    "            global train_ldos\n",
    "            opt.zero_grad()\n",
    "            for i in i_batch:\n",
    "                ldos_i = quartic_dos(sorted_full_eigen_energies[index[i]] + torch.clamp(alignment[i], -3 , 3), xdos, sigma) * normalization_quartic[i] * 2\n",
    "                train_ldos[i] = ldos_i\n",
    "            train_weights = torch.linalg.lstsq(Features, train_ldos, driver = \"gelsd\").solution\n",
    "            train_pred = Features @ train_weights        \n",
    "            loss_i = loss.t_get_mse(train_pred, train_ldos)\n",
    "            loss_i.backward(inputs = alignment)\n",
    "            train_ldos = train_ldos.detach()\n",
    "            return loss_i\n",
    "        opt.step(closure)\n",
    "        train_ldos = train_ldos.detach()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        n_ldos = []\n",
    "        for i in range(len(index)):  \n",
    "            l_dosi = quartic_dos(sorted_full_eigen_energies[index[i]] + torch.clamp(alignment[i], -3 , 3), xdos, sigma)\n",
    "            \n",
    "    #     n_xdos2.append(x_dos2)\n",
    "            n_ldos.append(l_dosi)\n",
    "    \n",
    "    # n_xdos2 = torch.vstack(n_xdos2)\n",
    "        n_ldos = torch.vstack(n_ldos)\n",
    "        n_ldos = ((n_ldos.T * normalization_quartic[index] ).T)* 2\n",
    "\n",
    "        weights_i = torch.linalg.lstsq(Features, n_ldos, driver = \"gelsd\").solution\n",
    "        pred_i = Features @ weights_i\n",
    "\n",
    "        i_loss = loss.t_get_mse(pred_i, n_ldos)\n",
    "        i_rmse = loss.t_get_rmse(pred_i, n_ldos, xdos, perc = True)\n",
    "    \n",
    "    \n",
    "        pred_loss = i_loss\n",
    "        if i_loss < prev_loss * (1 - 1e-3): \n",
    "            trigger = 0\n",
    "        else:\n",
    "            trigger +=1 \n",
    "            if trigger >= patience:\n",
    "                alignment = torch.nn.parameter.Parameter(best_state)\n",
    "                opt = torch.optim.Adam([alignment], lr = opt.param_groups[0]['lr'], weight_decay = 0)\n",
    "                counter = 0\n",
    "\n",
    "        if i_loss < best_mse:\n",
    "            best_mse = i_loss\n",
    "            best_state = alignment.clone()\n",
    "\n",
    "        prev_loss = i_loss\n",
    "        current_rmse = i_rmse\n",
    "\n",
    "        scheduler.step(i_loss)\n",
    "\n",
    "        if opt.param_groups[0]['lr'] < 0.0001:\n",
    "            break\n",
    "\n",
    "            \n",
    "shifted_ldos = []\n",
    "for i in range(len(index)):\n",
    "    shifted_ldos_i = quartic_dos(sorted_full_eigen_energies[index[i]] + torch.clamp(best_state[i], -3,3), xdos, sigma)\n",
    "    shifted_ldos.append(shifted_ldos_i)\n",
    "    \n",
    "shifted_ldos = torch.vstack(shifted_ldos)\n",
    "shifted_ldos = ((shifted_ldos.T * normalization_quartic[index]).T) * 2\n",
    "\n",
    "shifted_weights = torch.linalg.lstsq(Features, shifted_ldos, driver = \"gelsd\").solution\n",
    "shifted_preds = Features @ shifted_weights\n",
    "shifted_t_preds = t_Features @ shifted_weights\n",
    "\n",
    "\n",
    "shifted_train_loss = loss.t_get_rmse(shifted_preds, shifted_ldos, xdos, perc = True)\n",
    "# shifted_test_loss = loss.t_get_rmse(shifted_t_preds, shifted_ldos, xdos, perc = True) Need the one with the new loss function\n",
    "\n",
    "print (\"Final training loss: {:.4}\".format(shifted_train_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de674a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T20:39:13.422980Z",
     "start_time": "2023-03-27T20:39:13.422965Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#Biased dataset, fix the indexing issues\n",
    "\n",
    "sigma = 0.3\n",
    "n_epochs = 10000\n",
    "\n",
    "index = biased_train_index\n",
    "t_index = biased_test_index\n",
    "\n",
    "Features = torch.hstack([Silicon.Features['structure_avedescriptors'][index].double(), torch.ones(len(index)).view(-1,1)])\n",
    "\n",
    "t_Features = torch.hstack([Silicon.Features['structure_avedescriptors'][t_index].double(), torch.ones(len(t_index)).view(-1,1)])\n",
    "\n",
    "biased_alignment = torch.nn.parameter.Parameter(torch.zeros(len(index)))\n",
    "opt = torch.optim.Adam([biased_alignment], lr = 0.5, weight_decay = 0)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor = 0.1, patience = 20, threshold = 1e-7, min_lr = 0.001)\n",
    "\n",
    "xdos = n_xdos2\n",
    "ldos = n_ldos2[index]\n",
    "\n",
    "best_mse = torch.tensor(100)\n",
    "best_state = alignment.clone()\n",
    "\n",
    "reference_weights = torch.linalg.lstsq(Features, ldos, driver = \"gelsd\").solution\n",
    "reference_pred = Features @ reference_weights\n",
    "reference_t_pred = t_Features @ reference_weights\n",
    "\n",
    "train_loss = loss.t_get_rmse(reference_pred, ldos, xdos, perc = True)\n",
    "test_loss = loss.t_get_rmse(reference_t_pred, n_ldos2[t_index], xdos, perc = True)\n",
    "current_rmse = torch.tensor(100)\n",
    "pred_loss = torch.tensor(100)\n",
    "prev_loss = torch.tensor(100)\n",
    "trigger = 0\n",
    "print (\"Reference training loss: {:.4}\".format(train_loss))\n",
    "print (\"Reference test loss : {:.4}\".format(test_loss))\n",
    "pbar = tqdm(range(n_epochs))\n",
    "for epoch in pbar:\n",
    "    pbar.set_description(f\"Epoch: {epoch}\")\n",
    "    pbar.set_postfix(pred_loss = pred_loss.item(), lowest_mse = best_mse.item(), current_rmse = current_rmse.item(), trigger = trigger)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    n_ldos = []\n",
    "    for i in range(len(index)):  \n",
    "        l_dosi = quartic_dos(sorted_full_eigen_energies[i] + biased_alignment[i], xdos, sigma)\n",
    "#     n_xdos2.append(x_dos2)\n",
    "        n_ldos.append(l_dosi)\n",
    "    \n",
    "    # n_xdos2 = torch.vstack(n_xdos2)\n",
    "    n_ldos = torch.vstack(n_ldos)\n",
    "    n_ldos = ((n_ldos.T * normalization_quartic[index] ).T)* 2\n",
    "    \n",
    "    weights_i = torch.linalg.lstsq(Features, n_ldos, driver = \"gelsd\").solution\n",
    "    pred_i = Features @ weights_i\n",
    "    \n",
    "    i_loss = loss.t_get_mse(pred_i, n_ldos)\n",
    "    i_rmse = loss.t_get_rmse(pred_i, n_ldos, xdos, perc = True)\n",
    "    \n",
    "    i_loss.backward()\n",
    "    pred_loss = i_loss\n",
    "    if i_loss < prev_loss * (1 - 1e-3): \n",
    "        trigger = 0\n",
    "    else:\n",
    "        trigger +=1 \n",
    "        if trigger >= patience:\n",
    "            alignment = torch.nn.parameter.Parameter(best_state)\n",
    "            opt = torch.optim.Adam([shift], lr = opt.param_groups[0]['lr'], weight_decay = 0)\n",
    "            counter = 0\n",
    "            \n",
    "    if i_loss < best_mse:\n",
    "        best_mse = i_loss\n",
    "        best_state = alignment.clone()\n",
    "        \n",
    "    prev_loss = i_loss\n",
    "    current_rmse = i_rmse\n",
    "    \n",
    "    opt.step()\n",
    "    scheduler.step(i_loss)\n",
    "    torch.clamp(alignment, min = -3, max = 3)\n",
    "    \n",
    "    if opt.param_groups[0]['lr'] < 0.01:\n",
    "        break\n",
    "shifted_ldos = []\n",
    "for i in range(n_structures):\n",
    "    shifted_ldos_i = quartic_dos(sorted_full_eigen_energies[i] + best_state[i], xdos, sigma)\n",
    "    shifted_ldos.append(shifted_ldos_i)\n",
    "    \n",
    "shifted_ldos = torch.vstack(shifted_ldos)\n",
    "shifted_ldos = ((shifted_ldos.T * normalization_quartic).T) * 2\n",
    "\n",
    "shifted_weights = torch.linalg.lstsq(Features, shifted_ldos[index], driver = \"gelsd\").solution\n",
    "shifted_preds = Features @ shifted_weights\n",
    "shifted_t_preds = t_Features @ shifted_weights\n",
    "\n",
    "\n",
    "shifted_train_loss = loss.t_get_rmse(shifted_preds, shifted_ldos, xdos, perc = True)\n",
    "shifted_test_loss = loss.t_get_rmse(shifted_t_preds, shifted_ldos, xdos, perc = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9f7244c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T20:12:06.522293Z",
     "start_time": "2023-03-27T20:12:06.510189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.0065, grad_fn=<UnbindBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(biased_alignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d0f9f",
   "metadata": {},
   "source": [
    "## Linalg-Shift, fixed interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9963ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal dataset\n",
    "\n",
    "sigma = 0.3\n",
    "n_epochs = 10000\n",
    "patience = 20\n",
    "\n",
    "index = train_index\n",
    "t_index = test_index\n",
    "\n",
    "cutoff_index = \n",
    "\n",
    "Features = torch.hstack([Silicon.Features['structure_avedescriptors'][index].double(), torch.ones(len(index)).view(-1,1)])\n",
    "t_Features = torch.hstack([Silicon.Features['structure_avedescriptors'][t_index].double(), torch.ones(len(t_index)).view(-1,1)])\n",
    "alignment = torch.nn.parameter.Parameter(torch.zeros(len(index)))\n",
    "\n",
    "opt = torch.optim.Adam([alignment], lr = 1, weight_decay = 0)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor = 0.1, patience = 20, threshold = 1e-7, min_lr = 0.001)\n",
    "\n",
    "xdos = n_xdos2\n",
    "ldos = n_ldos2[train_index]\n",
    "\n",
    "best_mse = torch.tensor(100)\n",
    "best_state = alignment.clone()\n",
    "\n",
    "reference_weights = torch.linalg.lstsq(Features, ldos, driver = \"gelsd\").solution\n",
    "reference_pred = Features @ reference_weights\n",
    "reference_t_pred = t_Features @ reference_weights\n",
    "\n",
    "train_loss = loss.t_get_rmse(reference_pred, ldos, xdos, perc = True)\n",
    "test_loss = loss.t_get_rmse(reference_t_pred, n_ldos2[t_index], xdos, perc = True)\n",
    "current_rmse = torch.tensor(100)\n",
    "pred_loss = torch.tensor(100)\n",
    "prev_loss = torch.tensor(100)\n",
    "trigger = 0\n",
    "print (\"Reference training loss: {:.4}\".format(train_loss))\n",
    "print (\"Reference test loss : {:.4}\".format(test_loss))\n",
    "pbar = tqdm(range(n_epochs))\n",
    "for epoch in pbar:\n",
    "    pbar.set_description(f\"Epoch: {epoch}\")\n",
    "    pbar.set_postfix(pred_loss = pred_loss.item(), lowest_mse = best_mse.item(), current_rmse = current_rmse.item(), trigger = trigger)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    n_ldos = []\n",
    "    for i in range(len(index)):  \n",
    "        l_dosi = quartic_dos(sorted_full_eigen_energies[i] + alignment[i], xdos, sigma)\n",
    "#     n_xdos2.append(x_dos2)\n",
    "        n_ldos.append(l_dosi)\n",
    "    \n",
    "    # n_xdos2 = torch.vstack(n_xdos2)\n",
    "    n_ldos = torch.vstack(n_ldos)\n",
    "    n_ldos = ((n_ldos.T * normalization_quartic[index] ).T)* 2\n",
    "    \n",
    "    weights_i = torch.linalg.lstsq(Features, n_ldos, driver = \"gelsd\").solution\n",
    "    pred_i = Features @ weights_i\n",
    "    \n",
    "    i_loss = loss.t_get_mse(pred_i, n_ldos)\n",
    "    i_rmse = loss.t_get_rmse(pred_i, n_ldos, xdos, perc = True)\n",
    "    \n",
    "    \n",
    "    pred_loss = i_loss\n",
    "    if i_loss < prev_loss * (1 - 1e-3): \n",
    "        trigger = 0\n",
    "    else:\n",
    "        trigger +=1 \n",
    "        if trigger >= patience:\n",
    "            alignment = torch.nn.parameter.Parameter(best_state)\n",
    "            opt = torch.optim.Adam([shift], lr = opt.param_groups[0]['lr'], weight_decay = 0)\n",
    "            counter = 0\n",
    "            \n",
    "    if i_loss < best_mse:\n",
    "        best_mse = i_loss\n",
    "        best_state = alignment.clone()\n",
    "        \n",
    "    prev_loss = i_loss\n",
    "    current_rmse = i_rmse\n",
    "    \n",
    "    opt.step()\n",
    "    scheduler.step(i_loss)\n",
    "    \n",
    "    if opt.param_groups[0]['lr'] < 0.01:\n",
    "        break\n",
    "shifted_ldos = []\n",
    "for i in range(n_structures):\n",
    "    shifted_ldos_i = quartic_dos(sorted_full_eigen_energies[i] + best_state[i], xdos, sigma)\n",
    "    shifted_ldos.append(shifted_ldos_i)\n",
    "    \n",
    "shifted_ldos = torch.vstack(shifted_ldos)\n",
    "shifted_ldos = ((shifted_ldos.T * normalization_quartic).T) * 2\n",
    "\n",
    "shifted_weights = torch.linalg.lstsq(Features, shifted_ldos[index], driver = \"gelsd\").solution\n",
    "shifted_preds = Features @ shifted_weights\n",
    "shifted_t_preds = t_Features @ shifted_weights\n",
    "\n",
    "\n",
    "shifted_train_loss = loss.t_get_rmse(shifted_preds, shifted_ldos, xdos, perc = True)\n",
    "shifted_test_loss = loss.t_get_rmse(shifted_t_preds, shifted_ldos, xdos, perc = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f0e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c137b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a7c3061",
   "metadata": {},
   "source": [
    "## Linalg-Shift, variable interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b711cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "759px",
    "left": "26px",
    "top": "111.133px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
