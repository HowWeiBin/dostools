{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "2408af2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T21:37:53.210815Z",
     "start_time": "2023-04-18T21:37:53.203400Z"
    }
   },
   "outputs": [],
   "source": [
    "import dostools\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import time\n",
    "import scipy \n",
    "import copy\n",
    "torch.set_default_dtype(torch.float64) \n",
    "# %matplotlib notebook\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "db388414",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T20:03:27.066912Z",
     "start_time": "2023-04-18T20:03:26.980336Z"
    }
   },
   "outputs": [],
   "source": [
    "import dostools.datasets.data as data\n",
    "import dostools.utils.utils as utils\n",
    "\n",
    "n_structures = 1039\n",
    "np.random.seed(0)\n",
    "n_train = int(0.8 * n_structures)\n",
    "train_index = np.arange(n_structures)\n",
    "np.random.shuffle(train_index)\n",
    "test_index = train_index[n_train:]\n",
    "train_index = train_index[:n_train]\n",
    "\n",
    "with torch.no_grad():\n",
    "#     sigma = 0.3\n",
    "#     structures = data.load_structures(\":\")\n",
    "#     n_structures = len(structures) #total number of structures\n",
    "#     for structure in structures:#implement periodicity\n",
    "#         structure.wrap(eps = 1e-12) \n",
    "#     n_atoms = np.zeros(n_structures, dtype = int) #stores number of atoms in each structures\n",
    "#     for i in range(n_structures):\n",
    "#         n_atoms[i] = len(structures[i])\n",
    "        \n",
    "    xdos = torch.tensor(data.load_xdos())\n",
    "    ldos3 = torch.tensor(data.load_ldos())\n",
    "    ldos3 *= 2\n",
    "    \n",
    "    kMM_200 = torch.load(\"./kMM200.pt\")\n",
    "    SOAP = torch.load(\"./Soap.pt\")\n",
    "    KERNEL = torch.load(\"./kernel200.pt\")\n",
    "    ldos1 = torch.load(\"./ldos_01.pt\")\n",
    "    \n",
    "    biased_train_index = np.load(\"./biased_train_index.npy\")\n",
    "    biased_test_index = np.load(\"./biased_test_index.npy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3875df03",
   "metadata": {},
   "source": [
    "## Generate cluster-less index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "2f3e79a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:01:08.751856Z",
     "start_time": "2023-04-19T16:01:08.739512Z"
    }
   },
   "outputs": [],
   "source": [
    "#Unbiased\n",
    "clusterless_structures = np.concatenate([np.arange(0, (324 + 280 + 69)), np.arange(939,1039)])\n",
    "np.random.seed(0)\n",
    "n_train = int(0.8 * len(clusterless_structures))\n",
    "clusterless_train = np.arange(len(clusterless_structures))\n",
    "np.random.shuffle(clusterless_train)\n",
    "clusterless_test = clusterless_train[n_train:]\n",
    "clusterless_train = clusterless_train[:n_train]\n",
    "\n",
    "#Biased\n",
    "amorph_train = np.arange(939,1039,1)\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(amorph_train)\n",
    "\n",
    "amorph_test = amorph_train[:80]\n",
    "amorph_train = amorph_train[80:]\n",
    "\n",
    "n_structures = 673\n",
    "np.random.seed(0)\n",
    "n_train = int(0.8 * (1039-266))-20\n",
    "remaining_train_index = np.arange(n_structures)\n",
    "np.random.shuffle(remaining_train_index)\n",
    "\n",
    "remaining_test_index = remaining_train_index[n_train:]\n",
    "remaining_train_index = remaining_train_index[:n_train]\n",
    "\n",
    "biased_clusterless_train_index = np.concatenate([remaining_train_index, amorph_train])\n",
    "biased_clusterless_test_index = np.concatenate([remaining_test_index, amorph_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c31c4a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Opt Discrete shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "bdced428",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T20:03:29.161950Z",
     "start_time": "2023-04-18T20:03:29.153008Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Generate shifted data\n",
    "def shifted_ldos(ldos, xdos, shift): \n",
    "    xdos_step = xdos[1] - xdos[0]\n",
    "    shifted_ldos = torch.zeros_like(ldos)\n",
    "    if len(ldos.shape) > 1:\n",
    "        xdos_shift = torch.round(shift/xdos_step).int()\n",
    "        for i in range(len(ldos)):\n",
    "            if xdos_shift[i] > 0:\n",
    "                shifted_ldos[i] = torch.nn.functional.pad(ldos[i,:-1*xdos_shift[i]], (xdos_shift[i],0))\n",
    "            elif xdos_shift[i] < 0:\n",
    "                shifted_ldos[i] = torch.nn.functional.pad(ldos[i,(-1*xdos_shift[i]):], (0,(-1*xdos_shift[i])))\n",
    "            else:\n",
    "                shifted_ldos[i] = ldos[i]\n",
    "    else:        \n",
    "        xdos_shift = int(torch.round(shift/xdos_step))\n",
    "        if xdos_shift > 0:\n",
    "            shifted_ldos = torch.nn.functional.pad(ldos[:-1*xdos_shift], (xdos_shift,0))\n",
    "        elif xdos_shift < 0:\n",
    "            shifted_ldos = torch.nn.functional.pad(ldos[(-1*xdos_shift):], (0,(-1*xdos_shift)))\n",
    "        else:\n",
    "            shifted_ldos = ldos\n",
    "    return shifted_ldos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0d217c4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T20:03:29.331692Z",
     "start_time": "2023-04-18T20:03:29.321110Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import convolve, correlate, correlation_lags\n",
    "def find_optimal_discrete_shift(y1, y2):\n",
    "    if y2.shape == y1.shape and len(y1.shape) == 2:\n",
    "        shift = []\n",
    "        for i in range(y2.shape[0]):\n",
    "            corr = correlate(y1[i], y2[i], mode='full')\n",
    "            shift_i = np.argmax(corr) - len(y2[i]) + 1   \n",
    "            shift.append(shift_i)\n",
    "        \n",
    "        \n",
    "    elif y2.shape == y1.shape and len(y1.shape) == 1:\n",
    "        corr = correlate(y1, y2, mode='full')\n",
    "        shift = np.argmax(corr) - len(y2) + 1   \n",
    "    else:\n",
    "        print (\"input shapes are not the same\")\n",
    "        raise Exception\n",
    "    return shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b0b187",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_ldos0 = shifted_ldos(ldos3, xdos, torch.ones(1039))\n",
    "optshift = find_optimal_shift(np.array(ldos3), np.array(test_ldos0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982f374",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e027bd5",
   "metadata": {},
   "source": [
    "### Analytical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "c7fbdd60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:04:50.355301Z",
     "start_time": "2023-04-19T16:04:50.339398Z"
    }
   },
   "outputs": [],
   "source": [
    "def normal_reg_train_A(feat, target, train_index, test_index, reg):\n",
    "    features = torch.hstack([feat, torch.ones(feat.shape[0]).view(-1,1)])\n",
    "    Features = features[train_index]#Silicon.Features['structure_avekerneldescriptors'][train_index]\n",
    "    test_features = features[test_index]#Silicon.Features['structure_avekerneldescriptors'][test_index]\n",
    "    Target = target[train_index]\n",
    "    test_target = target[test_index]\n",
    "    n_col = Features.shape[1]\n",
    "    regularization = reg\n",
    "    reg = regularization * torch.eye(m)\n",
    "    reg[-1, -1] = 0\n",
    "    A = torch.vstack([Features, reg])\n",
    "    b = torch.vstack([Target, torch.zeros(n_col,Target.shape[1])])\n",
    "    weights = torch.linalg.lstsq(A, b, rcond=1e-10).solution\n",
    "    pred = Features @ weights \n",
    "    test_pred = test_features @ weights\n",
    "\n",
    "    loss_dos = loss.t_get_rmse(pred, Target, xdos, perc = True)\n",
    "    test_loss_dos = loss.t_get_rmse(test_pred, test_target, xdos, perc = True)\n",
    "    \n",
    "    return weights, loss_dos, test_loss_dos\n",
    "\n",
    "def kernel_reg_train_A(feat, target, train_index, test_index, reg, kMM):\n",
    "    features = torch.hstack([feat, torch.ones(feat.shape[0]).view(-1,1)])\n",
    "    Features = features[train_index]#Silicon.Features['structure_avekerneldescriptors'][train_index]\n",
    "    test_features = features[test_index]#Silicon.Features['structure_avekerneldescriptors'][test_index]\n",
    "    Target = target[train_index]\n",
    "    test_target = target[test_index]\n",
    "    n_col = Features.shape[1]\n",
    "    regularization = reg\n",
    "    rtkMM = scipy.linalg.sqrtm(kMM)\n",
    "    reg = torch.hstack([(torch.tensor(regularization * rtkMM)), torch.zeros(kMM.shape[0]).view(-1,1)])\n",
    "    reg = torch.vstack([reg, torch.zeros(n_col)])\n",
    "    # reg[-1, -1] = 0\n",
    "    A = torch.vstack([Features, reg])\n",
    "    b = torch.vstack([Target, torch.zeros(n_col,Target.shape[1])])\n",
    "\n",
    "    weights = torch.linalg.lstsq(A, b, driver = \"gelsd\", rcond = 1e-10).solution\n",
    "    pred = Features @ weights \n",
    "    test_pred = test_features @ weights\n",
    "\n",
    "    loss_dos = loss.t_get_rmse(pred, Target, xdos, perc = True)\n",
    "    test_loss_dos = loss.t_get_rmse(test_pred, test_target, xdos, perc = True)\n",
    "    \n",
    "    return weights, loss_dos, test_loss_dos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822926eb",
   "metadata": {},
   "source": [
    "\n",
    "### Normal Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "144c4906",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:55:39.169924Z",
     "start_time": "2023-04-19T14:55:39.145808Z"
    }
   },
   "outputs": [],
   "source": [
    "def normal_reg_train_L(feat, target, train_index, test_index, regularization, n_epochs, lr):\n",
    "    \n",
    "    patience = 20\n",
    "    index = train_index\n",
    "    t_index = test_index\n",
    "    features = torch.hstack([feat, torch.ones(feat.shape[0]).view(-1,1)])\n",
    "    Features = features[index]\n",
    "    t_Features = features[t_index]\n",
    "    n_col = Features.shape[1]\n",
    "    Target = target[index]\n",
    "    t_Target = target[t_index]\n",
    "    reg = regularization * torch.eye(n_col)\n",
    "    reg[-1, -1] = 0\n",
    "    reg_features = torch.vstack([Features, reg])\n",
    "    reg_target = torch.vstack([Target, torch.zeros(n_col,Target.shape[1])])\n",
    "    \n",
    "\n",
    "\n",
    "    weights = torch.nn.Parameter(torch.rand(Features.shape[1], Target.shape[1])- 0.5)\n",
    "    opt = torch.optim.LBFGS([weights], lr = lr, line_search_fn = \"strong_wolfe\")\n",
    "    pbar = tqdm(range(n_epochs))\n",
    "    current_rmse = torch.tensor(100)\n",
    "    pred_loss = torch.tensor(100)\n",
    "    prev_loss = torch.tensor(100)\n",
    "    best_mse = torch.tensor(100)\n",
    "    trigger = 0\n",
    "    for epoch in pbar:\n",
    "        pbar.set_description(f\"Epoch: {epoch}\")\n",
    "        pbar.set_postfix(pred_loss = pred_loss.item(), lowest_mse = best_mse.item(), trigger = trigger)\n",
    "        def closure():\n",
    "            opt.zero_grad()\n",
    "            pred_i = reg_features @ weights\n",
    "            loss_i = loss.t_get_mse(pred_i, reg_target)\n",
    "            loss_i.backward()\n",
    "            return loss_i\n",
    "        opt.step(closure)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = Features @ weights\n",
    "            epoch_rmse = loss.t_get_rmse(preds, Target, xdos, perc = True)\n",
    "            epoch_mse = loss.t_get_mse(preds, Target, xdos)\n",
    "\n",
    "\n",
    "            pred_loss = epoch_rmse\n",
    "\n",
    "            if epoch_mse < best_mse:\n",
    "                best_mse = epoch_mse\n",
    "                best_state = weights.clone()\n",
    "\n",
    "            if epoch_mse < prev_loss * ( 1 + 1e-3):\n",
    "                trigger =0\n",
    "            else:\n",
    "                trigger +=1 \n",
    "                if trigger >= patience:\n",
    "                    weights = best_state\n",
    "                    opt = torch.optim.Adam([weights], lr = opt.param_groups[0]['lr'], weight_decay = 0)\n",
    "\n",
    "            epoch_mse = prev_loss\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    final_preds = Features @ best_state \n",
    "    final_t_preds = t_Features @ best_state\n",
    "\n",
    "    loss_dos = loss.t_get_rmse(final_preds, Target, xdos, perc = True)\n",
    "    test_loss_dos = loss.t_get_rmse(final_t_preds, t_Target, xdos, perc = True)\n",
    "    return best_state, loss_dos, test_loss_dos\n",
    "\n",
    "def normal_reg_train_Ad(feat, target, train_index, test_index, regularization, n_epochs, batch_size, lr):\n",
    "    index = train_index\n",
    "    t_index = test_index\n",
    "\n",
    "    features = torch.hstack([feat, torch.ones(feat.shape[0]).view(-1,1)])\n",
    "\n",
    "    Sampler = torch.utils.data.RandomSampler(index, replacement = False)\n",
    "    Batcher = torch.utils.data.BatchSampler(Sampler, batch_size, False)\n",
    "\n",
    "    Features = features[index]\n",
    "    t_Features = features[t_index]\n",
    "    n_col = Features.shape[1]\n",
    "\n",
    "\n",
    "    Target = target[index]\n",
    "    t_Target = target[t_index]\n",
    "\n",
    "\n",
    "    # reg_features = torch.vstack([Features, reg])\n",
    "    # reg_target = torch.vstack([Target, torch.zeros(n_col,Target.shape[1])])\n",
    "\n",
    "\n",
    "    reg = regularization * torch.eye(n_col)\n",
    "    reg[-1, -1] = 0\n",
    "\n",
    "\n",
    "    weights = torch.nn.Parameter((torch.rand(Features.shape[1], Target.shape[1])- 0.5))\n",
    "    opt = torch.optim.Adam([weights], lr = lr, weight_decay = 0)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor = 0.1, patience = 200, threshold = 1e-5, min_lr = 1e-8)\n",
    "\n",
    "    pbar = tqdm(range(n_epochs))\n",
    "\n",
    "    current_rmse = torch.tensor(100)\n",
    "    pred_loss = torch.tensor(100)\n",
    "    prev_loss = torch.tensor(100)\n",
    "    best_mse = torch.tensor(100)\n",
    "    trigger = 0\n",
    "    for epoch in pbar:\n",
    "        pbar.set_description(f\"Epoch: {epoch}\")\n",
    "        pbar.set_postfix(pred_loss = pred_loss.item(), lowest_mse = best_mse.item(), trigger = trigger)\n",
    "        for i_batch in Batcher:\n",
    "            def closure():\n",
    "                opt.zero_grad()\n",
    "                reg_features_i = torch.vstack([Features[i_batch], reg])\n",
    "                target_i = torch.vstack([Target[i_batch], torch.zeros(n_col, Target.shape[1])])\n",
    "                pred_i = reg_features_i @ weights\n",
    "                loss_i = loss.t_get_mse(pred_i, target_i)\n",
    "                loss_i.backward()\n",
    "                return loss_i\n",
    "            opt.step(closure)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = Features @ weights\n",
    "            epoch_rmse = loss.t_get_rmse(preds, Target, xdos, perc = True)\n",
    "            epoch_mse = loss.t_get_mse(preds, Target, xdos)\n",
    "\n",
    "\n",
    "            pred_loss = epoch_rmse\n",
    "\n",
    "            if epoch_mse < best_mse:\n",
    "                best_mse = epoch_mse\n",
    "                best_state = weights.clone()\n",
    "\n",
    "            if epoch_mse < prev_loss * ( 1 + 1e-3):\n",
    "                trigger =0\n",
    "            else:\n",
    "                trigger +=1 \n",
    "                if trigger >= patience:\n",
    "                    weights = best_state\n",
    "                    opt = torch.optim.Adam([weights], lr = opt.param_groups[0]['lr'], weight_decay = 0)\n",
    "\n",
    "            epoch_mse = prev_loss\n",
    "\n",
    "            scheduler.step(epoch_mse)\n",
    "\n",
    "            if Batcher.batch_size > 1024:\n",
    "                break\n",
    "\n",
    "            if opt.param_groups[0]['lr'] < 1e-6:\n",
    "                Batcher.batch_size *= 2\n",
    "                opt.param_groups[0]['lr'] = 1e-4\n",
    "                print (\"The batch_size is now: \", Batcher.batch_size)\n",
    "\n",
    "    \n",
    "\n",
    "    final_preds = Features @ best_state \n",
    "    final_t_preds = t_Features @ best_state\n",
    "\n",
    "    loss_dos = loss.t_get_rmse(final_preds, Target, xdos, perc = True)\n",
    "    test_loss_dos = loss.t_get_rmse(final_t_preds, t_Target, xdos, perc = True)\n",
    "    return best_state, loss_dos, test_loss_dos\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014ef38f",
   "metadata": {},
   "source": [
    "### Kernel reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "7c97513b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:40:49.546850Z",
     "start_time": "2023-04-19T14:40:49.520503Z"
    }
   },
   "outputs": [],
   "source": [
    "def kernel_reg_train_Ad(feat, target, train_index, test_index, kMM, regularization, n_epochs, batch_size, lr):\n",
    "    index = train_index\n",
    "    t_index = test_index\n",
    "    features = torch.hstack([feat, torch.ones(feat.shape[0]).view(-1,1)])\n",
    "    Features = features[index]\n",
    "    t_Features = features[t_index]\n",
    "    n_col = Features.shape[1]\n",
    "    Target = target[index]\n",
    "    t_Target = target[t_index]\n",
    "    Sampler = torch.utils.data.RandomSampler(index, replacement = False)\n",
    "    Batcher = torch.utils.data.BatchSampler(Sampler, batch_size, False)\n",
    "    rtkMM = scipy.linalg.sqrtm(kMM)\n",
    "    reg = torch.hstack([(torch.tensor(regularization * rtkMM)), torch.zeros(kMM.shape[0]).view(-1,1)])\n",
    "    reg = torch.vstack([reg, torch.zeros(n_col)])\n",
    "\n",
    "    # reg_features = torch.vstack([Features, reg])\n",
    "    # reg_target = torch.vstack([Target, torch.zeros(n_col,Target.shape[1])])\n",
    "    weights = torch.nn.Parameter(torch.rand(Features.shape[1], Target.shape[1])- 0.5) \n",
    "\n",
    "    # weights = torch.nn.Parameter((torch.rand(Features.shape[1], Target.shape[1])- 0.5) * 1e-7)\n",
    "    opt = torch.optim.Adam([weights], lr = 1e-3, weight_decay = 0)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor = 0.1, patience = 200, threshold = 1e-5, min_lr = 1e-8)\n",
    "    pbar = tqdm(range(n_epochs))\n",
    "    \n",
    "    current_rmse = torch.tensor(100)\n",
    "    pred_loss = torch.tensor(100)\n",
    "    prev_loss = torch.tensor(100)\n",
    "    best_mse = torch.tensor(100)\n",
    "    trigger = 0\n",
    "    for epoch in pbar:\n",
    "        pbar.set_description(f\"Epoch: {epoch}\")\n",
    "        pbar.set_postfix(pred_loss = pred_loss.item(), lowest_mse = best_mse.item(), trigger = trigger)\n",
    "        for i_batch in Batcher:\n",
    "            def closure():\n",
    "                opt.zero_grad()\n",
    "                reg_features_i = torch.vstack([Features[i_batch], reg])\n",
    "                target_i = torch.vstack([Target[i_batch], torch.zeros(n_col, Target.shape[1])])\n",
    "                pred_i = reg_features_i @ weights\n",
    "                loss_i = loss.t_get_mse(pred_i, target_i)\n",
    "                loss_i.backward()\n",
    "                return loss_i\n",
    "            opt.step(closure)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = Features @ weights\n",
    "            epoch_rmse = loss.t_get_rmse(preds, Target, xdos, perc = True)\n",
    "            epoch_mse = loss.t_get_mse(preds, Target, xdos)\n",
    "\n",
    "\n",
    "            pred_loss = epoch_rmse\n",
    "\n",
    "            if epoch_mse < best_mse:\n",
    "                best_mse = epoch_mse\n",
    "                best_state = weights.clone()\n",
    "\n",
    "            if epoch_mse < prev_loss * ( 1 + 1e-3):\n",
    "                trigger =0\n",
    "            else:\n",
    "                trigger +=1 \n",
    "                if trigger >= patience:\n",
    "                    weights = best_state\n",
    "                    opt = torch.optim.Adam([weights], lr = opt.param_groups[0]['lr'], weight_decay = 0)\n",
    "\n",
    "            epoch_mse = prev_loss\n",
    "\n",
    "            scheduler.step(epoch_mse)\n",
    "\n",
    "            if Batcher.batch_size > 1024:\n",
    "                break\n",
    "\n",
    "            if opt.param_groups[0]['lr'] < 1e-6:\n",
    "                Batcher.batch_size *= 2\n",
    "                opt.param_groups[0]['lr'] = 1e-4\n",
    "                print (\"The batch_size is now: \", Batcher.batch_size)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    final_preds = Features @ best_state \n",
    "    final_t_preds = t_Features @ best_state\n",
    "\n",
    "    loss_dos = loss.t_get_rmse(final_preds, Target, xdos, perc = True)\n",
    "    test_loss_dos = loss.t_get_rmse(final_t_preds, t_Target, xdos, perc = True)\n",
    "    \n",
    "    return best_state, loss_dos, test_loss_dos\n",
    "\n",
    "\n",
    "def kernel_reg_train_L(feat, target, train_index, test_index, kMM, regularization, n_epochs, lr):\n",
    "    index = train_index\n",
    "    t_index = test_index\n",
    "    features = torch.hstack([feat, torch.ones(feat.shape[0]).view(-1,1)])\n",
    "    Features = features[index]\n",
    "    t_Features = features[t_index]\n",
    "    n_col = Features.shape[1]\n",
    "    Target = target[index]\n",
    "    t_Target = target[t_index]\n",
    "    rtkMM = scipy.linalg.sqrtm(kMM)\n",
    "    reg = torch.hstack([(torch.tensor(regularization * rtkMM)), torch.zeros(kMM.shape[0]).view(-1,1)])\n",
    "    reg = torch.vstack([reg, torch.zeros(n_col)])\n",
    "\n",
    "    reg_features = torch.vstack([Features, reg])\n",
    "    reg_target = torch.vstack([Target, torch.zeros(n_col,Target.shape[1])])\n",
    "    weights = torch.nn.Parameter(torch.rand(Features.shape[1], Target.shape[1])- 0.5) \n",
    "    opt = torch.optim.LBFGS([weights], lr = lr, line_search_fn = \"strong_wolfe\")\n",
    "\n",
    "    current_rmse = torch.tensor(100)\n",
    "    pred_loss = torch.tensor(100)\n",
    "    prev_loss = torch.tensor(100)\n",
    "    best_mse = torch.tensor(100)\n",
    "    trigger = 0\n",
    "    pbar = tqdm(range(n_epochs))\n",
    "    for epoch in pbar:\n",
    "        pbar.set_description(f\"Epoch: {epoch}\")\n",
    "        pbar.set_postfix(pred_loss = pred_loss.item(), lowest_mse = best_mse.item(), trigger = trigger)\n",
    "        def closure():\n",
    "            opt.zero_grad()\n",
    "            reg_features_i = torch.vstack([Features[i_batch], reg])\n",
    "            target_i = torch.vstack([Target[i_batch], torch.zeros(n_col, Target.shape[1])])\n",
    "            pred_i = reg_features_i @ weights\n",
    "            loss_i = loss.t_get_mse(pred_i, target_i)\n",
    "            loss_i.backward()\n",
    "            return loss_i\n",
    "        opt.step(closure)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = Features @ weights\n",
    "            epoch_rmse = loss.t_get_rmse(preds, Target, xdos, perc = True)\n",
    "            epoch_mse = loss.t_get_mse(preds, Target, xdos)\n",
    "\n",
    "\n",
    "            pred_loss = epoch_rmse\n",
    "\n",
    "            if epoch_mse < best_mse:\n",
    "                best_mse = epoch_mse\n",
    "                best_state = weights.clone()\n",
    "\n",
    "            if epoch_mse < prev_loss * ( 1 + 1e-3):\n",
    "                trigger =0\n",
    "            else:\n",
    "                trigger +=1 \n",
    "                if trigger >= patience:\n",
    "                    weights = best_state\n",
    "                    opt = torch.optim.Adam([weights], lr = opt.param_groups[0]['lr'], weight_decay = 0)\n",
    "\n",
    "            epoch_mse = prev_loss\n",
    "\n",
    "    final_preds = Features @ best_state \n",
    "    final_t_preds = t_Features @ best_state\n",
    "\n",
    "    loss_dos = loss.t_get_rmse(final_preds, Target, xdos, perc = True)\n",
    "    test_loss_dos = loss.t_get_rmse(final_t_preds, t_Target, xdos, perc = True)\n",
    "    \n",
    "    return best_state, loss_dos, test_loss_dos\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "ee4fd888",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:25:16.416013Z",
     "start_time": "2023-04-19T14:25:16.399401Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0695af6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "945d16f8",
   "metadata": {},
   "source": [
    "## Baseline Linalg Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8b8373af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T19:37:27.241500Z",
     "start_time": "2023-04-18T19:37:27.166756Z"
    }
   },
   "outputs": [],
   "source": [
    "from dostools.loss import loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_clusterless_train_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c89f0e",
   "metadata": {},
   "source": [
    "### SOAP - 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "94b2a40f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:06:00.774106Z",
     "start_time": "2023-04-19T16:06:00.681506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smearing: 0.3\n",
      "Unbiased\n",
      "The train error is 7.302 for SOAP\n",
      "The test error is 11.23 for SOAP\n",
      "Biased\n",
      "The train error is 6.598 for SOAP\n",
      "The test error is 14.83 for SOAP\n",
      "Unbiased Clusterless\n",
      "The train error is 10.08 for SOAP\n",
      "The test error is 13.26 for SOAP\n",
      "Biased Clusterless\n",
      "The train error is 13.32 for SOAP\n",
      "The test error is 19.89 for SOAP\n"
     ]
    }
   ],
   "source": [
    "U_weight_s03, loss_dos, test_loss_dos =normal_reg_train_A(SOAP, ldos3, train_index, test_index, 1e-3)\n",
    "print (\"Smearing: 0.3\")\n",
    "print (\"Unbiased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos))\n",
    "\n",
    "B_weight_s03, loss_dos, test_loss_dos =normal_reg_train_A(SOAP, ldos3, biased_train_index, biased_test_index, 1e-3)\n",
    "\n",
    "print (\"Biased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos, m))\n",
    "\n",
    "UC_weight_s03, loss_dos, test_loss_dos =normal_reg_train_A(SOAP, ldos3, clusterless_train, clusterless_test, 1e-2)\n",
    "\n",
    "print (\"Unbiased Clusterless\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos))\n",
    "\n",
    "UC_weight_s03, loss_dos, test_loss_dos =normal_reg_train_A(SOAP, ldos3, biased_clusterless_train_index, biased_clusterless_test_index, 1e-2)\n",
    "\n",
    "print (\"Biased Clusterless\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2f7b38",
   "metadata": {},
   "source": [
    "### SOAP - 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "d8a274da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:06:43.290775Z",
     "start_time": "2023-04-19T16:06:43.206079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smearing: 0.1\n",
      "Regularization: 0.001\n",
      "Unbiased\n",
      "The train error is 18.92 for SOAP\n",
      "The test error is 24.47 for SOAP\n",
      "Biased\n",
      "The train error is 17.86 for n_refs = 449\n",
      "The test error is 31.05 for n_refs = 449\n",
      "Unbiased Clusterless\n",
      "The train error is 22.8 for SOAP\n",
      "The test error is 30.0 for SOAP\n",
      "Biased Clusterless\n",
      "The train error is 31.58 for SOAP\n",
      "The test error is 39.72 for SOAP\n"
     ]
    }
   ],
   "source": [
    "regularization = 1e-3\n",
    "U_weight_s01, loss_dos, test_loss_dos =normal_reg_train_A(SOAP, ldos1, train_index, test_index, regularization)\n",
    "print (\"Smearing: 0.1\")\n",
    "print (\"Regularization: {}\".format(regularization))\n",
    "print (\"Unbiased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos))\n",
    "\n",
    "B_weight_s01, loss_dos, test_loss_dos =normal_reg_train_A(SOAP, ldos1, biased_train_index, biased_test_index, regularization)\n",
    "\n",
    "print (\"Biased\")\n",
    "print (\"The train error is {:.4} for n_refs = {}\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for n_refs = {}\".format(test_loss_dos, m))\n",
    "\n",
    "UC_weight_s03, loss_dos, test_loss_dos =normal_reg_train_A(SOAP, ldos1, clusterless_train, clusterless_test, 1e-2)\n",
    "\n",
    "print (\"Unbiased Clusterless\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos))\n",
    "\n",
    "UC_weight_s03, loss_dos, test_loss_dos =normal_reg_train_A(SOAP, ldos1, biased_clusterless_train_index, biased_clusterless_test_index, 1e-2)\n",
    "\n",
    "print (\"Biased Clusterless\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde9f25",
   "metadata": {},
   "source": [
    "### 200 Kernel - 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "2c8a1d74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:12:40.549637Z",
     "start_time": "2023-04-19T16:12:40.261983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smearing: 0.3\n",
      "Unbiased\n",
      "The train error is 10.91 for n_refs = 200\n",
      "The test error is 12.42 for n_refs = 200\n",
      "Biased\n",
      "The train error is 10.31 for n_refs = 200\n",
      "The test error is 16.22 for n_refs = 200\n",
      "Unbiased Clusterless\n",
      "The train error is 11.02 for n_refs = 200\n",
      "The test error is 14.99 for n_refs = 200\n",
      "Biased Clusterless\n",
      "The train error is 14.86 for n_refs = 200\n",
      "The test error is 23.36 for n_refs = 200\n"
     ]
    }
   ],
   "source": [
    "regularization = 1\n",
    "U_weight_s03, loss_dos , test_loss_dos = kernel_reg_train_A(KERNEL, ldos3, train_index, test_index, regularization, kMM_200)\n",
    "print (\"Smearing: 0.3\")\n",
    "print (\"Unbiased\")\n",
    "print (\"The train error is {:.4} for n_refs = 200\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for n_refs = 200\".format(test_loss_dos))\n",
    "B_weight_s03, loss_dos , test_loss_dos = kernel_reg_train_A(KERNEL, ldos3, biased_train_index, biased_test_index, regularization, kMM_200)\n",
    "print (\"Biased\")\n",
    "print (\"The train error is {:.4} for n_refs = 200\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for n_refs = 200\".format(test_loss_dos))\n",
    "\n",
    "regularization = 1\n",
    "U_weight_s03, loss_dos , test_loss_dos = kernel_reg_train_A(KERNEL, ldos3, clusterless_train, clusterless_test, regularization, kMM_200)\n",
    "\n",
    "print (\"Unbiased Clusterless\")\n",
    "print (\"The train error is {:.4} for n_refs = 200\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for n_refs = 200\".format(test_loss_dos))\n",
    "B_weight_s03, loss_dos , test_loss_dos = kernel_reg_train_A(KERNEL, ldos3, biased_clusterless_train_index, biased_clusterless_test_index, regularization, kMM_200)\n",
    "print (\"Biased Clusterless\")\n",
    "print (\"The train error is {:.4} for n_refs = 200\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for n_refs = 200\".format(test_loss_dos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce13e59d",
   "metadata": {},
   "source": [
    "### 200 Kernel - 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "6c7b0c93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:12:16.695557Z",
     "start_time": "2023-04-19T16:12:16.393553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smearing: 0.3\n",
      "Regularization: 1\n",
      "Unbiased\n",
      "The train error is 23.21 for n_refs = 200\n",
      "The test error is 25.19 for n_refs = 200\n",
      "Biased\n",
      "The train error is 22.38 for n_refs = 200\n",
      "The test error is 30.98 for n_refs = 200\n",
      "Unbiased Clusterless\n",
      "The train error is 23.6 for n_refs = 200\n",
      "The test error is 32.16 for n_refs = 200\n",
      "Biased Clusterless\n",
      "The train error is 33.5 for n_refs = 200\n",
      "The test error is 44.27 for n_refs = 200\n"
     ]
    }
   ],
   "source": [
    "regularization = 1\n",
    "U_weight_s01, loss_dos , test_loss_dos = kernel_reg_train_A(KERNEL, ldos1, train_index, test_index, regularization, kMM_200)\n",
    "print (\"Smearing: 0.3\")\n",
    "print (\"Regularization: {}\".format(regularization))\n",
    "print (\"Unbiased\")\n",
    "print (\"The train error is {:.4} for n_refs = 200\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for n_refs = 200\".format(test_loss_dos))\n",
    "B_weight_s01, loss_dos , test_loss_dos = kernel_reg_train_A(KERNEL, ldos1, biased_train_index, biased_test_index, regularization, kMM_200)\n",
    "print (\"Biased\")\n",
    "print (\"The train error is {:.4} for n_refs = 200\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for n_refs = 200\".format(test_loss_dos))\n",
    "\n",
    "regularization = 1\n",
    "U_weight_s01, loss_dos , test_loss_dos = kernel_reg_train_A(KERNEL, ldos1, clusterless_train, clusterless_test, regularization, kMM_200)\n",
    "\n",
    "print (\"Unbiased Clusterless\")\n",
    "print (\"The train error is {:.4} for n_refs = 200\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for n_refs = 200\".format(test_loss_dos))\n",
    "B_weight_s01, loss_dos , test_loss_dos = kernel_reg_train_A(KERNEL, ldos1, biased_clusterless_train_index, biased_clusterless_test_index, regularization, kMM_200)\n",
    "print (\"Biased Clusterless\")\n",
    "print (\"The train error is {:.4} for n_refs = 200\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for n_refs = 200\".format(test_loss_dos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d3cd33",
   "metadata": {},
   "source": [
    "## Baseline GD model - Adam -unbiased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f282d8f",
   "metadata": {},
   "source": [
    "### 0.3eV Smearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "8b8ddcbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T15:09:34.054692Z",
     "start_time": "2023-04-19T15:03:00.822375Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1007:  10%|██████████▏                                                                                          | 1007/10000 [03:43<27:58,  5.36it/s, lowest_mse=0.00643, pred_loss=13.7, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1612:  16%|████████████████▍                                                                                     | 1611/10000 [04:53<12:45, 10.97it/s, lowest_mse=0.0064, pred_loss=13.6, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2217:  22%|██████████████████████▍                                                                              | 2216/10000 [05:32<06:43, 19.29it/s, lowest_mse=0.00638, pred_loss=13.6, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2822:  28%|████████████████████████████▍                                                                        | 2820/10000 [05:56<04:08, 28.91it/s, lowest_mse=0.00636, pred_loss=13.6, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3428:  34%|██████████████████████████████████▌                                                                  | 3426/10000 [06:12<02:37, 41.87it/s, lowest_mse=0.00634, pred_loss=13.5, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4033:  40%|████████████████████████████████████████▋                                                            | 4033/10000 [06:24<01:43, 57.66it/s, lowest_mse=0.00633, pred_loss=13.5, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4624:  46%|██████████████████████████████████████████████▋                                                      | 4624/10000 [06:33<07:37, 11.76it/s, lowest_mse=0.00632, pred_loss=13.5, trigger=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  2048\n",
      "Adam Unbiased\n",
      "The train error is 13.52 for SOAP\n",
      "The test error is 12.97 for SOAP\n"
     ]
    }
   ],
   "source": [
    "weights, loss_dos, test_loss_dos = normal_reg_train_Ad(SOAP, ldos3, train_index, test_index, 1e-3, 10000, 16, 1e-2)\n",
    "print (\"Adam Unbiased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f92ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T15:02:55.096707Z",
     "start_time": "2023-04-19T15:02:55.096692Z"
    }
   },
   "source": [
    "The train error is 13.54 for n_refs = 449\n",
    "The test error is 12.99 for n_refs = 449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "b9d261cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T15:13:19.156499Z",
     "start_time": "2023-04-19T15:09:34.058324Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 807:   8%|████████▌                                                                                                 | 807/10000 [01:46<17:04,  8.97it/s, lowest_mse=0.15, pred_loss=65.8, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1412:  14%|██████████████▊                                                                                          | 1411/10000 [02:33<09:00, 15.90it/s, lowest_mse=0.116, pred_loss=58, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2017:  20%|█████████████████████▏                                                                                   | 2014/10000 [02:59<05:12, 25.56it/s, lowest_mse=0.097, pred_loss=53, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2623:  26%|██████████████████████████▋                                                                           | 2619/10000 [03:16<03:07, 39.39it/s, lowest_mse=0.0867, pred_loss=50.3, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3230:  32%|████████████████████████████████▉                                                                     | 3229/10000 [03:30<02:00, 55.98it/s, lowest_mse=0.0815, pred_loss=48.5, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3838:  38%|███████████████████████████████████████                                                               | 3834/10000 [03:38<01:17, 79.72it/s, lowest_mse=0.0778, pred_loss=47.4, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4423:  44%|█████████████████████████████████████████████                                                         | 4423/10000 [03:45<04:43, 19.65it/s, lowest_mse=0.0758, pred_loss=46.8, trigger=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  2048\n",
      "Adam Unbiased\n",
      "The train error is 46.8 for KERNEL\n",
      "The test error is 46.45 for KERNEL\n"
     ]
    }
   ],
   "source": [
    "A_U_weights_03, loss_dos, test_loss_dos = kernel_reg_train_Ad(KERNEL, ldos3, train_index, test_index, kMM, 1, 10000, 16, 1e-3)\n",
    "\n",
    "print (\"Adam Unbiased\")\n",
    "print (\"The train error is {:.4} for KERNEL\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for KERNEL\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875c7fc9",
   "metadata": {},
   "source": [
    "### 0.1eV Smearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "e46a567d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T15:20:06.840332Z",
     "start_time": "2023-04-19T15:13:19.159062Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1007:  10%|██████████▎                                                                                           | 1007/10000 [03:51<29:40,  5.05it/s, lowest_mse=0.0467, pred_loss=27.5, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1611:  16%|████████████████▍                                                                                     | 1611/10000 [05:05<13:38, 10.25it/s, lowest_mse=0.0466, pred_loss=27.4, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2217:  22%|██████████████████████▌                                                                               | 2216/10000 [05:44<06:42, 19.33it/s, lowest_mse=0.0465, pred_loss=27.4, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2822:  28%|████████████████████████████▊                                                                         | 2820/10000 [06:09<04:08, 28.94it/s, lowest_mse=0.0464, pred_loss=27.4, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3428:  34%|██████████████████████████████████▉                                                                   | 3425/10000 [06:26<02:36, 41.92it/s, lowest_mse=0.0464, pred_loss=27.3, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4032:  40%|█████████████████████████████████████████                                                             | 4025/10000 [06:37<01:54, 52.15it/s, lowest_mse=0.0463, pred_loss=27.3, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4624:  46%|███████████████████████████████████████████████▏                                                      | 4624/10000 [06:47<07:53, 11.34it/s, lowest_mse=0.0463, pred_loss=27.3, trigger=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  2048\n",
      "Adam Unbiased\n",
      "The train error is 27.32 for SOAP\n",
      "The test error is 26.9 for SOAP\n"
     ]
    }
   ],
   "source": [
    "weights, loss_dos, test_loss_dos = normal_reg_train_Ad(SOAP, ldos1, train_index, test_index, 1e-3, 10000, 16, 1e-2)\n",
    "print (\"Adam Unbiased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "e5d7d8f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T15:23:45.712446Z",
     "start_time": "2023-04-19T15:20:06.843730Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 807:   8%|████████▌                                                                                                 | 807/10000 [01:51<15:39,  9.78it/s, lowest_mse=0.37, pred_loss=77.2, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1413:  14%|██████████████▌                                                                                        | 1412/10000 [02:33<07:57, 17.99it/s, lowest_mse=0.328, pred_loss=72.8, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2018:  20%|████████████████████▊                                                                                  | 2016/10000 [02:58<04:31, 29.43it/s, lowest_mse=0.302, pred_loss=69.8, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2624:  26%|███████████████████████████                                                                            | 2623/10000 [03:13<02:43, 45.14it/s, lowest_mse=0.289, pred_loss=68.3, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3232:  32%|█████████████████████████████████▏                                                                     | 3225/10000 [03:24<01:51, 60.91it/s, lowest_mse=0.281, pred_loss=67.4, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3839:  38%|███████████████████████████████████████▌                                                               | 3836/10000 [03:32<01:12, 85.19it/s, lowest_mse=0.276, pred_loss=66.8, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4423:  44%|█████████████████████████████████████████████▌                                                         | 4423/10000 [03:38<04:35, 20.21it/s, lowest_mse=0.274, pred_loss=66.4, trigger=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  2048\n",
      "Adam Unbiased\n",
      "The train error is 66.45 for KERNEL\n",
      "The test error is 66.88 for KERNEL\n"
     ]
    }
   ],
   "source": [
    "A_U_weights_01, loss_dos, test_loss_dos = kernel_reg_train_Ad(KERNEL, ldos1, train_index, test_index, kMM, 1, 10000, 16, 1e-3)\n",
    "\n",
    "print (\"Adam Unbiased\")\n",
    "print (\"The train error is {:.4} for KERNEL\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for KERNEL\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa154931",
   "metadata": {},
   "source": [
    "## Baseline GD model - Adam -biased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207bcb4",
   "metadata": {},
   "source": [
    "### 0.3eV Smearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "065934ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T15:30:17.249479Z",
     "start_time": "2023-04-19T15:23:45.714775Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1007:  10%|██████████▏                                                                                          | 1007/10000 [03:39<32:13,  4.65it/s, lowest_mse=0.00615, pred_loss=12.9, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1612:  16%|████████████████▎                                                                                    | 1611/10000 [04:51<12:49, 10.90it/s, lowest_mse=0.00613, pred_loss=12.8, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2217:  22%|██████████████████████▌                                                                               | 2215/10000 [05:30<06:57, 18.64it/s, lowest_mse=0.0061, pred_loss=12.8, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2822:  28%|████████████████████████████▌                                                                        | 2822/10000 [05:55<03:58, 30.13it/s, lowest_mse=0.00608, pred_loss=12.8, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3428:  34%|██████████████████████████████████▌                                                                  | 3428/10000 [06:11<02:27, 44.48it/s, lowest_mse=0.00607, pred_loss=12.8, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4034:  40%|████████████████████████████████████████▋                                                            | 4028/10000 [06:23<01:43, 57.83it/s, lowest_mse=0.00605, pred_loss=12.8, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4624:  46%|██████████████████████████████████████████████▋                                                      | 4624/10000 [06:31<07:35, 11.81it/s, lowest_mse=0.00605, pred_loss=12.8, trigger=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  2048\n",
      "Adam biased\n",
      "The train error is 12.75 for SOAP\n",
      "The test error is 16.67 for SOAP\n"
     ]
    }
   ],
   "source": [
    "weights, loss_dos, test_loss_dos = normal_reg_train_Ad(SOAP, ldos3, biased_train_index, biased_test_index, 1e-3, 10000, 16, 1e-2)\n",
    "print (\"Adam biased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "79661c4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T15:33:47.155839Z",
     "start_time": "2023-04-19T15:30:17.251841Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 807:   8%|████████▍                                                                                                | 807/10000 [01:43<15:31,  9.87it/s, lowest_mse=0.381, pred_loss=76.1, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1413:  14%|██████████████▌                                                                                        | 1412/10000 [02:25<07:53, 18.13it/s, lowest_mse=0.336, pred_loss=71.4, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2018:  20%|████████████████████▊                                                                                  | 2016/10000 [02:49<04:28, 29.78it/s, lowest_mse=0.312, pred_loss=68.9, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2625:  26%|███████████████████████████                                                                            | 2623/10000 [03:05<02:39, 46.20it/s, lowest_mse=0.299, pred_loss=67.3, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3232:  32%|█████████████████████████████████▏                                                                     | 3225/10000 [03:15<01:50, 61.29it/s, lowest_mse=0.292, pred_loss=66.5, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3839:  38%|████████████████████████████████████████▎                                                                | 3836/10000 [03:23<01:12, 85.06it/s, lowest_mse=0.287, pred_loss=66, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4423:  44%|█████████████████████████████████████████████▌                                                         | 4423/10000 [03:29<04:24, 21.08it/s, lowest_mse=0.284, pred_loss=65.7, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  2048\n",
      "Adam Unbiased\n",
      "The train error is 65.67 for KERNEL\n",
      "The test error is 72.64 for KERNEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "A_U_weights_01, loss_dos, test_loss_dos = kernel_reg_train_Ad(KERNEL, ldos1, biased_train_index, biased_test_index, kMM, 1, 10000, 16, 1e-3)\n",
    "\n",
    "print (\"Adam Unbiased\")\n",
    "print (\"The train error is {:.4} for KERNEL\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for KERNEL\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2033525e",
   "metadata": {},
   "source": [
    "### 0.1eV Smearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "40fbfc14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T15:40:16.692655Z",
     "start_time": "2023-04-19T15:33:47.158203Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1007:  10%|██████████▎                                                                                           | 1007/10000 [03:40<27:57,  5.36it/s, lowest_mse=0.0459, pred_loss=26.4, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1612:  16%|████████████████▍                                                                                     | 1611/10000 [04:51<12:48, 10.92it/s, lowest_mse=0.0458, pred_loss=26.4, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2217:  22%|██████████████████████▌                                                                               | 2216/10000 [05:29<06:40, 19.44it/s, lowest_mse=0.0457, pred_loss=26.3, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2822:  28%|████████████████████████████▊                                                                         | 2820/10000 [05:53<04:01, 29.72it/s, lowest_mse=0.0457, pred_loss=26.3, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3428:  34%|██████████████████████████████████▉                                                                   | 3427/10000 [06:09<02:31, 43.29it/s, lowest_mse=0.0456, pred_loss=26.3, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4034:  40%|█████████████████████████████████████████                                                             | 4028/10000 [06:21<01:45, 56.55it/s, lowest_mse=0.0455, pred_loss=26.3, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4624:  46%|███████████████████████████████████████████████▏                                                      | 4624/10000 [06:29<07:32, 11.87it/s, lowest_mse=0.0455, pred_loss=26.3, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  2048\n",
      "Adam biased\n",
      "The train error is 26.27 for SOAP\n",
      "The test error is 31.64 for SOAP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "weights, loss_dos, test_loss_dos = normal_reg_train_Ad(SOAP, ldos1, biased_train_index, biased_test_index, 1e-3, 10000, 16, 1e-2)\n",
    "print (\"Adam biased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "8fa2ba76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T15:43:50.793673Z",
     "start_time": "2023-04-19T15:40:16.695777Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 807:   8%|████████▍                                                                                                | 807/10000 [01:44<15:46,  9.72it/s, lowest_mse=0.379, pred_loss=75.8, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1413:  14%|██████████████▌                                                                                        | 1412/10000 [02:26<07:57, 17.98it/s, lowest_mse=0.337, pred_loss=71.5, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2018:  20%|████████████████████▊                                                                                  | 2016/10000 [02:50<04:26, 29.94it/s, lowest_mse=0.312, pred_loss=68.7, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2625:  26%|███████████████████████████                                                                            | 2623/10000 [03:06<02:40, 46.01it/s, lowest_mse=0.299, pred_loss=67.3, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3229:  32%|█████████████████████████████████▏                                                                     | 3224/10000 [03:18<02:12, 50.97it/s, lowest_mse=0.292, pred_loss=66.5, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3838:  38%|████████████████████████████████████████▎                                                                | 3837/10000 [03:27<01:15, 81.98it/s, lowest_mse=0.287, pred_loss=66, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4423:  44%|█████████████████████████████████████████████▌                                                         | 4423/10000 [03:34<04:29, 20.66it/s, lowest_mse=0.284, pred_loss=65.7, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  2048\n",
      "Adam Unbiased\n",
      "The train error is 65.67 for KERNEL\n",
      "The test error is 72.58 for KERNEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "A_U_weights_01, loss_dos, test_loss_dos = kernel_reg_train_Ad(KERNEL, ldos1, biased_train_index, biased_test_index, kMM, 1, 10000, 16, 1e-3)\n",
    "\n",
    "print (\"Adam Unbiased\")\n",
    "print (\"The train error is {:.4} for KERNEL\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for KERNEL\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90f56aa",
   "metadata": {},
   "source": [
    "## Baseline GD model - LBFGS - unbiased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f00632",
   "metadata": {},
   "source": [
    "### 0.3eV Smearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "d264d084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:33:08.299364Z",
     "start_time": "2023-04-19T14:33:04.089476Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 39: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:04<00:00,  9.56it/s, lowest_mse=0.01, pred_loss=17, trigger=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS Unbiased\n",
      "The train error is 17.04 for SOAP\n",
      "The test error is 15.35 for SOAP\n"
     ]
    }
   ],
   "source": [
    "U_L_weights3 , loss_dos, test_loss_dos = normal_reg_train_L(SOAP, ldos3, train_index, test_index, 1e-3, 40, 1)\n",
    "print (\"LBFGS Unbiased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "edca682e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:33:11.400578Z",
     "start_time": "2023-04-19T14:33:09.230118Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 39: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 18.77it/s, lowest_mse=0.0476, pred_loss=37.1, trigger=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS Unbiased\n",
      "The train error is 37.09 for Kernel\n",
      "The test error is 36.84 for Kernel\n"
     ]
    }
   ],
   "source": [
    "U_L_weights3 , loss_dos, test_loss_dos = kernel_reg_train_L(KERNEL, ldos3, train_index, test_index, kMM, 1, 40, 1)\n",
    "print (\"LBFGS Unbiased\")\n",
    "print (\"The train error is {:.4} for Kernel\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for Kernel\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed57fba5",
   "metadata": {},
   "source": [
    "### 0.1eV Smearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "910e76cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:33:00.114712Z",
     "start_time": "2023-04-19T14:32:50.365526Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 39: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:09<00:00,  4.12it/s, lowest_mse=0.0438, pred_loss=26.6, trigger=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS Unbiased\n",
      "The train error is 26.57 for SOAP\n",
      "The test error is 26.29 for SOAP\n"
     ]
    }
   ],
   "source": [
    "U_L_weights3 , loss_dos, test_loss_dos = normal_reg_train_L(SOAP, ldos1, train_index, test_index, 1e-3, 40, 1)\n",
    "print (\"LBFGS Unbiased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "b9206187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:33:26.071199Z",
     "start_time": "2023-04-19T14:33:22.072530Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 39: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:03<00:00, 10.16it/s, lowest_mse=0.202, pred_loss=57, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS Unbiased\n",
      "The train error is 57.02 for Kernel\n",
      "The test error is 57.55 for Kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "U_L_weights3 , loss_dos, test_loss_dos = kernel_reg_train_L(KERNEL, ldos1, train_index, test_index, kMM, 1, 40, 1)\n",
    "print (\"LBFGS Unbiased\")\n",
    "print (\"The train error is {:.4} for Kernel\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for Kernel\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f51f4",
   "metadata": {},
   "source": [
    "## Baseline GD model - LBFGS - biased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d141b",
   "metadata": {},
   "source": [
    "### 0.3eV Smearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "1eb28ecf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:35:38.432525Z",
     "start_time": "2023-04-19T14:35:35.616825Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 39: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 14.33it/s, lowest_mse=0.0111, pred_loss=17.3, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS Biased\n",
      "The train error is 17.29 for SOAP\n",
      "The test error is 22.66 for SOAP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "U_L_weights3 , loss_dos, test_loss_dos = normal_reg_train_L(SOAP, ldos3, biased_train_index, biased_test_index, 1e-3, 40, 1)\n",
    "print (\"LBFGS Biased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "b92867e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:36:37.956183Z",
     "start_time": "2023-04-19T14:36:36.011635Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 39: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 21.03it/s, lowest_mse=0.0486, pred_loss=36.2, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS Unbiased\n",
      "The train error is 36.15 for Kernel\n",
      "The test error is 41.55 for Kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "U_L_weights3 , loss_dos, test_loss_dos = kernel_reg_train_L(KERNEL, ldos3, biased_train_index, biased_test_index, kMM, 1, 40, 1)\n",
    "print (\"LBFGS Biased\")\n",
    "print (\"The train error is {:.4} for Kernel\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for Kernel\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4d91f5",
   "metadata": {},
   "source": [
    "### 0.1 eV Smearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "cd384fcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:36:59.227525Z",
     "start_time": "2023-04-19T14:36:55.402144Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 39: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:03<00:00, 10.51it/s, lowest_mse=0.0586, pred_loss=29.8, trigger=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS Biased\n",
      "The train error is 29.8 for SOAP\n",
      "The test error is 35.63 for SOAP\n"
     ]
    }
   ],
   "source": [
    "U_L_weights3 , loss_dos, test_loss_dos = normal_reg_train_L(SOAP, ldos1, biased_train_index, biased_test_index, 1e-3, 40, 1)\n",
    "print (\"LBFGS Biased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "f6d2cc09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T14:36:55.400296Z",
     "start_time": "2023-04-19T14:36:51.750853Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 39: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:03<00:00, 11.08it/s, lowest_mse=0.21, pred_loss=56.5, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS Biased\n",
      "The train error is 56.48 for Kernel\n",
      "The test error is 63.5 for Kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "U_L_weights3 , loss_dos, test_loss_dos = kernel_reg_train_L(KERNEL, ldos1, biased_train_index, biased_test_index, kMM, 1, 40, 1)\n",
    "print (\"LBFGS Biased\")\n",
    "print (\"The train error is {:.4} for Kernel\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for Kernel\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ca6b9",
   "metadata": {},
   "source": [
    "## Baseline GF model - Adam - Clusterless Unbiased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e851a52",
   "metadata": {},
   "source": [
    "### 0.3eV Smearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2623912",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T16:19:09.409Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 155:   2%|█▌                                                                                                     | 155/10000 [00:25<26:59,  6.08it/s, lowest_mse=0.00979, pred_loss=20.2, trigger=0]"
     ]
    }
   ],
   "source": [
    "weights, loss_dos, test_loss_dos = normal_reg_train_Ad(SOAP, ldos3, clusterless_train, clusterless_test, 1e-3, 10000, 16, 1e-2)\n",
    "print (\"Adam Unbiased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323eea6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T16:19:25.666Z"
    }
   },
   "outputs": [],
   "source": [
    "A_U_weights_03, loss_dos, test_loss_dos = kernel_reg_train_Ad(KERNEL, ldos3, clusterless_train, clusterless_test, kMM, 1, 10000, 16, 1e-3)\n",
    "\n",
    "print (\"Adam Unbiased\")\n",
    "print (\"The train error is {:.4} for KERNEL\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for KERNEL\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, loss_dos, test_loss_dos = normal_reg_train_Ad(SOAP, ldos3, clusterless_train, clusterless_test, 1e-3, 10000, 16, 1e-2)\n",
    "print (\"Adam Unbiased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc2ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_U_weights_03, loss_dos, test_loss_dos = kernel_reg_train_Ad(KERNEL, ldos3, clusterless_train, clusterless_test, kMM, 1, 10000, 16, 1e-3)\n",
    "\n",
    "print (\"Adam Unbiased\")\n",
    "print (\"The train error is {:.4} for KERNEL\".format(loss_dos,m))\n",
    "print (\"The test error is {:.4} for KERNEL\".format(test_loss_dos, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e90628c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13689c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9edc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5df854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a287cdb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "396.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
