{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84565b74",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfdaeca7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T17:15:54.616738Z",
     "start_time": "2023-01-27T17:15:54.609357Z"
    }
   },
   "outputs": [],
   "source": [
    "import dostools\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import time\n",
    "torch.set_default_dtype(torch.float64) \n",
    "%matplotlib notebook\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 10)\n",
    "sys.modules['dostools.src'] = dostools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ccbf26d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T11:28:53.055005Z",
     "start_time": "2023-01-27T11:28:44.621291Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ldos shape is torch.Size([1039, 778])\n",
      "mean dos shape is torch.Size([778])\n",
      "Variance covered with 10 PCs is = 0.9871211778950166\n"
     ]
    }
   ],
   "source": [
    "import dostools.datasets.data as data\n",
    "import dostools.utils.utils as utils\n",
    "\n",
    "n_structures = 1039\n",
    "np.random.seed(0)\n",
    "n_train = int(0.8 * n_structures)\n",
    "train_index = np.arange(n_structures)\n",
    "np.random.shuffle(train_index)\n",
    "test_index = train_index[n_train:]\n",
    "train_index = train_index[:n_train]\n",
    "\n",
    "with torch.no_grad():\n",
    "    structures = data.load_structures(\":\")\n",
    "    n_structures = len(structures) #total number of structures\n",
    "    for structure in structures:#implement periodicity\n",
    "        structure.wrap(eps = 1e-12) \n",
    "    n_atoms = np.zeros(n_structures, dtype = int) #stores number of atoms in each structures\n",
    "    for i in range(n_structures):\n",
    "        n_atoms[i] = len(structures[i])\n",
    "\n",
    "    #eigenergies, emin, emax = dostools.src.datasets.data.load_eigenenergies(unpack = True, n_structures = len(structures))\n",
    "    xdos = torch.tensor(data.load_xdos())\n",
    "    ldos = torch.tensor(data.load_ldos())\n",
    "    ldos *= 2\n",
    "\n",
    "    print (\"ldos shape is {}\".format(ldos.shape))\n",
    "    mean_dos_per_atom = ldos[train_index].mean(axis = 0) #only calculated for train set to prevent data leakage\n",
    "    print (\"mean dos shape is {}\".format(mean_dos_per_atom.shape))\n",
    "    \n",
    "    \n",
    "    y_pw = ldos - mean_dos_per_atom\n",
    "    y_lcdf = torch.cumsum(y_pw, dim = 1)\n",
    "    _, pc_vectors = utils.build_pc(ldos[train_index], mean_dos_per_atom[None,:], n_pc = 10)\n",
    "    y_pc = utils.build_coeffs(ldos - mean_dos_per_atom[None,:], pc_vectors)\n",
    "    Silicon = data.load_features()\n",
    "    kMM = data.load_kMM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c7af2",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cfe1751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T11:28:53.067505Z",
     "start_time": "2023-01-27T11:28:53.058565Z"
    }
   },
   "outputs": [],
   "source": [
    "import dostools.evaluation.evaluation as evaluation\n",
    "importlib.reload(evaluation)\n",
    "import dostools.models.training as training\n",
    "importlib.reload(training)\n",
    "\n",
    "targets = {\n",
    "    'pw' : ldos,\n",
    "    'lcdf' : y_lcdf,\n",
    "    'pc' : y_pc\n",
    "}\n",
    "evaluator = evaluation.Evaluator(targets, xdos, mean_dos_per_atom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec309322",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926a2a74",
   "metadata": {},
   "source": [
    "Data Generation will consist of two steps  \n",
    "1. Generate a random alignment \n",
    "2. Use scikitlearn Ridge to determine optimal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eab90e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define limits for alignment to prevent complete shifts (shifting the spectrum out of the data)\n",
    "\n",
    "def determine_bounds(input_dos, threshold):\n",
    "    boo_dos = input_dos > threshold\n",
    "    left_bound = torch.nonzero(boo_dos)[0]\n",
    "    right_bound = torch.nonzero(boo_dos)[-1]\n",
    "        \n",
    "    return (0-left_bound), (788-right_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69a42be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = []\n",
    "for i in ldos[train_index]:\n",
    "    bounds.append(determine_bounds(i, 1e-10))\n",
    "\n",
    "bounds = torch.tensor(bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e610c331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -71,  121],\n",
       "        [-145,  149],\n",
       "        [ -28,   22],\n",
       "        ...,\n",
       "        [-132,  130],\n",
       "        [-108,  130],\n",
       "        [ -69,  104]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0f82f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdos_step = xdos[1] - xdos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "13b24a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import dostools.src.loss.loss as loss\n",
    "importlib.reload(loss)\n",
    "#Since it should be alright to overfit shifts\n",
    "def determine_error(normalized_dos):\n",
    "    model = Ridge(alpha = 0, fit_intercept = False, solver = 'svd')\n",
    "    model.fit(Silicon.Features['structure_avekerneldescriptors'][train_index,:], normalized_dos)\n",
    "    \n",
    "    preds = model.predict(Silicon.Features['structure_avekerneldescriptors'][train_index,:])\n",
    "    with torch.no_grad():\n",
    "        rmse = loss.t_get_rmse(torch.tensor(preds), normalized_dos, xdos)\n",
    "        \n",
    "    return rmse\n",
    "        \n",
    "\n",
    "def normalize(ldos, alignment):\n",
    "    shifted_dos = consistency.shifted_ldos(ldos, xdos, alignment * xdos_step)\n",
    "    mean = torch.mean(shifted_dos, dim = 0)\n",
    "    normalized_dos = shifted_dos - mean\n",
    "    \n",
    "    return normalized_dos\n",
    "\n",
    "def generate_sample(bounds, ldos, batch_size):\n",
    "    x_sample = []\n",
    "    for bound in bounds:\n",
    "        col_i = torch.randint(bound[0], bound[1], (batch_size,1))\n",
    "        x_sample.append(col_i)\n",
    "    \n",
    "    x_sample = torch.hstack(x_sample)\n",
    "    \n",
    "    y_sample = []\n",
    "    for x in x_sample:\n",
    "        normalized_dos = normalize(ldos, x)\n",
    "        y = determine_error(normalized_dos)\n",
    "        y_sample.append(y)\n",
    "        \n",
    "        \n",
    "    y_sample = torch.tensor(y_sample)\n",
    "    \n",
    "    return (x_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "84ee1531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  17,   90,   19,  ...,   26,   -7,  -35],\n",
       "         [ 103,  -57,   -2,  ...,  -65,  -68,   21],\n",
       "         [  68,  124,   19,  ...,   48, -102,   16],\n",
       "         [  47,  117,   17,  ...,   96,  -32,   52],\n",
       "         [ -28, -101,  -10,  ...,  -28,  -38,   22]]),\n",
       " tensor([0.0009, 0.0027, 0.0027, 0.0013, 0.0023]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sample(bounds, ldos[train_index], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a27e3",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "088db521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dostools.src.models.models as models\n",
    "import dostools.src.models.training as training\n",
    "import dostools.src.models.architectures as architecture\n",
    "import dostools.src.loss.loss as loss\n",
    "import torch.nn as nn\n",
    "\n",
    "importlib.reload(models)\n",
    "importlib.reload(training)\n",
    "importlib.reload(architecture)\n",
    "importlib.reload(loss)\n",
    "\n",
    "\n",
    "class ShiftErrorModel(nn.Module):\n",
    "    def __init__(self, inputSize, intermediateSize, outputSize):\n",
    "        super(ShiftErrorModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(inputSize, intermediateSize, bias = True)\n",
    "        self.fc2 = nn.Linear(intermediateSize, intermediateSize)\n",
    "        self.fc3 = nn.Linear(intermediateSize,intermediateSize)\n",
    "        self.fc4 = nn.Linear(intermediateSize, outputSize)\n",
    "        self.silu = torch.nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs the transformations to the features based on the model\n",
    "        \n",
    "        Args:\n",
    "            x (tensor): input features\n",
    "        \n",
    "        Returns:\n",
    "            tensor: output\n",
    "        \"\"\"\n",
    "        out = self.fc1(x)\n",
    "        out = self.silu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.silu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.silu(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1455252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ShiftErrorModel(831, 300, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b889b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 806:   1%|▊                                                                                                | 806/100000 [18:17:00<1910:26:00, 69.33s/it, lowest_loss=0.00173, pred_loss=0.00533, trigger=67]"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "batch_size = 16\n",
    "n_epochs = 100000\n",
    "weight_decay = 0\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr = lr, weight_decay = weight_decay)\n",
    "threshold = 1000\n",
    "scheduler_threshold = 100\n",
    "tol = 1e-4\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor = 0.1, patience = scheduler_threshold)#0.5)\n",
    "best_state = copy.deepcopy(model.state_dict())\n",
    "lowest_loss = torch.tensor(9999)\n",
    "pred_loss = torch.tensor(0)\n",
    "trigger = 0\n",
    "loss_history =[]\n",
    "pbar = tqdm(range(n_epochs))\n",
    "\n",
    "for epoch in pbar:\n",
    "    pbar.set_description(f\"Epoch: {epoch}\")\n",
    "    pbar.set_postfix(pred_loss = pred_loss.item(), lowest_loss = lowest_loss.item(), trigger = trigger)\n",
    "    opt.zero_grad()\n",
    "    x_data, y_data = generate_sample(bounds, ldos[train_index], batch_size)\n",
    "    pred = model.forward(x_data.double())\n",
    "    pred_loss = loss.t_get_mse(pred.view(-1,1), y_data.view(-1,1))#, self.xdos, perc = True)\n",
    "    new_loss = pred_loss #*1E7\n",
    "    new_loss.backward()\n",
    "    opt.step()\n",
    "    if pred_loss >100000 or (pred_loss.isnan().any()) :\n",
    "        print (\"Optimizer shows weird behaviour, reinitializing at previous best_State\")\n",
    "        model.load_state_dict(best_state)\n",
    "        opt = torch.optim.Adam(model.parameters(), lr = lr, weight_decay = weight_decay)\n",
    "    if epoch %1000 == 1:\n",
    "        loss_history.append(lowest_loss.item())\n",
    "    if lowest_loss - new_loss > tol: #threshold to stop training\n",
    "        best_state = copy.deepcopy(model.state_dict())\n",
    "        lowest_loss = new_loss\n",
    "        trigger = 0\n",
    "    else:\n",
    "        trigger +=1\n",
    "\n",
    "        if trigger > threshold:\n",
    "            weight_decay.load_state_dict(best_state)\n",
    "            for g in opt.param_groups:\n",
    "                g['lr'] = lr\n",
    "            batch_size = batch_size * 8\n",
    "            print (\"Increasing batch_size: {}\".format(lowest_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ebc76",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da43ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b97464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
