{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6feaefd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:10:59.253721Z",
     "start_time": "2023-04-14T09:10:47.847313Z"
    }
   },
   "outputs": [],
   "source": [
    "import dostools\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import time\n",
    "torch.set_default_dtype(torch.float64) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb1c188",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd01ce6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:11:13.663299Z",
     "start_time": "2023-04-14T09:11:02.337994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ldos shape is torch.Size([1039, 778])\n",
      "mean dos shape is torch.Size([778])\n"
     ]
    }
   ],
   "source": [
    "import dostools.datasets.data as data\n",
    "import dostools.utils.utils as utils\n",
    "importlib.reload(data)\n",
    "\n",
    "n_structures = 1039\n",
    "np.random.seed(0)\n",
    "n_train = int(0.8 * n_structures)\n",
    "train_index = np.arange(n_structures)\n",
    "np.random.shuffle(train_index)\n",
    "test_index = train_index[n_train:]\n",
    "train_index = train_index[:n_train]\n",
    "\n",
    "with torch.no_grad():\n",
    "    structures = data.load_structures(\":\")\n",
    "    n_structures = len(structures) #total number of structures\n",
    "    for structure in structures:#implement periodicity\n",
    "        structure.wrap(eps = 1e-12) \n",
    "    n_atoms = np.zeros(n_structures, dtype = int) #stores number of atoms in each structures\n",
    "    for i in range(n_structures):\n",
    "        n_atoms[i] = len(structures[i])\n",
    "\n",
    "    #eigenergies, emin, emax = dostools.src.datasets.data.load_eigenenergies(unpack = True, n_structures = len(structures))\n",
    "    xdos = torch.tensor(data.load_xdos())\n",
    "    ldos = torch.tensor(data.load_ldos())\n",
    "    ldos *= 2\n",
    "\n",
    "    print (\"ldos shape is {}\".format(ldos.shape))\n",
    "    mean_dos_per_atom = ldos[train_index].mean(axis = 0) #only calculated for train set to prevent data leakage\n",
    "    print (\"mean dos shape is {}\".format(mean_dos_per_atom.shape))\n",
    "    \n",
    "    \n",
    "#     y_pw = ldos - mean_dos_per_atom\n",
    "#     y_lcdf = torch.cumsum(y_pw, dim = 1)\n",
    "#     _, pc_vectors = utils.build_pc(ldos[train_index], mean_dos_per_atom[None,:], n_pc = 10)\n",
    "#     y_pc = utils.build_coeffs(ldos - mean_dos_per_atom[None,:], pc_vectors)\n",
    "#     Silicon = data.load_features()\n",
    "#     kMM = data.load_kMM()\n",
    "#     structure_eigvals_t, structure_coefficients_t, reconstructed_ldos_t = data.load_structure_gaussians()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb9aaeef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T13:36:15.370241Z",
     "start_time": "2023-04-13T13:36:15.367667Z"
    }
   },
   "outputs": [],
   "source": [
    "# sigma = 0.3\n",
    "# dx = 0.05\n",
    "# eigen_energies, emin, emax = data.load_eigenenergies(unpack = True, n_structures = 1039)\n",
    "# full_eigen_energies = [torch.tensor(i.flatten()) for i in eigen_energies]\n",
    "# eigenenergy_length = [len(i) for i in full_eigen_energies]\n",
    "# eigenenergy_length_t = torch.tensor(eigenenergy_length)\n",
    "# n_atoms_t = torch.tensor(n_atoms)\n",
    "# normalization_eiglength = [len(i) for i in eigen_energies]\n",
    "# normalization_eiglength_t = torch.tensor(normalization_eiglength)\n",
    "# normalization = 1/torch.sqrt(2*torch.tensor(np.pi)*sigma**2)/n_atoms_t/normalization_eiglength_t\n",
    "# normalization_quartic = 1/n_atoms/normalization_eiglength_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "604f8c55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:11:22.245694Z",
     "start_time": "2023-04-14T09:11:13.666410Z"
    }
   },
   "outputs": [],
   "source": [
    "#Try for full ldos and shifted ldos for splines\n",
    "emin = -24.553719539983\n",
    "max_efermi = -4.3758\n",
    "# emax = 11.346414696331\n",
    "Total_splines = torch.load(\"./Splines_dataset3.pt\").float()\n",
    "# lower_bound = torch.round(torch.tensor(emin-1.5).float(), decimals = 3)\n",
    "# upper_bound = torch.round(torch.tensor(max_efermi+3).float(), decimals = 3)\n",
    "# n_points = ((upper_bound - lower_bound)/0.001).long()\n",
    "# xaxis = torch.linspace(lower_bound,upper_bound,n_points).float()\n",
    "lower_bound = -24.553719539983-3\n",
    "upper_bound = -4.3758+3\n",
    "xaxis = torch.arange(lower_bound,upper_bound,0.001)\n",
    "import dostools.datasets.data as data\n",
    "xdos = torch.tensor(data.load_xdos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21ac924b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:11:22.254451Z",
     "start_time": "2023-04-14T09:11:22.247727Z"
    }
   },
   "outputs": [],
   "source": [
    "def manual_call2(spline_coefs, spline_positions, x):\n",
    "    \"\"\"\n",
    "    spline_coefs: shape of (n x 4 x spline_positions)\n",
    "    \n",
    "    return value: shape of (n x x)\n",
    "    \"\"\"\n",
    "    interval = torch.round(spline_positions[1] - spline_positions[0], decimals = 4)\n",
    "    indexes = torch.floor((x - spline_positions[0])/interval).long()\n",
    "    expanded_index = indexes.unsqueeze(dim=1).expand(-1,4,-1)\n",
    "    x_1 = x - spline_positions[indexes]\n",
    "    x_2 = x_1 * x_1\n",
    "    x_3 = x_2 * x_1\n",
    "    x_0 = torch.ones_like(x_1)\n",
    "    x_powers = torch.stack([x_3, x_2, x_1, x_0]).permute(1,0,2)\n",
    "    value = torch.sum(torch.mul(x_powers, torch.gather(spline_coefs, 2, expanded_index)), axis = 1) \n",
    "    \n",
    "    \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac501ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:12:25.259067Z",
     "start_time": "2023-04-14T09:11:22.256832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b53f0313092446da56a889bfb9b5eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import rascaline\n",
    "from skcosmo.feature_selection import FPS\n",
    "import scipy\n",
    "\n",
    "HYPER_PARAMETERS = {\n",
    "    \"cutoff\": 4.0,#6.0,#4.0,\n",
    "    \"max_radial\": 8,#12,#8,\n",
    "    \"max_angular\": 6,#9,#6,\n",
    "    \"atomic_gaussian_width\": 0.45,\n",
    "    \"center_atom_weight\": 1.0,\n",
    "    \"radial_basis\":{\n",
    "        \"Gto\":{}\n",
    "    },\n",
    "    \"cutoff_function\":{\n",
    "        \"Step\":{}, #maybe \n",
    "    },\n",
    "    \"radial_scaling\":{\n",
    "        \"Willatt2018\":{\n",
    "        'exponent': 5,\n",
    "        'rate' : 1,\n",
    "        'scale' : 3.,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "calculator = rascaline.SoapPowerSpectrum(**HYPER_PARAMETERS)\n",
    "descriptors = calculator.compute(structures)\n",
    "descriptors.keys_to_samples(\"species_center\")\n",
    "descriptors.keys_to_properties([\"species_neighbor_1\", \"species_neighbor_2\"])\n",
    "\n",
    "\n",
    "\n",
    "n_refs = 200\n",
    "n_atoms = descriptors.block(0).values.shape[0]\n",
    "n_structures = np.unique(descriptors.block(0).samples[\"structure\"])\n",
    "feature = torch.zeros(len(n_structures), n_refs)\n",
    "atom_descriptors = torch.tensor(descriptors.block(0).values)\n",
    "atom_descriptors = torch.nn.functional.normalize(atom_descriptors, dim = 1)\n",
    "selector = FPS(n_to_select = n_refs,\n",
    "           progress_bar = True,\n",
    "           score_threshold = 1e-12,\n",
    "           full = False,\n",
    "           initialize = 0\n",
    "          )\n",
    "selector.fit(atom_descriptors.T)\n",
    "references = selector.transform(atom_descriptors.T).T\n",
    "atomkernel_descriptors = torch.pow(atom_descriptors @ references.T, 2)\n",
    "for structure_i in n_structures:\n",
    "    a_i = descriptors.block(0).samples[\"structure\"] == structure_i\n",
    "    feature[structure_i, :] = torch.sum(atomkernel_descriptors[a_i, :], axis = 0)/np.sum(a_i)\n",
    "\n",
    "kMM = references @ references.T\n",
    "rtkMM = scipy.linalg.sqrtm(kMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a01cb532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:12:25.283090Z",
     "start_time": "2023-04-14T09:12:25.264642Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_xdos = torch.arange(lower_bound+1.5, upper_bound - 1, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c63be01",
   "metadata": {},
   "source": [
    "## Unbiased Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0ae647e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:12:26.320203Z",
     "start_time": "2023-04-14T09:12:25.285633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference training loss: 10.5108\n",
      "Reference test loss : 11.9648\n"
     ]
    }
   ],
   "source": [
    "from dostools.loss import loss\n",
    "#normal dataset\n",
    "\n",
    "\n",
    "index = train_index\n",
    "t_index = test_index\n",
    "\n",
    "\n",
    "\n",
    "Features = torch.hstack([feature[index], torch.ones(len(index)).view(-1,1)])#.type(dtype = torch.complex128)\n",
    "t_Features = torch.hstack([feature[t_index], torch.ones(len(t_index)).view(-1,1)])#.type(dtype = torch.complex128)\n",
    "# Features = torch.hstack([Silicon.Features['structure_avedescriptors'][index].double(), torch.ones(len(index)).view(-1,1)])\n",
    "# t_Features = torch.hstack([Silicon.Features['structure_avedescriptors'][t_index].double(), torch.ones(len(t_index)).view(-1,1)])\n",
    "alignment = torch.nn.parameter.Parameter(torch.zeros(len(index)))\n",
    "# alignment = torch.nn.parameter.Parameter((torch.rand(len(index))-0.5) *2 ) \n",
    "\n",
    "\n",
    "\n",
    "xdos_i = xdos.clone()\n",
    "# cutoff = torch.max(efermi) + 3\n",
    "# cutoff_index = torch.searchsorted(xdos, cutoff)\n",
    "\n",
    "train_ldos = manual_call2(Total_splines[index], xaxis, pred_xdos + alignment.view(-1,1))\n",
    "test_ldos = manual_call2(Total_splines[t_index], xaxis, pred_xdos + torch.zeros(len(t_index)).view(-1,1))\n",
    "\n",
    "best_mse = torch.tensor(100)\n",
    "best_state = alignment.clone()\n",
    "\n",
    "n_col = Features.shape[1]\n",
    "regularization = 1\n",
    "\n",
    "reg = torch.hstack([torch.real(torch.tensor(regularization * rtkMM)), torch.zeros(rtkMM.shape[0]).view(-1,1)])\n",
    "reg = torch.vstack([reg, torch.zeros(n_col)])\n",
    "\n",
    "\n",
    "reg_features = torch.vstack([Features, reg])\n",
    "reg_target = torch.vstack([train_ldos, torch.zeros(n_col,train_ldos.shape[1])])\n",
    "reference_weights = torch.linalg.lstsq(reg_features, reg_target, driver = \"gelsd\", rcond = 1e-10).solution\n",
    "reference_pred = Features @ reference_weights\n",
    "reference_t_pred = t_Features @ reference_weights\n",
    "\n",
    "\n",
    "\n",
    "train_loss = loss.t_get_rmse(reference_pred, train_ldos, pred_xdos, perc = True)#torch.mean(abs(reference_pred- train_ldos)**2) \n",
    "test_loss = loss.t_get_rmse(reference_t_pred, test_ldos, pred_xdos, perc = True)#torch.mean(abs(reference_t_pred- test_ldos)**2) \n",
    "\n",
    "print (\"Reference training loss: {:.6}\".format(train_loss))\n",
    "print (\"Reference test loss : {:.6}\".format(test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2486a2eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T09:31:16.486068Z",
     "start_time": "2023-04-14T09:31:16.454014Z"
    }
   },
   "outputs": [],
   "source": [
    "def monte_carlo_shifts(indices, alignment, n_epochs):\n",
    "    accepted = 0\n",
    "    total = 0\n",
    "    new_alignment = alignment.clone()\n",
    "    reg_features_i = torch.vstack([Features[indices], reg])\n",
    "    shifted_target = manual_call2(Total_splines[index[indices]], xaxis, pred_xdos + alignment[indices].view(-1,1))\n",
    "    shifted_reg_target = torch.vstack([shifted_target, torch.zeros(n_col,train_ldos.shape[1])])   \n",
    "    train_weights = torch.linalg.lstsq(reg_features_i, shifted_reg_target, rcond = 1e-10, driver = \"gelsd\").solution\n",
    "    shifted_train_preds = Features[i_batch] @ train_weights\n",
    "    loss_i = loss.t_get_rmse(shifted_train_preds, shifted_target, pred_xdos)\n",
    "    prev_loss = loss_i\n",
    "    for epoch in range(n_epochs):\n",
    "        new_alignment = alignment.clone()\n",
    "        new_alignment[i_batch] += (torch.rand(len(i_batch)) - 0.5)* 2 * step_size\n",
    "        new_alignment = torch.clamp(new_alignment, -1.5, 1)        \n",
    "        shifted_target = manual_call2(Total_splines[index[indices]], xaxis, pred_xdos + new_alignment[indices].view(-1,1))\n",
    "        shifted_reg_target = torch.vstack([shifted_target, torch.zeros(n_col,train_ldos.shape[1])])  \n",
    "        train_weights = torch.linalg.lstsq(reg_features_i, shifted_reg_target, rcond = 1e-10, driver = \"gelsd\").solution\n",
    "        shifted_train_preds = Features[i_batch] @ train_weights\n",
    "        loss_i = loss.t_get_rmse(shifted_train_preds, shifted_target, pred_xdos)\n",
    "        \n",
    "        \n",
    "        criteria = torch.exp(B*(prev_loss - loss_i))\n",
    "        acceptance = torch.rand(1)\n",
    "\n",
    "        if acceptance < criteria:\n",
    "            alignment = new_alignment.clone()\n",
    "            prev_loss = loss_i\n",
    "            accepted += 1\n",
    "        else:\n",
    "            loss_trajectory.append(prev_loss.item())\n",
    "\n",
    "        total += 1\n",
    "        \n",
    "    return alignment, accepted, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a8d4fc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-14T11:25:03.689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial RMSE is 0.04557377558334627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 168:  34%|██████████████████████████▉                                                     | 168/500 [3:48:57<7:33:37, 81.98s/it, AR=0.378, current_loss=0.0456, lowest_mse=0.0456, pred_loss=0.0598]"
     ]
    }
   ],
   "source": [
    "#Monte Carloception\n",
    "\n",
    "B = 10000 #Need to change\n",
    "step_size = 1e-2 #Need to change\n",
    "alignment = torch.nn.parameter.Parameter(torch.zeros(len(index)))\n",
    "batch_size = 32\n",
    "n_epochs = 500\n",
    "patience = 20\n",
    "\n",
    "Sampler = torch.utils.data.RandomSampler(index, replacement = False)\n",
    "Batcher = torch.utils.data.BatchSampler(Sampler, batch_size, False)\n",
    "\n",
    "prev_loss = torch.tensor(1)\n",
    "\n",
    "current_rmse = torch.tensor(100)\n",
    "pred_loss = torch.tensor(100)\n",
    "prev_loss = loss.t_get_rmse(reference_pred, train_ldos, pred_xdos, perc = False)\n",
    "best_mse = prev_loss.clone()\n",
    "print (\"Initial RMSE is {}\".format(prev_loss))\n",
    "trigger = 0\n",
    "accepted = 0\n",
    "total = 0\n",
    "AR = 0\n",
    "loss_trajectory = []\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(range(n_epochs))\n",
    "    for epoch in pbar:\n",
    "        pbar.set_description(f\"Epoch: {epoch}\")\n",
    "        pbar.set_postfix(pred_loss = pred_loss.item(), lowest_mse = best_mse.item(), current_loss = prev_loss.item(), AR = AR)\n",
    "        #MC\n",
    "        for i_batch in Batcher:\n",
    "            alignment, a_i, t_i = monte_carlo_shifts(i_batch, alignment, 100)\n",
    "            accepted += a_i\n",
    "            total += t_i\n",
    "        \n",
    "\n",
    "        alignment = torch.clamp(alignment, -1.5, 1)\n",
    "#             reg_features_i = torch.vstack([Features[i_batch], reg])\n",
    "        shifted_target = manual_call2(Total_splines[index], xaxis, pred_xdos + alignment.view(-1,1))\n",
    "        shifted_reg_target = torch.vstack([shifted_target, torch.zeros(n_col,train_ldos.shape[1])])   \n",
    "        train_weights = torch.linalg.lstsq(reg_features, shifted_reg_target, rcond = 1e-10, driver = \"gelsd\").solution\n",
    "        shifted_train_preds = Features @ train_weights\n",
    "        loss_i = loss.t_get_rmse(shifted_train_preds, shifted_target, pred_xdos)\n",
    "        loss_p = loss.t_get_rmse(shifted_train_preds, shifted_target, pred_xdos, perc = True).item()\n",
    "        pred_loss = loss_i\n",
    "        current_loss = loss_p\n",
    "        \n",
    "        AR = accepted/total\n",
    "        if pred_loss < best_mse:\n",
    "            best_mse = pred_loss.clone()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d14c27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c1d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5241e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf5010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Descent\n",
    "\n",
    "n_epochs = 1000000\n",
    "batch_size = 32\n",
    "patience = 20\n",
    "\n",
    "opt = torch.optim.Adam([alignment], lr = 1e-3, weight_decay = 0)\n",
    "# opt_LBFGS = torch.optim.LBFGS([alignment], lr = 1e-3, line_search_fn = 'strong_wolfe', tolerance_grad = 1e-15, tolerance_change = 1e-15)#, weight_decay = 0)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor = 0.1, patience = 20, threshold = 1e-5, min_lr = 1e-8)\n",
    "\n",
    "\n",
    "pbar = tqdm(range(n_epochs))\n",
    "for epoch in pbar:\n",
    "    pbar.set_description(f\"Epoch: {epoch}\")\n",
    "    pbar.set_postfix(pred_loss = pred_loss.item(), lowest_mse = best_mse.item(), trigger = trigger)\n",
    "    for i_batch in Batcher:\n",
    "        def closure():\n",
    "            opt.zero_grad()\n",
    "            reg_features_i = torch.vstack([Features[i_batch], reg])\n",
    "            shifted_target = manual_call2(Total_splines[index[i_batch]], xaxis, pred_xdos + alignment[i_batch].view(-1,1))\n",
    "            shifted_reg_target = torch.vstack([shifted_target, torch.zeros(n_col,train_ldos.shape[1])])          \n",
    "            train_weights = torch.linalg.lstsq(reg_features_i, shifted_reg_target, rcond = 1e-10, driver = \"gelsd\").solution\n",
    "            shifted_train_preds = Features[i_batch] @ train_weights\n",
    "            loss_i = loss.t_get_mse(shifted_train_preds, shifted_target)#torch.mean(abs(shifted_train_preds - shifted_target)**2) \n",
    "            loss_i.backward(inputs = alignment)\n",
    "            return loss_i\n",
    "        opt.step(closure)\n",
    "        train_ldos = train_ldos.detach()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        shifted_target = manual_call2(Total_splines[index], xaxis, pred_xdos + alignment.view(-1,1))\n",
    "        shifted_reg_target = torch.vstack([shifted_target, torch.zeros(n_col,train_ldos.shape[1])])          \n",
    "        train_weights = torch.linalg.lstsq(reg_features, shifted_reg_target, rcond = 1e-10, driver = \"gelsd\").solution\n",
    "        pred_i = Features @ train_weights\n",
    "        \n",
    "        \n",
    "        i_loss = loss.t_get_rmse(pred_i, shifted_target)#torch.mean(abs(pred_i - shifted_target)**2) \n",
    "        pred_loss = loss.t_get_rmse(pred_i, shifted_target, pred_xdos, perc = True)\n",
    "#         pred_loss = i_loss\n",
    "        if i_loss < prev_loss * (1 + 1e-3): \n",
    "            trigger = 0\n",
    "        else:\n",
    "            trigger +=1 \n",
    "            if trigger >= patience:\n",
    "                alignment = torch.nn.parameter.Parameter(best_state)\n",
    "                opt = torch.optim.Adam([alignment], lr = opt.param_groups[0]['lr'], weight_decay = 0)\n",
    "                counter = 0\n",
    "\n",
    "        if i_loss < best_mse:\n",
    "            best_mse = i_loss\n",
    "            best_state = alignment.clone()\n",
    "\n",
    "        prev_loss = i_loss\n",
    "\n",
    "        scheduler.step(i_loss)\n",
    "        if Batcher.batch_size > 1024:\n",
    "            break\n",
    "            \n",
    "        if opt.param_groups[0]['lr'] < 1e-3:\n",
    "            Batcher.batch_size *= 2 \n",
    "            opt.param_groups[0]['lr'] = 1e-3\n",
    "            print (\"The batch_size is now:\", Batcher.batch_size)\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "shifted_target = manual_call2(Total_splines[index], xaxis, pred_xdos + best_state.view(-1,1))\n",
    "shifted_reg_target = torch.vstack([shifted_target, torch.zeros(n_col,shifted_target.shape[1])])   \n",
    "\n",
    "\n",
    "shifted_weights = torch.linalg.lstsq(reg_features, shifted_reg_target, driver = \"gelsd\").solution\n",
    "shifted_preds = Features @ shifted_weights\n",
    "shifted_t_preds = t_Features @ shifted_weights\n",
    "\n",
    "\n",
    "shifted_train_loss = loss.t_get_rmse(shifted_preds, shifted_target, pred_xdos, perc = True)#torch.mean(abs(shifted_preds - shifted_target)**2)#\n",
    "# shifted_test_loss = loss.t_get_rmse(shifted_t_preds, shifted_ldos, xdos, perc = True) Need the one with the new loss function\n",
    "\n",
    "print (\"Final training loss: {:.6}\".format(shifted_train_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3d13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b535a772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "786px",
    "left": "51px",
    "top": "379px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
