{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84565b74",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dfdaeca7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:28:56.577267Z",
     "start_time": "2023-03-28T18:28:56.569889Z"
    }
   },
   "outputs": [],
   "source": [
    "import dostools\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import time\n",
    "torch.set_default_dtype(torch.float64) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7ccbf26d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:28:57.998901Z",
     "start_time": "2023-03-28T18:28:56.579599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ldos shape is torch.Size([1039, 778])\n",
      "mean dos shape is torch.Size([778])\n",
      "Variance covered with 10 PCs is = 0.9871211778950163\n"
     ]
    }
   ],
   "source": [
    "import dostools.datasets.data as data\n",
    "import dostools.utils.utils as utils\n",
    "\n",
    "n_structures = 1039\n",
    "np.random.seed(0)\n",
    "n_train = int(0.8 * n_structures)\n",
    "train_index = np.arange(n_structures)\n",
    "np.random.shuffle(train_index)\n",
    "test_index = train_index[n_train:]\n",
    "train_index = train_index[:n_train]\n",
    "\n",
    "with torch.no_grad():\n",
    "    structures = data.load_structures(\":\")\n",
    "    n_structures = len(structures) #total number of structures\n",
    "    for structure in structures:#implement periodicity\n",
    "        structure.wrap(eps = 1e-12) \n",
    "    n_atoms = np.zeros(n_structures, dtype = int) #stores number of atoms in each structures\n",
    "    for i in range(n_structures):\n",
    "        n_atoms[i] = len(structures[i])\n",
    "\n",
    "    #eigenergies, emin, emax = dostools.src.datasets.data.load_eigenenergies(unpack = True, n_structures = len(structures))\n",
    "    xdos = torch.tensor(data.load_xdos())\n",
    "    ldos = torch.tensor(data.load_ldos())\n",
    "    ldos *= 2\n",
    "\n",
    "    print (\"ldos shape is {}\".format(ldos.shape))\n",
    "    mean_dos_per_atom = ldos[train_index].mean(axis = 0) #only calculated for train set to prevent data leakage\n",
    "    print (\"mean dos shape is {}\".format(mean_dos_per_atom.shape))\n",
    "    \n",
    "    \n",
    "    y_pw = ldos - mean_dos_per_atom\n",
    "    y_lcdf = torch.cumsum(y_pw, dim = 1)\n",
    "    _, pc_vectors = utils.build_pc(ldos[train_index], mean_dos_per_atom[None,:], n_pc = 10)\n",
    "    y_pc = utils.build_coeffs(ldos - mean_dos_per_atom[None,:], pc_vectors)\n",
    "    Silicon = data.load_features()\n",
    "    kMM = data.load_kMM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "381681ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:02.965812Z",
     "start_time": "2023-03-28T18:28:58.001501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file contains the eigenenergies and their corresponding kpoints of the training Silicon structures generated using DFT PBE as implemented in FHI-AIMS version 171221_1 with the ``tight'' settings\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(data)\n",
    "eigen_energies, emin, emax = data.load_eigenenergies(unpack = True, n_structures = n_structures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c7af2",
   "metadata": {},
   "source": [
    "## Generate NN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cccb6b75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:03.060334Z",
     "start_time": "2023-03-28T18:29:02.975463Z"
    }
   },
   "outputs": [],
   "source": [
    "sigma = 0.3\n",
    "dx = 0.05\n",
    "\n",
    "full_eigen_energies = [torch.tensor(i.flatten()) for i in eigen_energies]\n",
    "eigenenergy_length = [len(i) for i in full_eigen_energies]\n",
    "eigenenergy_length_t = torch.tensor(eigenenergy_length)\n",
    "normalization_eiglength = [len(i) for i in eigen_energies]\n",
    "normalization_eiglength_t = torch.tensor(normalization_eiglength)\n",
    "normalization = 1/torch.sqrt(2*torch.tensor(np.pi)*sigma**2)/n_atoms/normalization_eiglength_t\n",
    "normalization_quartic = 1/n_atoms/normalization_eiglength_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6ff48068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:03.108119Z",
     "start_time": "2023-03-28T18:29:03.063010Z"
    }
   },
   "outputs": [],
   "source": [
    "#Determine right_bound as highest eigenenergy\n",
    "def determine_rightbounds(eigen_energies):\n",
    "    right_bounds = []\n",
    "    for energies in (eigen_energies):\n",
    "        right_bound = torch.max(energies)\n",
    "        right_bounds.append(right_bound)\n",
    "    right_bounds = torch.vstack(right_bounds)\n",
    "    return right_bounds\n",
    "\n",
    "\n",
    "rbounds = determine_rightbounds(full_eigen_energies)\n",
    "\n",
    "def determine_leftbounds(eigen_energies):\n",
    "    left_bounds = []\n",
    "    for energies in (eigen_energies):\n",
    "        left_bound = torch.min(energies)\n",
    "        left_bounds.append(left_bound)\n",
    "    left_bounds = torch.vstack(left_bounds)\n",
    "    return left_bounds\n",
    "lbounds = determine_leftbounds(full_eigen_energies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a6c5f365",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:03.112149Z",
     "start_time": "2023-03-28T18:29:03.110050Z"
    }
   },
   "outputs": [],
   "source": [
    "# Determine Fermi level with respect to upper bound\n",
    "# Get core level references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5d6187a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:06.040761Z",
     "start_time": "2023-03-28T18:29:03.113777Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fermi level\n",
    "import ase\n",
    "\n",
    "T_0 = 200\n",
    "beta_0 = 1 / (ase.units.kB * T_0) # inverse temperature\n",
    "efermi = np.zeros(n_structures)\n",
    "for i in range(n_structures):\n",
    "    efermi[i] = utils.getmu(ldos[i], beta_0, xdos, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "39bbc8ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:06.047410Z",
     "start_time": "2023-03-28T18:29:06.042951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.375835372334838e+00"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(efermi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b3d70a",
   "metadata": {},
   "source": [
    "## Inspecting default train-test split and generating biased dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "935d71c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:06.078583Z",
     "start_time": "2023-03-28T18:29:06.049062Z"
    }
   },
   "outputs": [],
   "source": [
    "diamond_range = np.arange(0,324,1)\n",
    "beta_tin_range = np.arange(324,604,1)\n",
    "liquid_range = np.arange(604, 673, 1)\n",
    "clusters_range = np.arange(673, 939, 1)\n",
    "amorphous_range = np.arange(939, 1039, 1)\n",
    "def find_structures_in_index(index):\n",
    "    structures = {}\n",
    "    structures['diamond'] =  np.sum(np.isin(index, diamond_range))\n",
    "    structures['beta_tin'] = np.sum(np.isin(index, beta_tin_range))\n",
    "    structures['liquid'] = np.sum(np.isin(index, liquid_range))\n",
    "    structures['clusters'] = np.sum(np.isin(index, clusters_range))\n",
    "    structures['amorphous'] = np.sum(np.isin(index, amorphous_range))\n",
    "    \n",
    "    return structures\n",
    "\n",
    "train_structures = find_structures_in_index(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "36af1a3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:06.100107Z",
     "start_time": "2023-03-28T18:29:06.081300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diamond': 249,\n",
       " 'beta_tin': 231,\n",
       " 'liquid': 58,\n",
       " 'clusters': 209,\n",
       " 'amorphous': 84}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8587576f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:06.133041Z",
     "start_time": "2023-03-28T18:29:06.103990Z"
    }
   },
   "outputs": [],
   "source": [
    "#Selected Amorphous structures\n",
    "\n",
    "amorph_train = np.arange(939,1039,1)\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(amorph_train)\n",
    "\n",
    "amorph_test = amorph_train[:80]\n",
    "amorph_train = amorph_train[80:]\n",
    "\n",
    "n_structures2 = 939\n",
    "np.random.seed(0)\n",
    "n_train = int(0.8 * 1039)-20\n",
    "remaining_train_index = np.arange(n_structures2)\n",
    "np.random.shuffle(remaining_train_index)\n",
    "\n",
    "remaining_test_index = remaining_train_index[n_train:]\n",
    "remaining_train_index = remaining_train_index[:n_train]\n",
    "\n",
    "biased_train_index = np.concatenate([remaining_train_index, amorph_train])\n",
    "biased_test_index = np.concatenate([remaining_test_index, amorph_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cb15359d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:06.177160Z",
     "start_time": "2023-03-28T18:29:06.135632Z"
    }
   },
   "outputs": [],
   "source": [
    "biased_train_structures = find_structures_in_index(biased_train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "71d34496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:06.217882Z",
     "start_time": "2023-03-28T18:29:06.180124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diamond': 278,\n",
       " 'beta_tin': 244,\n",
       " 'liquid': 60,\n",
       " 'clusters': 229,\n",
       " 'amorphous': 20}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biased_train_structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dbdbbf",
   "metadata": {},
   "source": [
    "## Quartic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ec184a5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:06.264750Z",
     "start_time": "2023-03-28T18:29:06.220492Z"
    }
   },
   "outputs": [],
   "source": [
    "#Determine bounds\n",
    "#Determine right_bound as highest eigenenergy\n",
    "rbounds = determine_rightbounds(full_eigen_energies)\n",
    "efermi = torch.tensor(efermi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "88b8889f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:06.270166Z",
     "start_time": "2023-03-28T18:29:06.266119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor(-4.3758),\n",
       "indices=tensor(723))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(efermi, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ccafc0a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:06.296249Z",
     "start_time": "2023-03-28T18:29:06.271357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor(-7.8526),\n",
       "indices=tensor(346))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(efermi, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cc5a7368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:06.333224Z",
     "start_time": "2023-03-28T18:29:06.298186Z"
    }
   },
   "outputs": [],
   "source": [
    "def quartic_dos(energies,xdos, sigma):\n",
    "   \n",
    "    left_b = energies - (np.sqrt(7) * sigma)\n",
    "\n",
    "    output = torch.zeros_like(xdos)\n",
    "\n",
    "    left_bound = torch.searchsorted(xdos, left_b)\n",
    "    \n",
    "    xdos_interval = xdos[1]-xdos[0]\n",
    "    interval = int((2 * (np.sqrt(7) * sigma))/xdos_interval) + 1\n",
    "    indexes = torch.clamp(left_bound.repeat(interval,1) + torch.arange(0,interval,1).view(-1,1), 0, len(xdos)-1)\n",
    "                     \n",
    "    E = torch.clamp((energies.view(1,-1) - xdos[indexes]), min = -1* (np.sqrt(7) * sigma), max = (np.sqrt(7) * sigma))\n",
    "    values = (E**2 - (7 * (sigma**2))) **2 / ((16/15) * (np.sqrt(7) * sigma)**5)\n",
    "    output.index_add_(0, indexes.flatten(), values.flatten())\n",
    "\n",
    "#     output = -1 * output\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ce53b9e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:07.696316Z",
     "start_time": "2023-03-28T18:29:06.335761Z"
    }
   },
   "outputs": [],
   "source": [
    "#1\n",
    "full_eigen_energies = [torch.tensor(i.flatten()) for i in eigen_energies]\n",
    "sorted_full_eigen_energies = [torch.sort(i)[0] for i in full_eigen_energies]\n",
    "# #2\n",
    "# #Sticking to sigma=0.3, 2eV above the max fermi level will correspond to max energy of 2.8ev above the max fermi level\n",
    "# sorted_full_eigen_energies_2 = []\n",
    "# for e in sorted_full_eigen_energies:\n",
    "    \n",
    "#     sorted_full_eigen_energies_2.append(e[:torch.searchsorted(e, torch.max(efermi) + 2.8)])\n",
    "# #3\n",
    "# sorted_full_eigen_energies_3 = []\n",
    "# for i,e in enumerate(sorted_full_eigen_energies):    \n",
    "#     sorted_full_eigen_energies_3.append(e[:torch.searchsorted(e, efermi[i] + 2.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1c5102e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:11.304149Z",
     "start_time": "2023-03-28T18:29:07.700876Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1039/1039 [00:03<00:00, 289.74it/s]\n"
     ]
    }
   ],
   "source": [
    "##Generate individual xdos, ldos\n",
    "with torch.no_grad():\n",
    "\n",
    "    n_xdos2 = []\n",
    "    n_ldos2 = []\n",
    "\n",
    "    sigma = torch.tensor(0.3)\n",
    "    ndos = 778 #+ int(30/0.05)\n",
    "\n",
    "\n",
    "    emin = -24.5537\n",
    "    emax = 11.3464\n",
    "\n",
    "    n_xdos2 = torch.arange(emin - 3, emax + 3,0.05)\n",
    "\n",
    "    for i in tqdm(range(n_structures)):\n",
    "        #steps = int((rbounds[i].item()- (10 * sigma) - lbounds[i].item() - 1.5)/0.05)    \n",
    "        l_dos2 = quartic_dos(sorted_full_eigen_energies[i], n_xdos2, sigma)#torch.sum(torch.exp(-0.5*((x_dos - full_eigen_energies[i].view(-1,1))/sigma)**2), dim = 0)\n",
    "    #     n_xdos2.append(x_dos2)\n",
    "        n_ldos2.append(l_dos2)\n",
    "\n",
    "    # n_xdos2 = torch.vstack(n_xdos2)\n",
    "    n_ldos2 = torch.vstack(n_ldos2)\n",
    "    n_ldos2 = ((n_ldos2.T * normalization_quartic ).T)* 2\n",
    "\n",
    "#Do cutting here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "af446d11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:55:54.727680Z",
     "start_time": "2023-03-29T11:55:54.721529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([839])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_xdos2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a2d78aa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:57:54.491271Z",
     "start_time": "2023-03-29T11:57:51.528762Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1039/1039 [00:02<00:00, 353.08it/s]\n"
     ]
    }
   ],
   "source": [
    "##Generate shifted quartic dataset\n",
    "\n",
    "\n",
    "full_xdos = []\n",
    "shifted_full_ldos = []\n",
    "\n",
    "sigma = torch.tensor(0.3)\n",
    "# ndos = 778 #+ int(30/0.05)\n",
    "\n",
    "\n",
    "emin = -24.5537\n",
    "emax = 11.3464\n",
    "\n",
    "true_alignments = (torch.rand(1039)-0.5) * 4\n",
    "\n",
    "full_xdos = torch.arange(emin - 3, emax + 3,0.05)\n",
    "for i in tqdm(range(n_structures)):\n",
    "    #steps = int((rbounds[i].item()- (10 * sigma) - lbounds[i].item() - 1.5)/0.05)\n",
    "    #x_dos2 = torch.linspace(emin - 1.5, emax + 1.5,ndos)\n",
    "    shifted_full_ldos_i = quartic_dos(sorted_full_eigen_energies[i] + true_alignments[i], full_xdos, sigma)#torch.sum(torch.exp(-0.5*((x_dos - full_eigen_energies[i].view(-1,1))/sigma)**2), dim = 0)\n",
    "#     n_xdos2.append(x_dos2)\n",
    "    shifted_full_ldos.append(shifted_full_ldos_i)\n",
    "    \n",
    "#n_xdos2 = torch.vstack(n_xdos2)\n",
    "shifted_full_ldos = torch.vstack(shifted_full_ldos)\n",
    "shifted_full_ldos = ((shifted_full_ldos.T * normalization_quartic ).T)* 2\n",
    "\n",
    "#Do cutting here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f549e7fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:11.308422Z",
     "start_time": "2023-03-28T18:29:11.306098Z"
    }
   },
   "outputs": [],
   "source": [
    "# i = 700\n",
    "# #plt.plot(n_xdos[i], n_ldos[i], c= 'r')\n",
    "# plt.plot(xdos, ldos[i], c= 'b')\n",
    "# plt.plot(xdos, n_ldos2[i], c= 'g')\n",
    "# plt.vlines(x = efermi[i], ymin = -0.05, ymax = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfd31fc",
   "metadata": {},
   "source": [
    "## Gradient descent in loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "45cfdd8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:29:51.157247Z",
     "start_time": "2023-03-28T18:29:51.152205Z"
    }
   },
   "outputs": [],
   "source": [
    "from dostools.loss.loss import t_get_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f184caef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:54:39.546974Z",
     "start_time": "2023-03-27T19:54:39.544674Z"
    }
   },
   "outputs": [],
   "source": [
    "#Goal is to only evaluate loss on the relevant energies\n",
    "# 1) Need to know the range of relevant energies \n",
    "# 2) Should train the energy levels individually,\n",
    "# 3) Need a dataset class\n",
    "# 4) Model receives data and determines which one to feed to\n",
    "# 5) Optimizer updates all relevant weights at once\n",
    "\n",
    "# To define Loss\n",
    "# 1) String together all the xdos, ldos values\n",
    "# 2) Calculate loss on that interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5769926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:54:39.558044Z",
     "start_time": "2023-03-27T19:54:39.549097Z"
    }
   },
   "outputs": [],
   "source": [
    "# Quartic polynomials\n",
    "# 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "582165de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:54:39.569056Z",
     "start_time": "2023-03-27T19:54:39.560289Z"
    }
   },
   "outputs": [],
   "source": [
    "#Need to see if i should align all at once or just one at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "3df1b4bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:57:56.482353Z",
     "start_time": "2023-03-29T11:57:56.460376Z"
    }
   },
   "outputs": [],
   "source": [
    "def MSE_shift_discrete(pred: torch.tensor, target_eigvals: list, normalization:torch.tensor, xdos: torch.tensor, rbound:int, n_epochs:int, draw = False):\n",
    "    #cannot rely solely on error values because pred might look different from target\n",
    "    alignments = []\n",
    "    all_mse = []\n",
    "    sigma = 0.3\n",
    "    patience = 20\n",
    "    counter = 0\n",
    "###DRAW\n",
    "    if draw:\n",
    "        fig, ax_list = plt.subplots(1,1)\n",
    "    #     ax_list = ax_list.flatten()\n",
    "        line, = ax_list.plot(xdos, pred[0], label = \"Aligned True\")\n",
    "        z, = ax_list.plot(xdos, pred[0], label = \"Prediction\")\n",
    "        ax_list.vlines(x = -2.3231, ymin = -0.05, ymax = 1, color = 'black')\n",
    "        fig.legend([line,z], labels = [\"Aligned True\", \"Prediction\"], loc = \"lower center\")\n",
    "\n",
    "    for i in tqdm(range(len(target_eigvals))):        \n",
    "        xdos_i = xdos\n",
    "        shift = torch.nn.parameter.Parameter(torch.tensor(0.))\n",
    "        best_mse = torch.tensor(1)\n",
    "        best_state = shift.clone()\n",
    "        opt_LBFGS = torch.optim.LBFGS([shift], lr = 100, line_search_fn = 'strong_wolfe')#, weight_decay = 0)\n",
    "        opt_adam = torch.optim.Adam([shift], lr = 1, weight_decay = 0)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_adam, factor = 0.1, patience = 20, threshold = 1e-7, min_lr = 0.01)\n",
    "        if draw:\n",
    "            z.set_ydata(pred[i].detach().numpy())\n",
    "        prev_mse = torch.tensor(1)\n",
    "        for epoch in range(n_epochs):            \n",
    "            opt_LBFGS.zero_grad()\n",
    "            def closure():\n",
    "                opt_LBFGS.zero_grad()\n",
    "                ldos_i = quartic_dos(target_eigvals[i] + shift, xdos_i, sigma)\n",
    "                ldos_i = ((ldos_i * normalization[i] ))* 2\n",
    "                mse = t_get_mse(pred[i,:rbound], ldos_i[:rbound])\n",
    "                mse.backward()\n",
    "                return mse\n",
    "                            \n",
    "            \n",
    "            if epoch == 0:\n",
    "                opt_LBFGS.step(closure)\n",
    "            else:\n",
    "                opt_adam.step(closure)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                ldos_i = quartic_dos(target_eigvals[i] + shift, xdos_i, sigma)\n",
    "                ldos_i = ((ldos_i * normalization[i] ))* 2\n",
    "                mse = t_get_mse(pred[i,:rbound], ldos_i[:rbound])\n",
    "                scheduler.step(mse)\n",
    "            if mse < best_mse:\n",
    "                \n",
    "                best_mse = mse.detach().clone()\n",
    "                best_state = shift.detach().clone()\n",
    "            \n",
    "            if mse < prev_mse * (1 - 1e-3):\n",
    "                counter = 0 \n",
    "            else:\n",
    "                counter +=1\n",
    "            prev_mse = mse\n",
    "#                 counter += 1\n",
    "#                 if counter >= patience:\n",
    "#                     shift = torch.nn.parameter.Parameter(torch.tensor(best_state))\n",
    "#                     counter = 0\n",
    "#             else:\n",
    "                \n",
    "##DRAW      \n",
    "            if draw:\n",
    "                ldos_i = quartic_dos(target_eigvals[i] + shift, xdos_i, sigma)\n",
    "                ldos_i = ((ldos_i * normalization[i] ))* 2\n",
    "                line.set_ydata(ldos_i.detach().numpy())\n",
    "                fig.suptitle(\"Epochs: {}, Shift: {:.3}, Best Shift: {:.3}, Current loss:{:.3}, Best Loss: {:.3}, LR: {}\".format(epoch, shift.item(), best_state.item(), mse.item(), best_mse.item(), opt_adam.param_groups[0]['lr']))\n",
    "                fig.canvas.draw()\n",
    "                fig.canvas.flush_events()\n",
    "            \n",
    "            \n",
    "            if mse < 1e-10:\n",
    "#                 print (\"break at lr: {}, mse : {}, epoch : {}, shift: {}\". format(opt.param_groups[0]['lr'], mse, epoch, shift.item()))\n",
    "                break\n",
    "            if best_mse.item() > 1e-5 and counter >= patience: #does not really work because i dont know when the error is unacceptable, maybe only applies to trained models?\n",
    "                shift = torch.nn.parameter.Parameter(best_state)\n",
    "                opt_adam = torch.optim.Adam([shift], lr = opt_adam.param_groups[0]['lr'], weight_decay = 0)\n",
    "                counter = 0\n",
    "                    \n",
    "            if opt_adam.param_groups[0]['lr'] < 0.1 and (counter >= patience or mse.item() < 1e-10):\n",
    "#                 print (\"break at lr: {}, mse : {}, epoch : {}, shift: {}\". format(opt.param_groups[0]['lr'], mse, epoch, shift.item()))\n",
    "                break\n",
    "\n",
    "\n",
    "        alignments.append(torch.tensor(best_state.item()))\n",
    "        ldos_i = quartic_dos(target_eigvals[i] + shift, xdos_i, sigma)\n",
    "        ldos_i = ((ldos_i * normalization_quartic[i] ))* 2\n",
    "        mse = t_get_mse(pred[i,:rbound], ldos_i[:rbound])\n",
    "        all_mse.append(mse)\n",
    "                \n",
    "        \n",
    "    all_mse = torch.vstack(all_mse)\n",
    "    alignments = torch.vstack(alignments)\n",
    "    \n",
    "    return all_mse, alignments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4814218a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:47:57.369903Z",
     "start_time": "2023-03-27T19:47:57.369891Z"
    }
   },
   "outputs": [],
   "source": [
    "def MSE_shift_continuous(x_pred, target): #Should make the model repredict the DOS at a shifted energy value\n",
    "    alignments = torch.nn.parameter.Parameter(torch.zeros(len(target)))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a4d5be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:47:57.370759Z",
     "start_time": "2023-03-27T19:47:57.370749Z"
    }
   },
   "outputs": [],
   "source": [
    "def MSE_shift_fourier(x_pred, target):\n",
    "    alignments = torch.nn.parameter.Parameter(torch.zeros(len(target)))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f361688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_shift_continuous(pred, target): #shifts the prediction values, 1) want to extract the inner representation with a method. 2) modify the energy input values at the inner representation layer, 3) optimize the optimal alignment values \n",
    "    alignments = torch.nn.parameter.Parameter(torch.tensor(0.))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "854eb832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T10:19:22.666424Z",
     "start_time": "2023-03-27T10:19:19.942612Z"
    },
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1039/1039 [00:02<00:00, 385.95it/s]\n"
     ]
    }
   ],
   "source": [
    "##Generate shifted quartic dataset\n",
    "\n",
    "\n",
    "full_xdos = []\n",
    "shifted_full_ldos = []\n",
    "\n",
    "sigma = torch.tensor(0.3)\n",
    "# ndos = 778 #+ int(30/0.05)\n",
    "\n",
    "\n",
    "emin = -24.5537\n",
    "emax = 11.3464\n",
    "\n",
    "true_alignments = (torch.rand(1039)-0.5) * 4\n",
    "\n",
    "full_xdos = torch.arange(emin - 1.5, emax + 3,0.05)\n",
    "for i in tqdm(range(n_structures)):\n",
    "    #steps = int((rbounds[i].item()- (10 * sigma) - lbounds[i].item() - 1.5)/0.05)\n",
    "    #x_dos2 = torch.linspace(emin - 1.5, emax + 1.5,ndos)\n",
    "    shifted_full_ldos_i = quartic_dos(sorted_full_eigen_energies[i] + true_alignments[i], full_xdos, sigma)#torch.sum(torch.exp(-0.5*((x_dos - full_eigen_energies[i].view(-1,1))/sigma)**2), dim = 0)\n",
    "#     n_xdos2.append(x_dos2)\n",
    "    shifted_full_ldos.append(shifted_full_ldos_i)\n",
    "    \n",
    "#n_xdos2 = torch.vstack(n_xdos2)\n",
    "shifted_full_ldos = torch.vstack(shifted_full_ldos)\n",
    "shifted_full_ldos = ((shifted_full_ldos.T * normalization_quartic ).T)* 2\n",
    "\n",
    "#Do cutting here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14394287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T10:19:12.458430Z",
     "start_time": "2023-03-27T10:19:12.402681Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6445e81a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T11:55:07.887185Z",
     "start_time": "2023-03-27T11:42:17.206424Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1039/1039 [12:50<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "j = 1039\n",
    "\n",
    "mse3, shift3 = MSE_shift_discrete(shifted_full_ldos[i:i+j], sorted_full_eigen_energies[i:i+j], normalization_quartic[i:i+j], full_xdos, 479, 300, draw = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64da990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37bf0843",
   "metadata": {},
   "source": [
    "## Linalg-Shift, Full dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "94910032",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:30:03.309024Z",
     "start_time": "2023-03-28T18:30:03.305576Z"
    }
   },
   "outputs": [],
   "source": [
    "import dostools.loss.loss as loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analytical_weights(feature, target, regularization):\n",
    "    n_col = feature.shape[1]\n",
    "    reg = regularization * torch.eye(n_col)\n",
    "    reg[n_col-1,n_col-1] = 0\n",
    "    weights = torch.linalg.lstsq(feature.T @ feature + reg, feature.T @ target, driver = 'gelsd').solution\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5e65beb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T09:02:36.158767Z",
     "start_time": "2023-03-29T09:02:36.150611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "74f25280",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T12:10:45.054420Z",
     "start_time": "2023-03-29T12:10:45.049591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([839])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "d6c9e22d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T10:08:59.306424Z",
     "start_time": "2023-03-31T10:05:20.154231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference training loss: 38.44\n",
      "Reference test loss : 37.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 26:   0%|                                                                                      | 26/200000 [03:36<461:29:03,  8.31s/it, current_rmse=37.7, lowest_mse=0.00105, pred_loss=0.00106, trigger=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training loss: 2.332\n"
     ]
    }
   ],
   "source": [
    "### normal dataset\n",
    "\n",
    "batch_size = 831\n",
    "sigma = 0.3\n",
    "n_epochs = 200000\n",
    "patience = 20\n",
    "\n",
    "index = train_index\n",
    "t_index = test_index\n",
    "\n",
    "Sampler = torch.utils.data.RandomSampler(index, replacement = False)\n",
    "Batcher = torch.utils.data.BatchSampler(Sampler, batch_size, False)\n",
    "\n",
    "Features = torch.hstack([Silicon.Features['structure_avekerneldescriptors'][index].double(), torch.ones(len(index)).view(-1,1)])\n",
    "t_Features = torch.hstack([Silicon.Features['structure_avekerneldescriptors'][t_index].double(), torch.ones(len(t_index)).view(-1,1)])\n",
    "alignment = torch.nn.parameter.Parameter(torch.zeros(len(index)))\n",
    "\n",
    "opt = torch.optim.Adam([alignment], lr = 1e-2, weight_decay = 0)\n",
    "# opt = torch.optim.LBFGS([alignment], lr = 1e-9, line_search_fn = 'strong_wolfe')\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor = 0.1, patience = 5, threshold = 1e-7, min_lr = 1e-5)\n",
    "\n",
    "xdos = n_xdos2\n",
    "cutoff = torch.max(efermi) + 3\n",
    "cutoff_index = torch.searchsorted(xdos, cutoff)\n",
    "\n",
    "# ldos = shifted_full_ldos[index,:cutoff_index].clone()#\n",
    "ldos = n_ldos2[index,:cutoff_index].clone()\n",
    "\n",
    "train_ldos = ldos.clone()\n",
    "\n",
    "best_mse = torch.tensor(100)\n",
    "best_state = alignment.clone()\n",
    "\n",
    "n_col = Features.shape[1]\n",
    "regularization = 1\n",
    "reg = regularization * torch.eye(n_col)\n",
    "reg[n_col-1, n_col-1] = 0\n",
    "reg_features = Features.T @ Features + reg\n",
    "reference_weights = torch.linalg.lstsq(reg_features, Features.T @ ldos, driver = \"gelsd\").solution\n",
    "reference_pred = Features @ reference_weights\n",
    "reference_t_pred = t_Features @ reference_weights\n",
    "\n",
    "train_loss = loss.t_get_rmse(reference_pred, ldos, xdos[:cutoff_index], perc = True)\n",
    "test_loss = loss.t_get_rmse(reference_t_pred, n_ldos2[t_index,:cutoff_index], xdos[:cutoff_index], perc = True)\n",
    "current_rmse = torch.tensor(100)\n",
    "pred_loss = torch.tensor(100)\n",
    "prev_loss = torch.tensor(100)\n",
    "trigger = 0\n",
    "print (\"Reference training loss: {:.4}\".format(train_loss))\n",
    "print (\"Reference test loss : {:.4}\".format(test_loss))\n",
    "\n",
    "pbar = tqdm(range(n_epochs))\n",
    "for epoch in pbar:\n",
    "    pbar.set_description(f\"Epoch: {epoch}\")\n",
    "    pbar.set_postfix(pred_loss = pred_loss.item(), lowest_mse = best_mse.item(), current_rmse = current_rmse.item(), trigger = trigger)\n",
    "    \n",
    "    for i_batch in Batcher:\n",
    "        def closure():\n",
    "            global train_ldos\n",
    "            opt.zero_grad()\n",
    "            for i in i_batch:\n",
    "                ldos_i = quartic_dos(sorted_full_eigen_energies[index[i]] + alignment[i], xdos, sigma) * normalization_quartic[i] * 2\n",
    "                train_ldos[i] = ldos_i[:cutoff_index]\n",
    "            train_weights = torch.linalg.lstsq(reg_features, Features.T @ train_ldos, driver = \"gelsd\").solution\n",
    "            train_pred = Features @ train_weights\n",
    "            loss_i = loss.t_get_mse(train_pred, train_ldos)\n",
    "            loss_i.backward(inputs = alignment)\n",
    "            train_ldos = train_ldos.detach()\n",
    "            return loss_i\n",
    "        opt.step(closure)\n",
    "        train_ldos = train_ldos.detach()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        train_ldos = []\n",
    "        for i in range(len(index)):  \n",
    "            l_dosi = quartic_dos(sorted_full_eigen_energies[index[i]] + alignment[i], xdos, sigma)\n",
    "            \n",
    "    #     n_xdos2.append(x_dos2)\n",
    "            train_ldos.append(l_dosi[:cutoff_index])\n",
    "    \n",
    "    # n_xdos2 = torch.vstack(n_xdos2)\n",
    "        train_ldos = torch.vstack(train_ldos)\n",
    "        train_ldos = ((train_ldos.T * normalization_quartic[index] ).T)* 2\n",
    "\n",
    "        weights_i = torch.linalg.lstsq(reg_features, Features.T @ train_ldos, driver = \"gelsd\").solution\n",
    "        pred_i = Features @ weights_i\n",
    "\n",
    "        i_loss = loss.t_get_mse(pred_i, train_ldos)\n",
    "        i_rmse = loss.t_get_rmse(pred_i, train_ldos, xdos[:cutoff_index], perc = True)\n",
    "    \n",
    "    \n",
    "        pred_loss = i_loss\n",
    "        if i_loss < prev_loss * (1 + 1e-3): \n",
    "            trigger = 0\n",
    "        else:\n",
    "            trigger +=1 \n",
    "            if trigger >= patience:\n",
    "                alignment = torch.nn.parameter.Parameter(best_state)\n",
    "                opt = torch.optim.Adam([alignment], lr = opt.param_groups[0]['lr'], weight_decay = 0)\n",
    "                counter = 0\n",
    "\n",
    "        if i_loss < best_mse:\n",
    "            best_mse = i_loss\n",
    "            best_state = alignment.clone()\n",
    "\n",
    "        prev_loss = i_loss\n",
    "        current_rmse = i_rmse\n",
    "\n",
    "        scheduler.step(i_loss)\n",
    "\n",
    "        if opt.param_groups[0]['lr'] < 1e-4:\n",
    "            break\n",
    "\n",
    "            \n",
    "shifted_ldos = []\n",
    "for i in range(len(index)):\n",
    "    shifted_ldos_i = quartic_dos(sorted_full_eigen_energies[index[i]] + torch.clamp(best_state[i], -3,3), xdos, sigma)\n",
    "    shifted_ldos.append(shifted_ldos_i)\n",
    "    \n",
    "shifted_ldos = torch.vstack(shifted_ldos)\n",
    "shifted_ldos = ((shifted_ldos.T * normalization_quartic[index]).T) * 2\n",
    "\n",
    "shifted_weights = torch.linalg.lstsq(Features, shifted_ldos, driver = \"gelsd\").solution\n",
    "shifted_preds = Features @ shifted_weights\n",
    "shifted_t_preds = t_Features @ shifted_weights\n",
    "\n",
    "\n",
    "shifted_train_loss = loss.t_get_rmse(shifted_preds, shifted_ldos, xdos, perc = True)\n",
    "# shifted_test_loss = loss.t_get_rmse(shifted_t_preds, shifted_ldos, xdos, perc = True) Need the one with the new loss function\n",
    "\n",
    "print (\"Final training loss: {:.4}\".format(shifted_train_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "b30fe43a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T11:01:18.215544Z",
     "start_time": "2023-03-31T11:01:15.504414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training loss: 2.507\n"
     ]
    }
   ],
   "source": [
    "shifted_ldos = []\n",
    "for i in range(len(index)):\n",
    "    shifted_ldos_i = quartic_dos(sorted_full_eigen_energies[index[i]] + torch.clamp(best_state[i], -3,3), xdos, sigma)\n",
    "    shifted_ldos.append(shifted_ldos_i)\n",
    "    \n",
    "shifted_ldos = torch.vstack(shifted_ldos)\n",
    "shifted_ldos = ((shifted_ldos.T * normalization_quartic[index]).T) * 2\n",
    "\n",
    "shifted_weights = torch.linalg.lstsq(Features, shifted_ldos[:,:cutoff_index], driver = \"gelsd\").solution\n",
    "shifted_preds = Features @ shifted_weights\n",
    "shifted_t_preds = t_Features @ shifted_weights\n",
    "\n",
    "\n",
    "shifted_train_loss = loss.t_get_rmse(shifted_preds, shifted_ldos[:,:cutoff_index], xdos[:cutoff_index], perc = True)\n",
    "# shifted_test_loss = loss.t_get_rmse(shifted_t_preds, shifted_ldos, xdos, perc = True) Need the one with the new loss function\n",
    "\n",
    "print (\"Final training loss: {:.4}\".format(shifted_train_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "87fc2102",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T11:02:23.797701Z",
     "start_time": "2023-03-31T11:02:23.647018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference training loss: 8.175\n",
      "Reference test loss : 10.08\n"
     ]
    }
   ],
   "source": [
    "regularization = 0\n",
    "reg = regularization * torch.eye(n_col)\n",
    "reg[n_col-1, n_col-1] = 0\n",
    "reg_features = Features.T @ Features + reg\n",
    "reference_weights = torch.linalg.lstsq(reg_features, Features.T @ n_ldos2[index,:cutoff_index], driver = \"gelsd\").solution\n",
    "reference_pred = Features @ reference_weights\n",
    "reference_t_pred = t_Features @ reference_weights\n",
    "\n",
    "train_loss = loss.t_get_rmse(reference_pred, n_ldos2[index, :cutoff_index], xdos[:cutoff_index], perc = True)\n",
    "test_loss = loss.t_get_rmse(reference_t_pred, n_ldos2[t_index,:cutoff_index], xdos[:cutoff_index], perc = True)\n",
    "current_rmse = torch.tensor(100)\n",
    "pred_loss = torch.tensor(100)\n",
    "prev_loss = torch.tensor(100)\n",
    "trigger = 0\n",
    "print (\"Reference training loss: {:.4}\".format(train_loss))\n",
    "print (\"Reference test loss : {:.4}\".format(test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "554fa3e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T11:10:14.010027Z",
     "start_time": "2023-03-31T11:10:14.003770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1001, 524])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "6f8dc4ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T11:10:21.169842Z",
     "start_time": "2023-03-31T11:10:21.163664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([831, 1001])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "b41b01e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T11:22:47.977804Z",
     "start_time": "2023-03-31T11:22:47.970391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1001, 524])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02731133",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "4a3ec570",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T12:22:09.952516Z",
     "start_time": "2023-03-31T12:22:09.868466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.9378e+23)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.cond(Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "ccec8362",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T13:47:03.992097Z",
     "start_time": "2023-03-31T13:47:03.786711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training loss: 5.389\n"
     ]
    }
   ],
   "source": [
    "Features = torch.hstack([Silicon.Features['structure_avekerneldescriptors'][index].double(), torch.ones(len(index)).view(-1,1)])\n",
    "t_Features = torch.hstack([Silicon.Features['structure_avekerneldescriptors'][t_index].double(), torch.ones(len(t_index)).view(-1,1)])\n",
    "\n",
    "\n",
    "matinv = torch.linalg.inv(Features.T @ Features)\n",
    "weight = matinv @ Features.T @ n_ldos2[index,:cutoff_index]\n",
    "\n",
    "shifted_weights = torch.linalg.lstsq(Features.T @ Features, Features.T @ n_ldos2[index,:cutoff_index], driver = \"gelsd\", rcond = 1e-15).solution\n",
    "shifted_preds = Features @ shifted_weights\n",
    "# shifted_preds2 = Features @ weight\n",
    "\n",
    "\n",
    "shifted_train_loss = loss.t_get_rmse(shifted_preds, n_ldos2[index,:cutoff_index], xdos[:cutoff_index], perc = True)\n",
    "shifted_train_loss2 = loss.t_get_rmse(shifted_preds2, n_ldos2[index,:cutoff_index], xdos[:cutoff_index], perc = True)\n",
    "\n",
    "# shifted_test_loss = loss.t_get_rmse(shifted_t_preds, shifted_ldos, xdos, perc = True) Need the one with the new loss function\n",
    "\n",
    "print (\"Final training loss: {:.4}\".format(shifted_train_loss))\n",
    "# print (\"Final training loss2: {:.4}\".format(shifted_train_loss2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "4694f0ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T11:01:32.275844Z",
     "start_time": "2023-03-31T11:01:32.115502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference training loss: 11.7\n",
      "Reference test loss : 10.08\n"
     ]
    }
   ],
   "source": [
    "regularization = 0\n",
    "reg = regularization * torch.eye(n_col)\n",
    "reg[n_col-1, n_col-1] = 0\n",
    "reg_features = Features.T @ Features + reg\n",
    "reference_weights = torch.linalg.lstsq(reg_features, Features.T @ shifted_ldos[:, :cutoff_index], driver = \"gelsd\").solution\n",
    "reference_pred = Features @ reference_weights\n",
    "reference_t_pred = t_Features @ reference_weights\n",
    "\n",
    "train_loss = loss.t_get_rmse(reference_pred, shifted_ldos[:, :cutoff_index], xdos[:cutoff_index], perc = True)\n",
    "current_rmse = torch.tensor(100)\n",
    "pred_loss = torch.tensor(100)\n",
    "prev_loss = torch.tensor(100)\n",
    "trigger = 0\n",
    "print (\"Reference training loss: {:.4}\".format(train_loss))\n",
    "print (\"Reference test loss : {:.4}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "33838e1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T10:14:17.836274Z",
     "start_time": "2023-03-31T10:14:17.831220Z"
    }
   },
   "outputs": [],
   "source": [
    "alignment_1 = best_state.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "143cec57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T12:11:23.906748Z",
     "start_time": "2023-03-29T12:11:23.872441Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "trapezoid: There must be one `x` value for each sample point",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [242]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m i_rmse \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt_get_rmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ldos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxdos\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcutoff_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dostools/src/dostools/loss/loss.py:38\u001b[0m, in \u001b[0;36mt_get_rmse\u001b[0;34m(a, b, xdos, perc)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xdos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a\u001b[38;5;241m.\u001b[39msize()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 38\u001b[0m         rmse \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt((\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrapezoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxdos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m         rmse \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt((torch\u001b[38;5;241m.\u001b[39mtrapezoid((a \u001b[38;5;241m-\u001b[39m b)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, xdos, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mmean())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: trapezoid: There must be one `x` value for each sample point"
     ]
    }
   ],
   "source": [
    "i_rmse = loss.t_get_rmse(pred_i, train_ldos, xdos[:cutoff_index], perc = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "93198ded",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T12:11:52.271104Z",
     "start_time": "2023-03-29T12:11:52.264701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(524)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c6df9c89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T12:11:36.660547Z",
     "start_time": "2023-03-29T12:11:36.654357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([831, 839])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ad443af0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T12:11:42.276878Z",
     "start_time": "2023-03-29T12:11:42.270808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([831, 839])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ldos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f310d09d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:21:16.375671Z",
     "start_time": "2023-03-28T18:14:55.033259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference training loss: 3.98\n",
      "Reference test loss : 39.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:   0%|                                                                                                              | 0/10000 [06:19<?, ?it/s, current_rmse=100, lowest_mse=100, pred_loss=100, trigger=0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [144]\u001b[0m, in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         train_ldos \u001b[38;5;241m=\u001b[39m train_ldos\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m loss_i\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     train_ldos \u001b[38;5;241m=\u001b[39m train_ldos\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:426\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directional_evaluate(closure, x, t, d)\n\u001b[0;32m--> 426\u001b[0m     loss, flat_grad, t, ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[43m_strong_wolfe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[1;32m    429\u001b[0m opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:148\u001b[0m, in \u001b[0;36m_strong_wolfe\u001b[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[1;32m    145\u001b[0m     insuf_progress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Evaluate new point\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m f_new, g_new \u001b[38;5;241m=\u001b[39m \u001b[43mobj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m ls_func_evals \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    150\u001b[0m gtd_new \u001b[38;5;241m=\u001b[39m g_new\u001b[38;5;241m.\u001b[39mdot(d)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:424\u001b[0m, in \u001b[0;36mLBFGS.step.<locals>.obj_func\u001b[0;34m(x, t, d)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[0;32m--> 424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_directional_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:277\u001b[0m, in \u001b[0;36mLBFGS._directional_evaluate\u001b[0;34m(self, closure, x, t, d)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_directional_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure, x, t, d):\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(closure())\n\u001b[1;32m    279\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:265\u001b[0m, in \u001b[0;36mLBFGS._add_grad\u001b[0;34m(self, step_size, update)\u001b[0m\n\u001b[1;32m    263\u001b[0m     numel \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;66;03m# view as to avoid deprecated pointwise semantics\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m[\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m:\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m     offset \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numel\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m offset \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numel()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#normal dataset\n",
    "\n",
    "batch_size = 831\n",
    "sigma = 0.3\n",
    "n_epochs = 10000\n",
    "patience = 20\n",
    "\n",
    "index = train_index\n",
    "t_index = test_index\n",
    "\n",
    "Sampler = torch.utils.data.RandomSampler(index, replacement = False)\n",
    "Batcher = torch.utils.data.BatchSampler(Sampler, batch_size, False)\n",
    "\n",
    "Features = torch.hstack([Silicon.Features['structure_avedescriptors'][index].double(), torch.ones(len(index)).view(-1,1)])\n",
    "t_Features = torch.hstack([Silicon.Features['structure_avedescriptors'][t_index].double(), torch.ones(len(t_index)).view(-1,1)])\n",
    "alignment = torch.nn.parameter.Parameter(torch.zeros(len(index)))\n",
    "\n",
    "#opt = torch.optim.Adam([alignment], lr = 0.01, weight_decay = 0)\n",
    "opt = torch.optim.LBFGS([alignment], lr = 100, line_search_fn = 'strong_wolfe')\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor = 0.1, patience = 50, threshold = 1e-7, min_lr = 0.00001)\n",
    "\n",
    "xdos = n_xdos2\n",
    "ldos = n_ldos2[index].clone()\n",
    "\n",
    "train_ldos = ldos.clone()\n",
    "\n",
    "best_mse = torch.tensor(100)\n",
    "best_state = alignment.clone()\n",
    "\n",
    "reference_weights = torch.linalg.lstsq(Features, ldos, driver = \"gelsd\").solution\n",
    "reference_pred = Features @ reference_weights\n",
    "reference_t_pred = t_Features @ reference_weights\n",
    "\n",
    "train_loss = loss.t_get_rmse(reference_pred, ldos, xdos, perc = True)\n",
    "test_loss = loss.t_get_rmse(reference_t_pred, n_ldos2[t_index], xdos, perc = True)\n",
    "current_rmse = torch.tensor(100)\n",
    "pred_loss = torch.tensor(100)\n",
    "prev_loss = torch.tensor(100)\n",
    "trigger = 0\n",
    "print (\"Reference training loss: {:.4}\".format(train_loss))\n",
    "print (\"Reference test loss : {:.4}\".format(test_loss))\n",
    "pbar = tqdm(range(n_epochs))\n",
    "\n",
    "for epoch in pbar:\n",
    "    pbar.set_description(f\"Epoch: {epoch}\")\n",
    "    pbar.set_postfix(pred_loss = pred_loss.item(), lowest_mse = best_mse.item(), current_rmse = current_rmse.item(), trigger = trigger)\n",
    "    \n",
    "    for i_batch in Batcher:\n",
    "        def closure():\n",
    "            global train_ldos\n",
    "            opt.zero_grad()\n",
    "            for i in i_batch:\n",
    "                ldos_i = quartic_dos(sorted_full_eigen_energies[index[i]] + torch.clamp(alignment[i], -3 , 3), xdos, sigma) * normalization_quartic[i] * 2\n",
    "                train_ldos[i] = ldos_i\n",
    "            train_weights = torch.linalg.lstsq(Features, train_ldos, driver = \"gelsd\").solution\n",
    "            train_pred = Features @ train_weights        \n",
    "            loss_i = loss.t_get_mse(train_pred, train_ldos)\n",
    "            loss_i.backward(inputs = alignment)\n",
    "            train_ldos = train_ldos.detach()\n",
    "            return loss_i\n",
    "        opt.step(closure)\n",
    "        train_ldos = train_ldos.detach()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        n_ldos = []\n",
    "        for i in range(len(index)):  \n",
    "            l_dosi = quartic_dos(sorted_full_eigen_energies[index[i]] + torch.clamp(alignment[i], -3 , 3), xdos, sigma)\n",
    "            \n",
    "    #     n_xdos2.append(x_dos2)\n",
    "            n_ldos.append(l_dosi)\n",
    "    \n",
    "    # n_xdos2 = torch.vstack(n_xdos2)\n",
    "        n_ldos = torch.vstack(n_ldos)\n",
    "        n_ldos = ((n_ldos.T * normalization_quartic[index] ).T)* 2\n",
    "\n",
    "        weights_i = torch.linalg.lstsq(Features, n_ldos, driver = \"gelsd\").solution\n",
    "        pred_i = Features @ weights_i\n",
    "\n",
    "        i_loss = loss.t_get_mse(pred_i, n_ldos)\n",
    "        i_rmse = loss.t_get_rmse(pred_i, n_ldos, xdos, perc = True)\n",
    "    \n",
    "    \n",
    "        pred_loss = i_loss\n",
    "        if i_loss < prev_loss * (1 - 1e-3): \n",
    "            trigger = 0\n",
    "        else:\n",
    "            trigger +=1 \n",
    "            if trigger >= patience:\n",
    "                alignment = torch.nn.parameter.Parameter(best_state)\n",
    "                opt = torch.optim.Adam([alignment], lr = opt.param_groups[0]['lr'], weight_decay = 0)\n",
    "                counter = 0\n",
    "\n",
    "        if i_loss < best_mse:\n",
    "            best_mse = i_loss\n",
    "            best_state = alignment.clone()\n",
    "\n",
    "        prev_loss = i_loss\n",
    "        current_rmse = i_rmse\n",
    "\n",
    "        scheduler.step(i_loss)\n",
    "\n",
    "        if opt.param_groups[0]['lr'] < 0.0001:\n",
    "            break\n",
    "\n",
    "            \n",
    "shifted_ldos = []\n",
    "for i in range(len(index)):\n",
    "    shifted_ldos_i = quartic_dos(sorted_full_eigen_energies[index[i]] + torch.clamp(best_state[i], -3,3), xdos, sigma)\n",
    "    shifted_ldos.append(shifted_ldos_i)\n",
    "    \n",
    "shifted_ldos = torch.vstack(shifted_ldos)\n",
    "shifted_ldos = ((shifted_ldos.T * normalization_quartic[index]).T) * 2\n",
    "\n",
    "shifted_weights = torch.linalg.lstsq(Features, shifted_ldos, driver = \"gelsd\").solution\n",
    "shifted_preds = Features @ shifted_weights\n",
    "shifted_t_preds = t_Features @ shifted_weights\n",
    "\n",
    "\n",
    "shifted_train_loss = loss.t_get_rmse(shifted_preds, shifted_ldos, xdos, perc = True)\n",
    "# shifted_test_loss = loss.t_get_rmse(shifted_t_preds, shifted_ldos, xdos, perc = True) Need the one with the new loss function\n",
    "\n",
    "print (\"Final training loss: {:.4}\".format(shifted_train_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de674a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T20:39:13.422980Z",
     "start_time": "2023-03-27T20:39:13.422965Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#Biased dataset, fix the indexing issues\n",
    "\n",
    "sigma = 0.3\n",
    "n_epochs = 10000\n",
    "\n",
    "index = biased_train_index\n",
    "t_index = biased_test_index\n",
    "\n",
    "Features = torch.hstack([Silicon.Features['structure_avedescriptors'][index].double(), torch.ones(len(index)).view(-1,1)])\n",
    "\n",
    "t_Features = torch.hstack([Silicon.Features['structure_avedescriptors'][t_index].double(), torch.ones(len(t_index)).view(-1,1)])\n",
    "\n",
    "biased_alignment = torch.nn.parameter.Parameter(torch.zeros(len(index)))\n",
    "opt = torch.optim.Adam([biased_alignment], lr = 0.5, weight_decay = 0)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor = 0.1, patience = 20, threshold = 1e-7, min_lr = 0.001)\n",
    "\n",
    "xdos = n_xdos2\n",
    "ldos = n_ldos2[index]\n",
    "\n",
    "best_mse = torch.tensor(100)\n",
    "best_state = alignment.clone()\n",
    "\n",
    "reference_weights = torch.linalg.lstsq(Features, ldos, driver = \"gelsd\").solution\n",
    "reference_pred = Features @ reference_weights\n",
    "reference_t_pred = t_Features @ reference_weights\n",
    "\n",
    "train_loss = loss.t_get_rmse(reference_pred, ldos, xdos, perc = True)\n",
    "test_loss = loss.t_get_rmse(reference_t_pred, n_ldos2[t_index], xdos, perc = True)\n",
    "current_rmse = torch.tensor(100)\n",
    "pred_loss = torch.tensor(100)\n",
    "prev_loss = torch.tensor(100)\n",
    "trigger = 0\n",
    "print (\"Reference training loss: {:.4}\".format(train_loss))\n",
    "print (\"Reference test loss : {:.4}\".format(test_loss))\n",
    "pbar = tqdm(range(n_epochs))\n",
    "for epoch in pbar:\n",
    "    pbar.set_description(f\"Epoch: {epoch}\")\n",
    "    pbar.set_postfix(pred_loss = pred_loss.item(), lowest_mse = best_mse.item(), current_rmse = current_rmse.item(), trigger = trigger)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    n_ldos = []\n",
    "    for i in range(len(index)):  \n",
    "        l_dosi = quartic_dos(sorted_full_eigen_energies[i] + biased_alignment[i], xdos, sigma)\n",
    "#     n_xdos2.append(x_dos2)\n",
    "        n_ldos.append(l_dosi)\n",
    "    \n",
    "    # n_xdos2 = torch.vstack(n_xdos2)\n",
    "    n_ldos = torch.vstack(n_ldos)\n",
    "    n_ldos = ((n_ldos.T * normalization_quartic[index] ).T)* 2\n",
    "    \n",
    "    weights_i = torch.linalg.lstsq(Features, n_ldos, driver = \"gelsd\").solution\n",
    "    pred_i = Features @ weights_i\n",
    "    \n",
    "    i_loss = loss.t_get_mse(pred_i, n_ldos)\n",
    "    i_rmse = loss.t_get_rmse(pred_i, n_ldos, xdos, perc = True)\n",
    "    \n",
    "    i_loss.backward()\n",
    "    pred_loss = i_loss\n",
    "    if i_loss < prev_loss * (1 - 1e-3): \n",
    "        trigger = 0\n",
    "    else:\n",
    "        trigger +=1 \n",
    "        if trigger >= patience:\n",
    "            alignment = torch.nn.parameter.Parameter(best_state)\n",
    "            opt = torch.optim.Adam([shift], lr = opt.param_groups[0]['lr'], weight_decay = 0)\n",
    "            counter = 0\n",
    "            \n",
    "    if i_loss < best_mse:\n",
    "        best_mse = i_loss\n",
    "        best_state = alignment.clone()\n",
    "        \n",
    "    prev_loss = i_loss\n",
    "    current_rmse = i_rmse\n",
    "    \n",
    "    opt.step()\n",
    "    scheduler.step(i_loss)\n",
    "    torch.clamp(alignment, min = -3, max = 3)\n",
    "    \n",
    "    if opt.param_groups[0]['lr'] < 0.01:\n",
    "        break\n",
    "shifted_ldos = []\n",
    "for i in range(n_structures):\n",
    "    shifted_ldos_i = quartic_dos(sorted_full_eigen_energies[i] + best_state[i], xdos, sigma)\n",
    "    shifted_ldos.append(shifted_ldos_i)\n",
    "    \n",
    "shifted_ldos = torch.vstack(shifted_ldos)\n",
    "shifted_ldos = ((shifted_ldos.T * normalization_quartic).T) * 2\n",
    "\n",
    "shifted_weights = torch.linalg.lstsq(Features, shifted_ldos[index], driver = \"gelsd\").solution\n",
    "shifted_preds = Features @ shifted_weights\n",
    "shifted_t_preds = t_Features @ shifted_weights\n",
    "\n",
    "\n",
    "shifted_train_loss = loss.t_get_rmse(shifted_preds, shifted_ldos, xdos, perc = True)\n",
    "shifted_test_loss = loss.t_get_rmse(shifted_t_preds, shifted_ldos, xdos, perc = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9f7244c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T20:12:06.522293Z",
     "start_time": "2023-03-27T20:12:06.510189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.0065, grad_fn=<UnbindBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(biased_alignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d0f9f",
   "metadata": {},
   "source": [
    "## Linalg-Shift, fixed interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9963ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal dataset\n",
    "\n",
    "sigma = 0.3\n",
    "n_epochs = 10000\n",
    "patience = 20\n",
    "\n",
    "index = train_index\n",
    "t_index = test_index\n",
    "\n",
    "cutoff_index = \n",
    "\n",
    "Features = torch.hstack([Silicon.Features['structure_avedescriptors'][index].double(), torch.ones(len(index)).view(-1,1)])\n",
    "t_Features = torch.hstack([Silicon.Features['structure_avedescriptors'][t_index].double(), torch.ones(len(t_index)).view(-1,1)])\n",
    "alignment = torch.nn.parameter.Parameter(torch.zeros(len(index)))\n",
    "\n",
    "opt = torch.optim.Adam([alignment], lr = 1, weight_decay = 0)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor = 0.1, patience = 20, threshold = 1e-7, min_lr = 0.001)\n",
    "\n",
    "xdos = n_xdos2\n",
    "ldos = n_ldos2[train_index]\n",
    "\n",
    "best_mse = torch.tensor(100)\n",
    "best_state = alignment.clone()\n",
    "\n",
    "reference_weights = torch.linalg.lstsq(Features, ldos, driver = \"gelsd\").solution\n",
    "reference_pred = Features @ reference_weights\n",
    "reference_t_pred = t_Features @ reference_weights\n",
    "\n",
    "train_loss = loss.t_get_rmse(reference_pred, ldos, xdos, perc = True)\n",
    "test_loss = loss.t_get_rmse(reference_t_pred, n_ldos2[t_index], xdos, perc = True)\n",
    "current_rmse = torch.tensor(100)\n",
    "pred_loss = torch.tensor(100)\n",
    "prev_loss = torch.tensor(100)\n",
    "trigger = 0\n",
    "print (\"Reference training loss: {:.4}\".format(train_loss))\n",
    "print (\"Reference test loss : {:.4}\".format(test_loss))\n",
    "pbar = tqdm(range(n_epochs))\n",
    "for epoch in pbar:\n",
    "    pbar.set_description(f\"Epoch: {epoch}\")\n",
    "    pbar.set_postfix(pred_loss = pred_loss.item(), lowest_mse = best_mse.item(), current_rmse = current_rmse.item(), trigger = trigger)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    n_ldos = []\n",
    "    for i in range(len(index)):  \n",
    "        l_dosi = quartic_dos(sorted_full_eigen_energies[i] + alignment[i], xdos, sigma)\n",
    "#     n_xdos2.append(x_dos2)\n",
    "        n_ldos.append(l_dosi)\n",
    "    \n",
    "    # n_xdos2 = torch.vstack(n_xdos2)\n",
    "    n_ldos = torch.vstack(n_ldos)\n",
    "    n_ldos = ((n_ldos.T * normalization_quartic[index] ).T)* 2\n",
    "    \n",
    "    weights_i = torch.linalg.lstsq(Features, n_ldos, driver = \"gelsd\").solution\n",
    "    pred_i = Features @ weights_i\n",
    "    \n",
    "    i_loss = loss.t_get_mse(pred_i, n_ldos)\n",
    "    i_rmse = loss.t_get_rmse(pred_i, n_ldos, xdos, perc = True)\n",
    "    \n",
    "    \n",
    "    pred_loss = i_loss\n",
    "    if i_loss < prev_loss * (1 - 1e-3): \n",
    "        trigger = 0\n",
    "    else:\n",
    "        trigger +=1 \n",
    "        if trigger >= patience:\n",
    "            alignment = torch.nn.parameter.Parameter(best_state)\n",
    "            opt = torch.optim.Adam([shift], lr = opt.param_groups[0]['lr'], weight_decay = 0)\n",
    "            counter = 0\n",
    "            \n",
    "    if i_loss < best_mse:\n",
    "        best_mse = i_loss\n",
    "        best_state = alignment.clone()\n",
    "        \n",
    "    prev_loss = i_loss\n",
    "    current_rmse = i_rmse\n",
    "    \n",
    "    opt.step()\n",
    "    scheduler.step(i_loss)\n",
    "    \n",
    "    if opt.param_groups[0]['lr'] < 0.01:\n",
    "        break\n",
    "shifted_ldos = []\n",
    "for i in range(n_structures):\n",
    "    shifted_ldos_i = quartic_dos(sorted_full_eigen_energies[i] + best_state[i], xdos, sigma)\n",
    "    shifted_ldos.append(shifted_ldos_i)\n",
    "    \n",
    "shifted_ldos = torch.vstack(shifted_ldos)\n",
    "shifted_ldos = ((shifted_ldos.T * normalization_quartic).T) * 2\n",
    "\n",
    "shifted_weights = torch.linalg.lstsq(Features, shifted_ldos[index], driver = \"gelsd\").solution\n",
    "shifted_preds = Features @ shifted_weights\n",
    "shifted_t_preds = t_Features @ shifted_weights\n",
    "\n",
    "\n",
    "shifted_train_loss = loss.t_get_rmse(shifted_preds, shifted_ldos, xdos, perc = True)\n",
    "shifted_test_loss = loss.t_get_rmse(shifted_t_preds, shifted_ldos, xdos, perc = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f0e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c137b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a7c3061",
   "metadata": {},
   "source": [
    "## Linalg-Shift, variable interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b711cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "759px",
    "left": "26px",
    "top": "111.133px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
