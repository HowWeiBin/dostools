{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee53854f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T14:54:59.334607Z",
     "start_time": "2023-04-24T14:54:56.298561Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import scipy \n",
    "import copy\n",
    "import ase\n",
    "import ase.io\n",
    "torch.set_default_dtype(torch.float64) \n",
    "# %matplotlib notebook\n",
    "# matplotlib.rcParams['figure.figsize'] = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af18caf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T14:55:00.302829Z",
     "start_time": "2023-04-24T14:54:59.337161Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "       \n",
    "    xdos = torch.load(\"./xdos.pt\")\n",
    "    \n",
    "    total_dos3 = torch.load(\"./total_ldos3.pt\")\n",
    "    total_dos1 = torch.load(\"./total_ldos1.pt\")\n",
    "    \n",
    "    surface_dos3 = torch.load(\"./surface_ldos3.pt\")\n",
    "    surface_dos1 = torch.load(\"./surface_ldos1.pt\")\n",
    "    \n",
    "    surface_aligned_dos3 = torch.load(\"./surface_aligned_dos3.pt\")\n",
    "    surface_aligned_dos1 = torch.load(\"./surface_aligned_dos1.pt\")\n",
    "    \n",
    "    bulk_dos3 = torch.load(\"./bulk_ldos3.pt\")\n",
    "    bulk_dos1 = torch.load(\"./bulk_ldos1.pt\")\n",
    "    \n",
    "    total_aligned_dos3 = torch.load(\"./total_aligned_dos3.pt\")\n",
    "    total_aligned_dos1 = torch.load(\"./total_aligned_dos1.pt\")\n",
    "    \n",
    "    surface_soap = torch.load(\"./surface_soap.pt\")\n",
    "    bulk_soap = torch.load(\"./bulk_soap.pt\")\n",
    "    total_soap = torch.load(\"./total_soap.pt\")\n",
    "    \n",
    "    surface_kernel_30 = torch.load(\"./surface_kernel_30.pt\")\n",
    "    surface_kMM_30 = torch.load(\"./surface_kMM_30.pt\")\n",
    "    \n",
    "    bulk_kernel_200 = torch.load(\"./bulk_kernel_200.pt\")\n",
    "    bulk_kMM_200 = torch.load(\"./bulk_kMM_200.pt\")\n",
    "    \n",
    "    bulk_kernel_100 = torch.load(\"./bulk_kernel_100.pt\")\n",
    "    bulk_kMM_100 = torch.load(\"./bulk_kMM_100.pt\")\n",
    "    \n",
    "    total_kernel_100 = torch.load(\"./total_kernel_100.pt\")\n",
    "    total_kMM_100 = torch.load(\"./total_kMM_100.pt\")\n",
    "    \n",
    "    total_kernel_150 = torch.load(\"./total_kernel_150.pt\")\n",
    "    total_kMM_150 = torch.load(\"./total_kMM_150.pt\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91165f41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T14:55:00.317619Z",
     "start_time": "2023-04-24T14:55:00.305597Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_train_test_split(n_samples):\n",
    "    n_structures = n_samples\n",
    "    np.random.seed(0)\n",
    "    n_train = int(0.8 * n_structures)\n",
    "    train_index = np.arange(n_structures)\n",
    "    np.random.shuffle(train_index)\n",
    "    test_index = train_index[n_train:]\n",
    "    train_index = train_index[:n_train]\n",
    "    \n",
    "    return train_index, test_index\n",
    "\n",
    "def generate_biased_train_test_split(n_samples):\n",
    "    #Assumes 100 amorphous structures at the end\n",
    "    n_structures = n_samples\n",
    "    amorph_train = np.arange(n_samples-100, n_samples,1)\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(amorph_train)\n",
    "    \n",
    "    amorph_test = amorph_train[:80]\n",
    "    amorph_train = amorph_train[80:]\n",
    "\n",
    "    n_structures = n_samples - 100\n",
    "    np.random.seed(0)\n",
    "    n_train = int(0.8 * n_samples)-20\n",
    "    remaining_train_index = np.arange(n_structures)\n",
    "    np.random.shuffle(remaining_train_index)\n",
    "\n",
    "    remaining_test_index = remaining_train_index[n_train:]\n",
    "    remaining_train_index = remaining_train_index[:n_train]\n",
    "\n",
    "    biased_train_index = np.concatenate([remaining_train_index, amorph_train])\n",
    "    biased_test_index = np.concatenate([remaining_test_index, amorph_test])\n",
    "    \n",
    "    return biased_train_index, biased_test_index\n",
    "\n",
    "def generate_surface_holdout_split(n_samples):\n",
    "    #Assumes that we are using the 110 surfaces for test which are located at 673 + 31st-57th index\n",
    "    #26 structures\n",
    "    \n",
    "    n_test = int(0.2 * n_samples) - 26\n",
    "    n_train = n_samples - n_test\n",
    "    \n",
    "    remaining_indexes = np.concatenate([np.arange(673+31), np.arange(673+57,n_samples,1)])\n",
    "    indexes_110 = np.arange(673+31, 673+57,1)\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    np.random.shuffle(remaining_indexes)\n",
    "    \n",
    "    remaining_test_index = remaining_indexes[n_train:]\n",
    "    remaining_train_index = remaining_indexes[:n_train]\n",
    "    \n",
    "    total_train_index = remaining_train_index\n",
    "    total_test_index = np.concatenate([remaining_test_index, indexes_110])\n",
    "    \n",
    "    return total_train_index, total_test_index\n",
    "    \n",
    "def surface_holdout(n_samples):\n",
    "    test_index = np.arange(31,57,1)\n",
    "    train_index = np.concatenate([np.arange(31), np.arange(57, n_samples)])\n",
    "    \n",
    "    return train_index, test_index\n",
    "\n",
    "n_surfaces = 154\n",
    "n_bulkstructures = 773\n",
    "n_total_structures = 773 + 154\n",
    "\n",
    "\n",
    "surface_train_index, surface_test_index = generate_train_test_split(n_surfaces)\n",
    "bulk_train_index, bulk_test_index = generate_train_test_split(n_bulkstructures)\n",
    "total_train_index, total_test_index = generate_train_test_split(n_total_structures)\n",
    "surface_holdout_train_index, surface_holdout_test_index = surface_holdout(n_surfaces)\n",
    "bulk_biased_train_index, bulk_biased_test_index = generate_biased_train_test_split(n_bulkstructures)\n",
    "total_biased_train_index, total_biased_test_index = generate_biased_train_test_split(n_total_structures)\n",
    "holdout_train_index, holdout_test_index = generate_surface_holdout_split(n_total_structures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ed621084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T15:13:44.980205Z",
     "start_time": "2023-04-25T15:13:44.969069Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.signal import convolve, correlate, correlation_lags\n",
    "def find_optimal_discrete_shift(prediction, true):\n",
    "    if true.shape == prediction.shape and len(prediction.shape) == 2:\n",
    "        shift = []\n",
    "        for i in range(true.shape[0]):\n",
    "            corr = correlate(true[i], prediction[i], mode='full')\n",
    "            shift_i = np.argmax(corr) - len(true[i]) + 1   \n",
    "            shift.append(shift_i)\n",
    "        \n",
    "        \n",
    "    elif true.shape == prediction.shape and len(prediction.shape) == 1:\n",
    "        corr = correlate(true, prediction, mode='full')\n",
    "        shift = np.argmax(corr) - len(true) + 1   \n",
    "    else:\n",
    "        print (\"input shapes are not the same\")\n",
    "        raise Exception\n",
    "    return shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bc7afc58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T15:13:45.162169Z",
     "start_time": "2023-04-25T15:13:45.150581Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate shifted data\n",
    "def shifted_ldos_discrete(ldos, xdos, shift): \n",
    "    shifted_ldos = torch.zeros_like(ldos)\n",
    "    if len(ldos.shape) > 1:\n",
    "        xdos_shift = torch.round(shift).int()\n",
    "        for i in range(len(ldos)):\n",
    "            if xdos_shift[i] > 0:\n",
    "                shifted_ldos[i] = torch.nn.functional.pad(ldos[i,:-1*xdos_shift[i]], (xdos_shift[i],0))\n",
    "            elif xdos_shift[i] < 0:\n",
    "                shifted_ldos[i] = torch.nn.functional.pad(ldos[i,(-1*xdos_shift[i]):], (0,(-1*xdos_shift[i])))\n",
    "            else:\n",
    "                shifted_ldos[i] = ldos[i]\n",
    "    else:        \n",
    "        xdos_shift = int(torch.round(shift))\n",
    "        if xdos_shift > 0:\n",
    "            shifted_ldos = torch.nn.functional.pad(ldos[:-1*xdos_shift], (xdos_shift,0))\n",
    "        elif xdos_shift < 0:\n",
    "            shifted_ldos = torch.nn.functional.pad(ldos[(-1*xdos_shift):], (0,(-1*xdos_shift)))\n",
    "        else:\n",
    "            shifted_ldos = ldos\n",
    "    return shifted_ldos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "de1445cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T15:13:45.320098Z",
     "start_time": "2023-04-25T15:13:45.306802Z"
    }
   },
   "outputs": [],
   "source": [
    "def t_get_mse(a, b, xdos = None, perc = False):\n",
    "    if xdos is not None:\n",
    "        if len(a.size()) > 1:\n",
    "            mse = (torch.trapezoid((a - b)**2, xdos, axis=1)).mean()\n",
    "        else:\n",
    "            mse = (torch.trapezoid((a - b)**2, xdos, axis=0)).mean()\n",
    "        if not perc:\n",
    "            return mse\n",
    "        else:\n",
    "            mean = b.mean(axis = 0)\n",
    "            std = torch.trapezoid((b - mean)**2, xdos, axis=1).mean()\n",
    "            return (100 * mse / std)\n",
    "    else:\n",
    "        if len(a.size()) > 1:\n",
    "            mse = ((a - b)**2).mean(dim = 1)\n",
    "        else:\n",
    "            mse = ((a - b)**2).mean()\n",
    "        if len(mse.shape) > 1:\n",
    "            raise ValueError('Loss became 2D')\n",
    "        if not perc:\n",
    "            return torch.mean(mse, 0)\n",
    "        else:\n",
    "            return torch.mean(100 * (mse / b.std(dim=0, unbiased = True)),0)\n",
    "        \n",
    "        \n",
    "def t_get_rmse(a, b, xdos=None, perc=False): #account for the fact that DOS is continuous but we are training them pointwise\n",
    "    \"\"\" computes  Root Mean Squared Error (RMSE) of array properties (DOS/aofd).\n",
    "         a=pred, b=target, xdos, perc: if False return RMSE else return %RMSE\"\"\"\n",
    "    #MIGHT NOT WORK FOR PC\n",
    "    if xdos is not None:\n",
    "        if len(a.size()) > 1:\n",
    "            rmse = torch.sqrt((torch.trapezoid((a - b)**2, xdos, axis=1)).mean())\n",
    "        else:\n",
    "            rmse = torch.sqrt((torch.trapezoid((a - b)**2, xdos, axis=0)).mean())\n",
    "        if not perc:\n",
    "            return rmse\n",
    "        else:\n",
    "            mean = b.mean(axis = 0)\n",
    "            std = torch.sqrt((torch.trapezoid((b - mean)**2, xdos, axis=1)).mean())\n",
    "            return (100 * rmse / std)\n",
    "    else:\n",
    "        if len(a.size()) > 1:\n",
    "            rmse = torch.sqrt(((a - b)**2).mean(dim =0))\n",
    "        else:\n",
    "            rmse = torch.sqrt(((a - b)**2).mean())\n",
    "        if not perc:\n",
    "            return torch.mean(rmse, 0)\n",
    "        else:\n",
    "            return torch.mean(100 * (rmse / b.std(dim = 0,unbiased=True)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ac8eea30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:59:44.988805Z",
     "start_time": "2023-04-26T13:59:44.937073Z"
    }
   },
   "outputs": [],
   "source": [
    "from dostools.loss import loss\n",
    "\n",
    "def normal_reg_train_L(feat, target, train_index, test_index, regularization, n_epochs, lr):\n",
    "    \n",
    "    patience = 20\n",
    "    index = train_index\n",
    "    t_index = test_index\n",
    "    features = torch.hstack([feat, torch.ones(feat.shape[0]).view(-1,1)])\n",
    "    Features = features[index]\n",
    "    t_Features = features[t_index]\n",
    "    n_col = Features.shape[1]\n",
    "    Target = target[index]\n",
    "    t_Target = target[t_index]\n",
    "    reg = regularization * torch.eye(n_col)\n",
    "    reg[-1, -1] = 0\n",
    "    reg_features = torch.vstack([Features, reg])\n",
    "    reg_target = torch.vstack([Target, torch.zeros(n_col,Target.shape[1])])\n",
    "    \n",
    "\n",
    "\n",
    "    weights = torch.nn.Parameter(torch.rand(Features.shape[1], Target.shape[1])- 0.5)\n",
    "    opt = torch.optim.LBFGS([weights], lr = lr, line_search_fn = \"strong_wolfe\", tolerance_grad = 1e-20, tolerance_change = 1-20, history_size = 200)\n",
    "    pbar = tqdm(range(n_epochs))\n",
    "    current_rmse = torch.tensor(100)\n",
    "    pred_loss = torch.tensor(100)\n",
    "    prev_loss = torch.tensor(100)\n",
    "    best_mse = torch.tensor(100)\n",
    "    trigger = 0\n",
    "    for epoch in pbar:\n",
    "        pbar.set_description(f\"Epoch: {epoch}\")\n",
    "        pbar.set_postfix(pred_loss = pred_loss.item(), lowest_mse = best_mse.item(), trigger = trigger)\n",
    "        def closure():\n",
    "            opt.zero_grad()\n",
    "            pred_i = reg_features @ weights\n",
    "            opt_shift = find_optimal_discrete_shift(np.array(pred_i[:len(index)].detach()),np.array(reg_target[:len(index)].detach()))\n",
    "            pred_i[:len(index)] = shifted_ldos_discrete(pred_i[:len(index)], xdos, torch.tensor(opt_shift))\n",
    "            loss_i = loss.t_get_mse(pred_i, reg_target)\n",
    "            loss_i.backward()\n",
    "            return loss_i\n",
    "        opt.step(closure)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = Features @ weights\n",
    "            opt_shift = find_optimal_discrete_shift(np.array(preds),np.array(Target))\n",
    "            preds = shifted_ldos_discrete(preds, xdos, torch.tensor(opt_shift))\n",
    "            epoch_rmse = loss.t_get_rmse(preds, Target, xdos, perc = True)\n",
    "            epoch_mse = loss.t_get_mse(preds, Target, xdos)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            pred_loss = epoch_rmse\n",
    "\n",
    "            if epoch_mse < best_mse:\n",
    "                best_mse = epoch_mse\n",
    "                best_state = weights.clone()\n",
    "\n",
    "            if epoch_mse < prev_loss * ( 1 + 1e-3):\n",
    "                trigger =0\n",
    "            else:\n",
    "                trigger +=1 \n",
    "                if trigger >= patience:\n",
    "                    weights = best_state\n",
    "                    opt = torch.optim.Adam([weights], lr = opt.param_groups[0]['lr'], weight_decay = 0)\n",
    "\n",
    "            epoch_mse = prev_loss\n",
    "\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        final_preds = Features @ best_state \n",
    "        final_t_preds = t_Features @ best_state\n",
    "\n",
    "        opt_shift_train = find_optimal_discrete_shift(np.array(final_preds),np.array(Target))\n",
    "        final_preds = shifted_ldos_discrete(final_preds, xdos, torch.tensor(opt_shift_train))\n",
    "        opt_shift_test = find_optimal_discrete_shift(np.array(final_t_preds),np.array(t_Target))\n",
    "        final_t_preds = shifted_ldos_discrete(final_t_preds, xdos, torch.tensor(opt_shift_test))\n",
    "\n",
    "        loss_dos = loss.t_get_rmse(final_preds, Target, xdos, perc = True)\n",
    "        test_loss_dos = loss.t_get_rmse(final_t_preds, t_Target, xdos, perc = True)\n",
    "        return best_state, loss_dos, test_loss_dos\n",
    "        \n",
    "\n",
    "def normal_reg_train_Ad(feat, target, train_index, test_index, regularization, n_epochs, batch_size, lr):\n",
    "    patience = 20\n",
    "    index = train_index\n",
    "    t_index = test_index\n",
    "\n",
    "    features = torch.hstack([feat, torch.ones(feat.shape[0]).view(-1,1)])\n",
    "\n",
    "    Sampler = torch.utils.data.RandomSampler(index, replacement = False)\n",
    "    Batcher = torch.utils.data.BatchSampler(Sampler, batch_size, False)\n",
    "\n",
    "    Features = features[index]\n",
    "    t_Features = features[t_index]\n",
    "    n_col = Features.shape[1]\n",
    "\n",
    "\n",
    "    Target = target[index]\n",
    "    t_Target = target[t_index]\n",
    "\n",
    "\n",
    "    # reg_features = torch.vstack([Features, reg])\n",
    "    # reg_target = torch.vstack([Target, torch.zeros(n_col,Target.shape[1])])\n",
    "\n",
    "\n",
    "    reg = regularization * torch.eye(n_col)\n",
    "    reg[-1, -1] = 0\n",
    "\n",
    "\n",
    "    weights = torch.nn.Parameter((torch.rand(Features.shape[1], Target.shape[1])- 0.5))\n",
    "    opt = torch.optim.Adam([weights], lr = lr, weight_decay = 0)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor = 0.1, patience = 500, threshold = 1e-7, min_lr = 1e-8)\n",
    "\n",
    "    pbar = tqdm(range(n_epochs))\n",
    "\n",
    "    current_rmse = torch.tensor(100)\n",
    "    pred_loss = torch.tensor(100)\n",
    "    prev_loss = torch.tensor(100)\n",
    "    best_mse = torch.tensor(100)\n",
    "    trigger = 0\n",
    "    for epoch in pbar:\n",
    "        pbar.set_description(f\"Epoch: {epoch}\")\n",
    "        pbar.set_postfix(pred_loss = pred_loss.item(), lowest_mse = best_mse.item(), trigger = trigger)\n",
    "        for i_batch in Batcher:\n",
    "            def closure():\n",
    "                opt.zero_grad()\n",
    "                reg_features_i = torch.vstack([Features[i_batch], reg])\n",
    "                target_i = torch.vstack([Target[i_batch], torch.zeros(n_col, Target.shape[1])])\n",
    "                pred_i = reg_features_i @ weights\n",
    "                opt_shift = find_optimal_discrete_shift(np.array(pred_i[:len(i_batch)].detach()),np.array(target_i[:len(i_batch)].detach()))\n",
    "                pred_i[:len(i_batch)] = shifted_ldos_discrete(pred_i[:len(i_batch)], xdos, torch.tensor(opt_shift))\n",
    "                loss_i = loss.t_get_mse(pred_i, target_i)\n",
    "                loss_i.backward()\n",
    "                return loss_i\n",
    "            opt.step(closure)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = Features @ weights\n",
    "            opt_shift = find_optimal_discrete_shift(np.array(preds),np.array(Target))\n",
    "            preds = shifted_ldos_discrete(preds, xdos, torch.tensor(opt_shift))\n",
    "            epoch_rmse = loss.t_get_rmse(preds, Target, xdos, perc = True)\n",
    "            epoch_mse = loss.t_get_mse(preds, Target, xdos)\n",
    "\n",
    "\n",
    "            pred_loss = epoch_rmse\n",
    "\n",
    "            if epoch_mse < best_mse:\n",
    "                best_mse = epoch_mse\n",
    "                best_state = weights.clone()\n",
    "\n",
    "            if epoch_mse < prev_loss * ( 1 + 1e-3):\n",
    "                trigger =0\n",
    "            else:\n",
    "                trigger +=1 \n",
    "                if trigger >= patience:\n",
    "                    weights = best_state\n",
    "                    opt = torch.optim.Adam([weights], lr = opt.param_groups[0]['lr'], weight_decay = 0)\n",
    "\n",
    "            epoch_mse = prev_loss\n",
    "\n",
    "            scheduler.step(epoch_mse)\n",
    "\n",
    "            if Batcher.batch_size > 1024:\n",
    "                break\n",
    "\n",
    "            if opt.param_groups[0]['lr'] < 1e-4:\n",
    "                Batcher.batch_size *= 2\n",
    "                opt.param_groups[0]['lr'] = lr\n",
    "                print (\"The batch_size is now: \", Batcher.batch_size)\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        final_preds = Features @ best_state \n",
    "        final_t_preds = t_Features @ best_state\n",
    "\n",
    "        opt_shift_train = find_optimal_discrete_shift(np.array(final_preds),np.array(Target))\n",
    "        final_preds = shifted_ldos_discrete(final_preds, xdos, torch.tensor(opt_shift_train))\n",
    "        opt_shift_test = find_optimal_discrete_shift(np.array(final_t_preds),np.array(t_Target))\n",
    "        final_t_preds = shifted_ldos_discrete(final_t_preds, xdos, torch.tensor(opt_shift_test))\n",
    "\n",
    "        loss_dos = loss.t_get_rmse(final_preds, Target, xdos, perc = True)\n",
    "        test_loss_dos = loss.t_get_rmse(final_t_preds, t_Target, xdos, perc = True)\n",
    "        return best_state, loss_dos, test_loss_dos\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c110556b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T15:15:12.509067Z",
     "start_time": "2023-04-25T15:15:12.483416Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# #For mass production\n",
    "# def normal_reg_train_L(feat, target, train_index, test_index, regularization, n_epochs, lr):    \n",
    "#     patience = 20\n",
    "#     index = train_index\n",
    "#     t_index = test_index\n",
    "#     features = torch.hstack([feat, torch.ones(feat.shape[0]).view(-1,1)])\n",
    "#     Features = features[index]\n",
    "#     t_Features = features[t_index]\n",
    "#     n_col = Features.shape[1]\n",
    "#     Target = target[index]\n",
    "#     t_Target = target[t_index]\n",
    "#     reg = regularization * torch.eye(n_col)\n",
    "#     reg[-1, -1] = 0\n",
    "#     reg_features = torch.vstack([Features, reg])\n",
    "#     reg_target = torch.vstack([Target, torch.zeros(n_col,Target.shape[1])])\n",
    "    \n",
    "#     weights = torch.nn.Parameter(torch.rand(Features.shape[1], Target.shape[1])- 0.5)\n",
    "#     opt = torch.optim.LBFGS([weights], lr = lr, line_search_fn = \"strong_wolfe\", tolerance_grad = 1e-20, tolerance_change = 1-20, history_size = 200)\n",
    "    \n",
    "#     for epoch in range(n_epochs):\n",
    "#         def closure():\n",
    "#             opt.zero_grad()\n",
    "#             pred_i = reg_features @ weights\n",
    "#             opt_shift = find_optimal_discrete_shift(np.array(pred_i[:len(index)].detach()),np.array(reg_target[:len(index)].detach()))\n",
    "#             pred_i[:len(index)] = shifted_ldos_discrete(pred_i[:len(index)], xdos, torch.tensor(opt_shift))\n",
    "#             loss_i = t_get_mse(pred_i, reg_target)\n",
    "#             loss_i.backward()\n",
    "#             return loss_i\n",
    "#         opt.step(closure)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         final_preds = Features @ best_state \n",
    "#         final_t_preds = t_Features @ best_state\n",
    "\n",
    "#         opt_shift_train = find_optimal_discrete_shift(np.array(final_preds),np.array(Target))\n",
    "#         final_preds = shifted_ldos_discrete(final_preds, xdos, torch.tensor(opt_shift_train))\n",
    "#         opt_shift_test = find_optimal_discrete_shift(np.array(final_t_preds),np.array(t_Target))\n",
    "#         final_t_preds = shifted_ldos_discrete(final_t_preds, xdos, torch.tensor(opt_shift_test))\n",
    "\n",
    "#         loss_dos = t_get_rmse(final_preds, Target, xdos, perc = True)\n",
    "#         test_loss_dos = t_get_rmse(final_t_preds, t_Target, xdos, perc = True)\n",
    "#         return best_state, loss_dos, test_loss_dos\n",
    "        \n",
    "\n",
    "# def normal_reg_train_Ad(feat, target, train_index, test_index, regularization, n_epochs, batch_size, lr):\n",
    "#     patience = 20\n",
    "#     index = train_index\n",
    "#     t_index = test_index\n",
    "\n",
    "#     features = torch.hstack([feat, torch.ones(feat.shape[0]).view(-1,1)])\n",
    "\n",
    "#     Sampler = torch.utils.data.RandomSampler(index, replacement = False)\n",
    "#     Batcher = torch.utils.data.BatchSampler(Sampler, batch_size, False)\n",
    "\n",
    "#     Features = features[index]\n",
    "#     t_Features = features[t_index]\n",
    "#     n_col = Features.shape[1]\n",
    "\n",
    "\n",
    "#     Target = target[index]\n",
    "#     t_Target = target[t_index]\n",
    "\n",
    "\n",
    "#     # reg_features = torch.vstack([Features, reg])\n",
    "#     # reg_target = torch.vstack([Target, torch.zeros(n_col,Target.shape[1])])\n",
    "\n",
    "\n",
    "#     reg = regularization * torch.eye(n_col)\n",
    "#     reg[-1, -1] = 0\n",
    "\n",
    "\n",
    "#     weights = torch.nn.Parameter((torch.rand(Features.shape[1], Target.shape[1])- 0.5))\n",
    "#     opt = torch.optim.Adam([weights], lr = lr, weight_decay = 0)\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor = 0.1, patience = 500, threshold = 1e-7, min_lr = 1e-8)\n",
    "\n",
    "#     best_mse = torch.tensor(100)\n",
    "#     for epoch in tqdm(range(n_epochs))yy:\n",
    "#         for i_batch in Batcher:\n",
    "#             def closure():\n",
    "#                 opt.zero_grad()\n",
    "#                 reg_features_i = torch.vstack([Features[i_batch], reg])\n",
    "#                 target_i = torch.vstack([Target[i_batch], torch.zeros(n_col, Target.shape[1])])\n",
    "#                 pred_i = reg_features_i @ weights\n",
    "#                 opt_shift = find_optimal_discrete_shift(np.array(pred_i[:len(i_batch)].detach()),np.array(target_i[:len(i_batch)].detach()))\n",
    "#                 pred_i[:len(i_batch)] = shifted_ldos_discrete(pred_i[:len(i_batch)], xdos, torch.tensor(opt_shift))\n",
    "#                 loss_i = t_get_mse(pred_i, target_i)\n",
    "#                 loss_i.backward()\n",
    "#                 return loss_i\n",
    "#             opt.step(closure)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             preds = Features @ weights\n",
    "#             opt_shift = find_optimal_discrete_shift(np.array(preds),np.array(Target))\n",
    "#             preds = shifted_ldos_discrete(preds, xdos, torch.tensor(opt_shift))\n",
    "#             epoch_rmse = t_get_rmse(preds, Target, xdos, perc = True)\n",
    "#             epoch_mse = t_get_mse(preds, Target, xdos)\n",
    "\n",
    "\n",
    "#             pred_loss = epoch_rmse\n",
    "\n",
    "#             if epoch_mse < best_mse:\n",
    "#                 best_mse = epoch_mse\n",
    "#                 best_state = weights.clone()\n",
    "\n",
    "#             scheduler.step(epoch_mse)\n",
    "\n",
    "#             if Batcher.batch_size > 1024:\n",
    "#                 break\n",
    "\n",
    "#             if opt.param_groups[0]['lr'] < 1e-4:\n",
    "#                 Batcher.batch_size *= 2\n",
    "#                 opt.param_groups[0]['lr'] = lr\n",
    "#                 print (\"The batch_size is now: \", Batcher.batch_size)\n",
    "\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         final_preds = Features @ best_state \n",
    "#         final_t_preds = t_Features @ best_state\n",
    "\n",
    "#         opt_shift_train = find_optimal_discrete_shift(np.array(final_preds),np.array(Target))\n",
    "#         final_preds = shifted_ldos_discrete(final_preds, xdos, torch.tensor(opt_shift_train))\n",
    "#         opt_shift_test = find_optimal_discrete_shift(np.array(final_t_preds),np.array(t_Target))\n",
    "#         final_t_preds = shifted_ldos_discrete(final_t_preds, xdos, torch.tensor(opt_shift_test))\n",
    "\n",
    "#         loss_dos = t_get_rmse(final_preds, Target, xdos, perc = True)\n",
    "#         test_loss_dos = t_get_rmse(final_t_preds, t_Target, xdos, perc = True)\n",
    "#         return best_state, loss_dos, test_loss_dos\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a1364600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T15:14:38.291742Z",
     "start_time": "2023-04-25T15:14:38.279997Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_weights(weights, feat, target, train_index, test_index):\n",
    "    \n",
    "    features = torch.hstack([feat, torch.ones(feat.shape[0]).view(-1,1)])\n",
    "    \n",
    "    best_state = weights\n",
    "    Features = features[train_index]\n",
    "    t_Features = features[test_index]\n",
    "    \n",
    "    Target = target[train_index]\n",
    "    t_Target = target[test_index]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        final_preds = Features @ best_state \n",
    "        final_t_preds = t_Features @ best_state\n",
    "\n",
    "        opt_shift_train = find_optimal_discrete_shift(np.array(final_preds),np.array(Target))\n",
    "        final_preds = shifted_ldos_discrete(final_preds, xdos, torch.tensor(opt_shift_train))\n",
    "        opt_shift_test = find_optimal_discrete_shift(np.array(final_t_preds),np.array(t_Target))\n",
    "        final_t_preds = shifted_ldos_discrete(final_t_preds, xdos, torch.tensor(opt_shift_test))\n",
    "\n",
    "        loss_dos = t_get_rmse(final_preds, Target, xdos, perc = True)\n",
    "        test_loss_dos = t_get_rmse(final_t_preds, t_Target, xdos, perc = True)\n",
    "    \n",
    "    return loss_dos, test_loss_dos, opt_shift_train, opt_shift_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ce43a0b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T15:14:38.757005Z",
     "start_time": "2023-04-25T15:14:38.749627Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions(weights, feat, target, train_index, test_index):\n",
    "    features = torch.hstack([feat, torch.ones(feat.shape[0]).view(-1,1)])\n",
    "    \n",
    "    best_state = weights\n",
    "    Features = features[train_index]\n",
    "    t_Features = features[test_index]\n",
    "    \n",
    "    Target = target[train_index]\n",
    "    t_Target = target[test_index]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        final_preds = Features @ best_state \n",
    "        final_t_preds = t_Features @ best_state\n",
    "\n",
    "        opt_shift_train = find_optimal_discrete_shift(np.array(final_preds),np.array(Target))\n",
    "        final_preds2 = shifted_ldos_discrete(final_preds, xdos, torch.tensor(opt_shift_train))\n",
    "        opt_shift_test = find_optimal_discrete_shift(np.array(final_t_preds),np.array(t_Target))\n",
    "        final_t_preds2 = shifted_ldos_discrete(final_t_preds, xdos, torch.tensor(opt_shift_test))\n",
    "        \n",
    "    return final_preds, final_t_preds, opt_shift_train, opt_shift_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e1136799",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:37:16.166292Z",
     "start_time": "2023-04-25T11:37:15.915260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train error is 19.83 for SOAP\n",
      "The test error is 22.49 for SOAP\n"
     ]
    }
   ],
   "source": [
    "# adam_opt_weights = weights.clone()\n",
    "loss_dos, test_loss_dos, opt_shift_train, opt_shift_test = evaluate_weights(adam_opt_weights, total_soap, total_aligned_dos3, total_train_index, total_test_index)\n",
    "\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1163fdde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T12:13:31.682855Z",
     "start_time": "2023-04-25T12:13:31.419898Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pred, test_pred, train_shift, test_shift = get_predictions(adam_opt_weights, total_soap, total_aligned_dos3, total_train_index, total_test_index)\n",
    "torch.save(torch.tensor(train_shift), \"./adam_corr_train_shifts.pt\")\n",
    "torch.save(torch.tensor(test_shift), \"./adam_corr_test_shifts.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cce421d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T13:03:09.565323Z",
     "start_time": "2023-04-25T13:03:09.452804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcbf94bf130>]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 454\n",
    "plt.plot(xdos, train_pred[i])\n",
    "plt.plot(xdos, total_aligned_dos3[total_train_index[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "cec4d3c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T15:15:43.955514Z",
     "start_time": "2023-04-25T15:15:40.813154Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                          | 5/20000 [00:03<3:23:15,  1.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [173]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m aweights, loss_dos, test_loss_dos \u001b[38;5;241m=\u001b[39m \u001b[43mnormal_reg_train_Ad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_soap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_aligned_dos3\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mtotal_train_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_test_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam Unbiased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train error is \u001b[39m\u001b[38;5;132;01m{:.4}\u001b[39;00m\u001b[38;5;124m for SOAP\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(loss_dos))\n",
      "Input \u001b[0;32mIn [171]\u001b[0m, in \u001b[0;36mnormal_reg_train_Ad\u001b[0;34m(feat, target, train_index, test_index, regularization, n_epochs, batch_size, lr)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     91\u001b[0m     preds \u001b[38;5;241m=\u001b[39m Features \u001b[38;5;241m@\u001b[39m weights\n\u001b[0;32m---> 92\u001b[0m     opt_shift \u001b[38;5;241m=\u001b[39m \u001b[43mfind_optimal_discrete_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     preds \u001b[38;5;241m=\u001b[39m shifted_ldos_discrete(preds, xdos, torch\u001b[38;5;241m.\u001b[39mtensor(opt_shift))\n\u001b[1;32m     94\u001b[0m     epoch_rmse \u001b[38;5;241m=\u001b[39m t_get_rmse(preds, Target, xdos, perc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [158]\u001b[0m, in \u001b[0;36mfind_optimal_discrete_shift\u001b[0;34m(prediction, true)\u001b[0m\n\u001b[1;32m      4\u001b[0m shift \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m----> 6\u001b[0m     corr \u001b[38;5;241m=\u001b[39m \u001b[43mcorrelate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     shift_i \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(corr) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(true[i]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m   \n\u001b[1;32m      8\u001b[0m     shift\u001b[38;5;241m.\u001b[39mappend(shift_i)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/signal/signaltools.py:239\u001b[0m, in \u001b[0;36mcorrelate\u001b[0;34m(in1, in2, mode, method)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# this either calls fftconvolve or this function with method=='direct'\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43min1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_reverse_and_conj\u001b[49m\u001b[43m(\u001b[49m\u001b[43min2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirect\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m# fastpath to faster numpy.correlate for 1d inputs when possible\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _np_conv_ok(in1, in2, mode):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/signal/signaltools.py:1408\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(in1, in2, mode, method)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirect\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1406\u001b[0m     \u001b[38;5;66;03m# fastpath to faster numpy.convolve for 1d inputs when possible\u001b[39;00m\n\u001b[1;32m   1407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _np_conv_ok(volume, kernel, mode):\n\u001b[0;32m-> 1408\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m correlate(volume, _reverse_and_conj(kernel), mode, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirect\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/core/numeric.py:844\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(a, v, mode)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv cannot be empty\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 844\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultiarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "aweights, loss_dos, test_loss_dos = normal_reg_train_Ad(total_soap, total_aligned_dos3,\n",
    "                                                       total_train_index, total_test_index,\n",
    "                                                       1e-2, 20000, 60, 1e-3)\n",
    "\n",
    "\n",
    "print (\"Adam Unbiased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2d44ad89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:32:41.829922Z",
     "start_time": "2023-04-25T11:21:51.117999Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1005:  10%|███████████                                                                                                   | 1005/10000 [01:53<15:39,  9.57it/s, lowest_mse=0.0152, pred_loss=46.7, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2007:  20%|█████████████████████▉                                                                                       | 2007/10000 [03:28<12:29, 10.66it/s, lowest_mse=0.00871, pred_loss=35.4, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3009:  30%|████████████████████████████████▊                                                                            | 3009/10000 [04:58<10:23, 11.22it/s, lowest_mse=0.00751, pred_loss=32.8, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4011:  40%|███████████████████████████████████████████▋                                                                 | 4010/10000 [06:27<08:41, 11.50it/s, lowest_mse=0.00695, pred_loss=31.6, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5013:  50%|██████████████████████████████████████████████████████▋                                                      | 5013/10000 [07:56<07:13, 11.51it/s, lowest_mse=0.00656, pred_loss=30.7, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6015:  60%|██████████████████████████████████████████████████████████████████▊                                            | 6015/10000 [09:23<05:45, 11.54it/s, lowest_mse=0.00628, pred_loss=30, trigger=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7015:  70%|████████████████████████████████████████████████████████████████████████████▍                                | 7015/10000 [10:50<04:36, 10.78it/s, lowest_mse=0.00604, pred_loss=29.4, trigger=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size is now:  2048\n",
      "Adam Unbiased\n",
      "The train error is 29.43 for SOAP\n",
      "The test error is 38.52 for SOAP\n"
     ]
    }
   ],
   "source": [
    "weights, loss_dos, test_loss_dos = normal_reg_train_Ad(surface_soap, surface_dos3, surface_train_index, surface_test_index, 1e-2, 10000, 16, 1e-3)\n",
    "print (\"Adam Unbiased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11eeae",
   "metadata": {},
   "source": [
    "22.36, 24.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d6fe123c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:21:51.115360Z",
     "start_time": "2023-04-25T11:17:37.519949Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 29: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [04:13<00:00,  8.44s/it, lowest_mse=0.0537, pred_loss=49.2, trigger=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS Unbiased\n",
      "The train error is 49.19 for SOAP\n",
      "The test error is 49.19 for SOAP\n"
     ]
    }
   ],
   "source": [
    "U_L_weights3 , loss_dos, test_loss_dos = normal_reg_train_L(total_soap, total_aligned_dos3,\n",
    "                                                            total_train_index, total_test_index,\n",
    "                                                            1e-2, 30, 1)\n",
    "print (\"LBFGS Unbiased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dd988b80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T11:12:43.352218Z",
     "start_time": "2023-04-25T11:12:35.214200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4:   7%|████████                                                                                                                 | 4/60 [00:07<01:50,  1.98s/it, lowest_mse=0.259, pred_loss=193, trigger=0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [132]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m U_L_weights3 , loss_dos, test_loss_dos \u001b[38;5;241m=\u001b[39m \u001b[43mnormal_reg_train_L\u001b[49m\u001b[43m(\u001b[49m\u001b[43msurface_soap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msurface_dos3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msurface_train_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msurface_test_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLBFGS Unbiased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train error is \u001b[39m\u001b[38;5;132;01m{:.4}\u001b[39;00m\u001b[38;5;124m for SOAP\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(loss_dos))\n",
      "Input \u001b[0;32mIn [126]\u001b[0m, in \u001b[0;36mnormal_reg_train_L\u001b[0;34m(feat, target, train_index, test_index, regularization, n_epochs, lr)\u001b[0m\n\u001b[1;32m     38\u001b[0m     loss_i\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_i\n\u001b[0;32m---> 40\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     43\u001b[0m     preds \u001b[38;5;241m=\u001b[39m Features \u001b[38;5;241m@\u001b[39m weights\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:426\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directional_evaluate(closure, x, t, d)\n\u001b[0;32m--> 426\u001b[0m     loss, flat_grad, t, ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[43m_strong_wolfe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[1;32m    429\u001b[0m opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:148\u001b[0m, in \u001b[0;36m_strong_wolfe\u001b[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[1;32m    145\u001b[0m     insuf_progress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Evaluate new point\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m f_new, g_new \u001b[38;5;241m=\u001b[39m \u001b[43mobj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m ls_func_evals \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    150\u001b[0m gtd_new \u001b[38;5;241m=\u001b[39m g_new\u001b[38;5;241m.\u001b[39mdot(d)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:424\u001b[0m, in \u001b[0;36mLBFGS.step.<locals>.obj_func\u001b[0;34m(x, t, d)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[0;32m--> 424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_directional_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:278\u001b[0m, in \u001b[0;36mLBFGS._directional_evaluate\u001b[0;34m(self, closure, x, t, d)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_directional_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure, x, t, d):\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[0;32m--> 278\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    279\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_param(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [126]\u001b[0m, in \u001b[0;36mnormal_reg_train_L.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     34\u001b[0m pred_i \u001b[38;5;241m=\u001b[39m reg_features \u001b[38;5;241m@\u001b[39m weights\n\u001b[0;32m---> 35\u001b[0m opt_shift \u001b[38;5;241m=\u001b[39m \u001b[43mfind_optimal_discrete_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_i\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreg_target\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m pred_i[:\u001b[38;5;28mlen\u001b[39m(index)] \u001b[38;5;241m=\u001b[39m shifted_ldos_discrete(pred_i[:\u001b[38;5;28mlen\u001b[39m(index)], xdos, torch\u001b[38;5;241m.\u001b[39mtensor(opt_shift))\n\u001b[1;32m     37\u001b[0m loss_i \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mt_get_mse(pred_i, reg_target)\n",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36mfind_optimal_discrete_shift\u001b[0;34m(prediction, true)\u001b[0m\n\u001b[1;32m      4\u001b[0m shift \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m----> 6\u001b[0m     corr \u001b[38;5;241m=\u001b[39m \u001b[43mcorrelate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     shift_i \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(corr) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(true[i]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m   \n\u001b[1;32m      8\u001b[0m     shift\u001b[38;5;241m.\u001b[39mappend(shift_i)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/signal/signaltools.py:239\u001b[0m, in \u001b[0;36mcorrelate\u001b[0;34m(in1, in2, mode, method)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# this either calls fftconvolve or this function with method=='direct'\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43min1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_reverse_and_conj\u001b[49m\u001b[43m(\u001b[49m\u001b[43min2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirect\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m# fastpath to faster numpy.correlate for 1d inputs when possible\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _np_conv_ok(in1, in2, mode):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/signal/signaltools.py:1408\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(in1, in2, mode, method)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirect\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1406\u001b[0m     \u001b[38;5;66;03m# fastpath to faster numpy.convolve for 1d inputs when possible\u001b[39;00m\n\u001b[1;32m   1407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _np_conv_ok(volume, kernel, mode):\n\u001b[0;32m-> 1408\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m correlate(volume, _reverse_and_conj(kernel), mode, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirect\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/core/numeric.py:844\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(a, v, mode)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv cannot be empty\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 844\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultiarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "U_L_weights3 , loss_dos, test_loss_dos = normal_reg_train_L(surface_soap, surface_dos3, surface_train_index, surface_test_index,\n",
    "                                                            1e-2, 60, 1)\n",
    "print (\"LBFGS Unbiased\")\n",
    "print (\"The train error is {:.4} for SOAP\".format(loss_dos))\n",
    "print (\"The test error is {:.4} for SOAP\".format(test_loss_dos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace30a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
