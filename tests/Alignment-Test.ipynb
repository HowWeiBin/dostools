{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84565b74",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfdaeca7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T17:15:54.616738Z",
     "start_time": "2023-01-27T17:15:54.609357Z"
    }
   },
   "outputs": [],
   "source": [
    "import dostools\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "torch.set_default_dtype(torch.float64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ccbf26d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T11:28:53.055005Z",
     "start_time": "2023-01-27T11:28:44.621291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ldos shape is torch.Size([1039, 778])\n",
      "mean dos shape is torch.Size([778])\n",
      "Variance covered with 10 PCs is = 0.9871211778950157\n"
     ]
    }
   ],
   "source": [
    "import dostools.src.datasets.data as data\n",
    "import dostools.src.utils.utils as utils\n",
    "\n",
    "n_structures = 1039\n",
    "np.random.seed(0)\n",
    "n_train = int(0.8 * n_structures)\n",
    "train_index = np.arange(n_structures)\n",
    "np.random.shuffle(train_index)\n",
    "test_index = train_index[n_train:]\n",
    "train_index = train_index[:n_train]\n",
    "\n",
    "with torch.no_grad():\n",
    "    structures = data.load_structures(\":\")\n",
    "    n_structures = len(structures) #total number of structures\n",
    "    for structure in structures:#implement periodicity\n",
    "        structure.wrap(eps = 1e-12) \n",
    "    n_atoms = np.zeros(n_structures, dtype = int) #stores number of atoms in each structures\n",
    "    for i in range(n_structures):\n",
    "        n_atoms[i] = len(structures[i])\n",
    "\n",
    "    #eigenergies, emin, emax = dostools.src.datasets.data.load_eigenenergies(unpack = True, n_structures = len(structures))\n",
    "    xdos = torch.tensor(data.load_xdos())\n",
    "    ldos = torch.tensor(data.load_ldos())\n",
    "    ldos *= 2\n",
    "\n",
    "    print (\"ldos shape is {}\".format(ldos.shape))\n",
    "    mean_dos_per_atom = ldos[train_index].mean(axis = 0) #only calculated for train set to prevent data leakage\n",
    "    print (\"mean dos shape is {}\".format(mean_dos_per_atom.shape))\n",
    "    \n",
    "    \n",
    "    y_pw = ldos - mean_dos_per_atom\n",
    "    y_lcdf = torch.cumsum(y_pw, dim = 1)\n",
    "    _, pc_vectors = utils.build_pc(ldos[train_index], mean_dos_per_atom[None,:], n_pc = 10)\n",
    "    y_pc = utils.build_coeffs(ldos - mean_dos_per_atom[None,:], pc_vectors)\n",
    "    Silicon = data.load_features()\n",
    "    kMM = data.load_kMM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c7af2",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cfe1751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T11:28:53.067505Z",
     "start_time": "2023-01-27T11:28:53.058565Z"
    }
   },
   "outputs": [],
   "source": [
    "import dostools.src.evaluation.evaluation as evaluation\n",
    "importlib.reload(evaluation)\n",
    "import dostools.src.models.training as training\n",
    "importlib.reload(training)\n",
    "\n",
    "targets = {\n",
    "    'pw' : ldos,\n",
    "    'lcdf' : y_lcdf,\n",
    "    'pc' : y_pc\n",
    "}\n",
    "evaluator = evaluation.Evaluator(targets, xdos, mean_dos_per_atom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ebc76",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7efa3cb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T17:16:59.548164Z",
     "start_time": "2023-01-27T17:16:59.507360Z"
    }
   },
   "outputs": [],
   "source": [
    "import dostools.src.datasets.dataset as data\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = 'cpu'\n",
    "kwargs = {\"pin_memory\":True} if device == \"cuda:0\" else {}\n",
    "#Dataset\n",
    "train_data_soap = TensorDataset(Silicon.Features[\"structure_avedescriptors\"][train_index].double(), y_pw[train_index].double())\n",
    "train_data_kernel = TensorDataset(Silicon.Features[\"structure_avekerneldescriptors\"][train_index].double(), y_pw[train_index].double())\n",
    "\n",
    "test_data_soap = TensorDataset(Silicon.Features[\"structure_avedescriptors\"][test_index].double(), y_pw[test_index].double())\n",
    "test_data_kernel = TensorDataset(Silicon.Features[\"structure_avekerneldescriptors\"][test_index].double(), y_pw[test_index].double())\n",
    "\n",
    "#Dataloader\n",
    "\n",
    "train_dataloader_soap = DataLoader(train_data_soap, batch_size = len(train_data_soap), shuffle = False, **kwargs)\n",
    "train_dataloader_kernel = DataLoader(train_data_kernel, batch_size = len(train_data_kernel), shuffle = False, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7691fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T16:19:17.672020Z",
     "start_time": "2023-01-27T16:19:17.669361Z"
    }
   },
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fcd3ea42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T17:30:43.824172Z",
     "start_time": "2023-01-27T17:30:43.801134Z"
    }
   },
   "outputs": [],
   "source": [
    "import dostools.src.consistency.consistency as consistency\n",
    "import dostools.src.loss.loss as loss\n",
    "importlib.reload(loss)\n",
    "importlib.reload(consistency)\n",
    "\n",
    "def t_get_BF_shift_index_mse(prediction, true, shift_range, xdos = None, perc = False):\n",
    "    if xdos is not None:\n",
    "        mse = torch.zeros(true.shape[0])\n",
    "        index = torch.zeros(true.shape[0])\n",
    "        for i, pred in enumerate((prediction)):\n",
    "            shifted_preds = consistency.shifted_ldos(pred.repeat(shift_range.shape[0],1), xdos, shift_range)\n",
    "            mse[i], index[i] = torch.min(loss.t_get_each_mse(shifted_preds, true[i].repeat(shift_range.shape[0],1)),0)\n",
    "        mse = torch.mean(mse, 0)\n",
    "        \n",
    "        return mse,index        \n",
    "    else:\n",
    "        raise ValueError(\"xdos not defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfaf523",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "21a54f85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T17:32:53.309190Z",
     "start_time": "2023-01-27T17:32:53.298140Z"
    }
   },
   "outputs": [],
   "source": [
    "def t_get_opt_BF_shift_rmse(prediction, true, opt_shift, xdos = None, perc = False):\n",
    "    if xdos is not None:\n",
    "        rmse = torch.zeros(true.shape[0])\n",
    "        index = torch.zeros(true.shape[0])\n",
    "        shifted_preds = consistency.shifted_ldos(prediction, xdos, opt_shift)\n",
    "        rmse = torch.sqrt(torch.trapezoid((shifted_preds - true)**2, xdos, axis = 1)).mean()\n",
    "\n",
    "        if perc:\n",
    "            mean = true.mean(axis = 0)\n",
    "            std = torch.sqrt(torch.trapezoid((true - mean)**2, xdos, axis = 1)).mean()\n",
    "            loss = (100 * rmse/std)\n",
    "        return loss        \n",
    "    else:\n",
    "        raise ValueError(\"xdos not defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db6462d",
   "metadata": {},
   "source": [
    "## Alignment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ba5bb960",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T17:32:53.935041Z",
     "start_time": "2023-01-27T17:32:53.896654Z"
    }
   },
   "outputs": [],
   "source": [
    "import dostools.src.models.models as models\n",
    "import dostools.src.models.training as training\n",
    "import dostools.src.models.architectures as architecture\n",
    "import dostools.src.loss.loss as loss\n",
    "import torch.nn as nn\n",
    "\n",
    "importlib.reload(models)\n",
    "importlib.reload(training)\n",
    "importlib.reload(architecture)\n",
    "importlib.reload(loss)\n",
    "\n",
    "\n",
    "class AlignmentLinearModel(nn.Module):\n",
    "    def __init__(self, inputSize, outputSize, train_size, xdos, reg, opt, device):\n",
    "        super(AlignmentLinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(inputSize, outputSize, bias = False)\n",
    "        self.xdos = xdos\n",
    "        self.opt = opt\n",
    "        self.device = device\n",
    "        self.reg = torch.tensor(reg, requires_grad = False).to(self.device)\n",
    "        self.alignment = torch.zeros(train_size, device = self.device)\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs the transformations to the features based on the model\n",
    "        \n",
    "        Args:\n",
    "            x (tensor): input features\n",
    "        \n",
    "        Returns:\n",
    "            tensor: output\n",
    "        \"\"\"\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "    def fit(self, traindata_loader, valdata_loader, loss, lr ,n_epochs):\n",
    "        \"\"\"\n",
    "        Fits the model based on the training data, early stopping is based on performance on training data (or validation data)\n",
    "        Returns the loss history \n",
    "        \n",
    "        Args:\n",
    "            traindata_loader (DataLoader): Train dataloader\n",
    "            valdata_loader (DataLoader): Validation dataloader\n",
    "            loss (function): Loss function\n",
    "            lr (float): Learning rate\n",
    "            n_epochs (int): Max number of epochs\n",
    "        \n",
    "        Returns:\n",
    "            list: Loss history of the training process\n",
    "        \"\"\"\n",
    "        if self.opt == \"Adam\":\n",
    "            opt = torch.optim.Adam(self.parameters(), lr = lr, weight_decay = self.reg.item())\n",
    "            if valdata_loader is not None:\n",
    "                threshold = 1000\n",
    "                scheduler_threshold = 100\n",
    "            else:\n",
    "                threshold = 1000\n",
    "                scheduler_threshold = 1000\n",
    "            tol = 1e-4\n",
    "        if self.opt == \"LBFGS\":\n",
    "            opt = torch.optim.LBFGS(self.parameters(), lr = lr)\n",
    "            if valdata_loader is not None:\n",
    "                threshold = 2000\n",
    "                scheduler_threshold = 2000\n",
    "            else:\n",
    "                threshold = 30\n",
    "                scheduler_threshold = 5\n",
    "            tol = 1e-2\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(opt, scheduler_threshold, gamma = 0.1)\n",
    "        best_state = copy.deepcopy(self.state_dict())\n",
    "        lowest_loss = torch.tensor(9999)\n",
    "        pred_loss = torch.tensor(0)\n",
    "        trigger = 0\n",
    "        loss_history =[]\n",
    "        pbar = tqdm(range(n_epochs))\n",
    "        \n",
    "        for epoch in pbar:\n",
    "            pbar.set_description(f\"Epoch: {epoch}\")\n",
    "            if valdata_loader is not None:\n",
    "                pbar.set_postfix(val_loss = lowest_loss.item(), trigger = trigger, train_loss = pred_loss.item())\n",
    "            else:\n",
    "                pbar.set_postfix(pred_loss = pred_loss.item(), lowest_loss = lowest_loss.item(), trigger = trigger)\n",
    "\n",
    "            for x_data, y_data in traindata_loader:\n",
    "                opt.zero_grad()\n",
    "                x_data, y_data = x_data.to(self.device), y_data.to(self.device)\n",
    "                if self.opt == \"LBFGS\":\n",
    "                    def closure(predictions = False):\n",
    "                        \"\"\"\n",
    "                        Function is necessary for LBFGS, returns the total loss of the model\n",
    "                        \n",
    "                        Args:\n",
    "                            predictions (bool, optional): Returns prediction loss if true, returns total loss if False\n",
    "                        \n",
    "                        Returns:\n",
    "                            tensor: Loss\n",
    "                        \"\"\"\n",
    "                        opt.zero_grad()\n",
    "                        _pred = self.forward(x_data)\n",
    "                        _pred_loss, self.alignment = t_get_BF_shift_index_mse(_pred, y_data, shift_range, self.xdos)#, self.xdos), perc = True)       \n",
    "                        _pred_loss *= 1e7\n",
    "                        _pred_loss = torch.nan_to_num(_pred_loss, nan=lowest_loss.item(), posinf = lowest_loss.item(), neginf = lowest_loss.item())                 \n",
    "                        _reg_loss = torch.sum(torch.pow(self.linear.weight,2))\n",
    "                        _reg_loss *= self.reg.item()\n",
    "                        _new_loss = _pred_loss + _reg_loss\n",
    "                        _new_loss.backward()\n",
    "                        # global z \n",
    "                        # z = (torch.sum(abs(self.linear.weight.grad)))\n",
    "                        if predictions:\n",
    "                            return _pred_loss\n",
    "                        return _new_loss\n",
    "                    opt.step(closure)\n",
    "                    #print (z)\n",
    "                    with torch.no_grad():\n",
    "                        pred = self.forward(x_data)\n",
    "                        pred_loss = t_get_opt_BF_shift_rmse(pred, y_data, self.alignment, self.xdos, perc = True)\n",
    "                        reg_loss = torch.sum(torch.pow(self.linear.weight,2))\n",
    "                        reg_loss *= self.reg.item()\n",
    "                        new_loss = pred_loss + reg_loss\n",
    "                    if pred_loss >100000 or (pred_loss.isnan().any()) :\n",
    "                        print (\"Optimizer shows weird behaviour, reinitializing at previous best_State\")\n",
    "                        self.load_state_dict(best_state)\n",
    "                        opt = torch.optim.LBFGS(self.parameters(), lr = lr)\n",
    "                    if epoch %10 == 1:\n",
    "                        loss_history.append(lowest_loss.item())\n",
    "                elif self.opt == \"Adam\":\n",
    "                    pred = self.forward(x_data)\n",
    "                    pred_loss = loss(pred, y_data)#, self.xdos, perc = True)\n",
    "                    new_loss = pred_loss\n",
    "                    pred_loss.backward()\n",
    "                    opt.step()\n",
    "                    if pred_loss >100000 or (pred_loss.isnan().any()) :\n",
    "                        print (\"Optimizer shows weird behaviour, reinitializing at previous best_State\")\n",
    "                        self.load_state_dict(best_state)\n",
    "                        opt = torch.optim.Adam(self.parameters(), lr = lr, weight_decay = self.reg.item())\n",
    "                    if epoch %1000 == 1:\n",
    "                        loss_history.append(lowest_loss.item())\n",
    "\n",
    "            with torch.no_grad():\n",
    "                if valdata_loader is not None:\n",
    "                    new_loss = torch.zeros(1, requires_grad = False).to(self.device)\n",
    "                    for x_val, y_val in valdata_loader:\n",
    "                        x_val, y_val = x_val.to(self.device), y_val.to(self.device)\n",
    "                        val_pred = self.forward(x_val)\n",
    "                        new_loss += loss(val_pred, y_val, self.xdos, perc = False)\n",
    "\n",
    "                if lowest_loss - new_loss > tol: #threshold to stop training\n",
    "                    best_state = copy.deepcopy(self.state_dict())\n",
    "                    lowest_loss = new_loss\n",
    "                    trigger = 0\n",
    "\n",
    "                else:\n",
    "                    trigger +=1\n",
    "                    scheduler.step()\n",
    "                    if trigger > threshold:\n",
    "                        self.load_state_dict(best_state)\n",
    "                        print (\"Implemented early stopping with lowest_loss: {}\".format(lowest_loss))\n",
    "                        return loss_history\n",
    "        return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9441e750",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T17:37:38.673859Z",
     "start_time": "2023-01-27T17:37:26.800637Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3:   0%|                                                                                                          | 3/20000 [00:11<21:44:51,  3.92s/it, lowest_loss=24.2, pred_loss=24.2, trigger=0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [108]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m shift_range \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([x\u001b[38;5;241m*\u001b[39mxdos_step \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)])\n\u001b[1;32m      3\u001b[0m M_soap \u001b[38;5;241m=\u001b[39m AlignmentLinearModel(\u001b[38;5;241m448\u001b[39m, \u001b[38;5;241m778\u001b[39m, n_train, xdos, \u001b[38;5;241m1e-11\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLBFGS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mM_soap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader_soap\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [106]\u001b[0m, in \u001b[0;36mAlignmentLinearModel.fit\u001b[0;34m(self, traindata_loader, valdata_loader, loss, lr, n_epochs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _pred_loss\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _new_loss\n\u001b[0;32m--> 113\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m#print (z)\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/anaconda3/envs/rascaline/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     64\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rascaline/lib/python3.10/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rascaline/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rascaline/lib/python3.10/site-packages/torch/optim/lbfgs.py:437\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_iter \u001b[38;5;241m!=\u001b[39m max_iter:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;66;03m# re-evaluate function only if not in last iteration\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;66;03m# the reason we do this: in a stochastic setting,\u001b[39;00m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;66;03m# no use to re-evaluate that function here\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 437\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    438\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n\u001b[1;32m    439\u001b[0m     opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n",
      "File \u001b[0;32m~/anaconda3/envs/rascaline/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [106]\u001b[0m, in \u001b[0;36mAlignmentLinearModel.fit.<locals>.closure\u001b[0;34m(predictions)\u001b[0m\n\u001b[1;32m     99\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    100\u001b[0m _pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x_data)\n\u001b[0;32m--> 101\u001b[0m _pred_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malignment \u001b[38;5;241m=\u001b[39m \u001b[43mt_get_BF_shift_index_mse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxdos\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, self.xdos), perc = True)       \u001b[39;00m\n\u001b[1;32m    102\u001b[0m _pred_loss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e7\u001b[39m\n\u001b[1;32m    103\u001b[0m _pred_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnan_to_num(_pred_loss, nan\u001b[38;5;241m=\u001b[39mlowest_loss\u001b[38;5;241m.\u001b[39mitem(), posinf \u001b[38;5;241m=\u001b[39m lowest_loss\u001b[38;5;241m.\u001b[39mitem(), neginf \u001b[38;5;241m=\u001b[39m lowest_loss\u001b[38;5;241m.\u001b[39mitem())                 \n",
      "Input \u001b[0;32mIn [97]\u001b[0m, in \u001b[0;36mt_get_BF_shift_index_mse\u001b[0;34m(prediction, true, shift_range, xdos, perc)\u001b[0m\n\u001b[1;32m      9\u001b[0m index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m((prediction)):\n\u001b[0;32m---> 11\u001b[0m     shifted_preds \u001b[38;5;241m=\u001b[39m \u001b[43mconsistency\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshifted_ldos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshift_range\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxdos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_range\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     mse[i], index[i] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmin(loss\u001b[38;5;241m.\u001b[39mt_get_each_mse(shifted_preds, true[i]\u001b[38;5;241m.\u001b[39mrepeat(shift_range\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m)),\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     13\u001b[0m mse \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(mse, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/scratch/how/dostools/src/consistency/consistency.py:95\u001b[0m, in \u001b[0;36mshifted_ldos\u001b[0;34m(ldos, xdos, shift)\u001b[0m\n\u001b[1;32m     93\u001b[0m shifted_ldos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(ldos)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ldos\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     xdos_shift \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshift\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mxdos_step\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mint()\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ldos)):\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m xdos_shift[i] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xdos_step = xdos[1] - xdos[0]\n",
    "shift_range = torch.tensor([x*xdos_step for x in range(0,1)])\n",
    "M_soap = AlignmentLinearModel(448, 778, n_train, xdos, 1e-11, \"LBFGS\", \"cpu\")\n",
    "loss_history = M_soap.fit(train_dataloader_soap,None, None, 1, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(self, traindata_loader, valdata_loader, loss, lr ,n_epochs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a400e30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T17:12:43.058218Z",
     "start_time": "2023-01-27T17:12:43.052956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1039, 448])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Silicon.Features['structure_avedescriptors'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37822348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T17:12:52.677940Z",
     "start_time": "2023-01-27T17:12:52.672236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1039, 778])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c20edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, inputSize, outputSize, train_size, xdos, reg, opt, device):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
